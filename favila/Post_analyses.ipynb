{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Import stuff](#import_everything)\n",
    "2. [Set whether these analyses are done for this analysis or not](#set_whether_these_analyses_are_done_for_this_analysis_or_not)\n",
    "3. [Load data](#os.path.exists_checkpoint_fig_dir_load_data)\n",
    "    1. [Set values for indexing](#Set_some_values_for_indexing_etc)\n",
    "    2. [Rearranging data](#Rearranging_data)\n",
    "4. [Start Analyses](#Start_Analyses)\n",
    "5. [Learning Accuracy (SSE ) over time](#Learning_Accuracy_SSE_over_time)\n",
    "    1. [Print checkpoint](#Checkpoint_0:_istheoutputoutputshowncorrectlythroughoutthelearningtask)\n",
    "    2. [Visualize the output layer at each epoch](#Visualizetheoutputlayerateachepoch)\n",
    "6. [Correlation Analysis](#Correlation_AnalysisFirstsetupcorrelationmatricesforfinalepochineachtask)\n",
    "    1. [Plot Within Pair Correlation Over Time](#Plot_Within_Pair_Correlation_Over_Time)\n",
    "    2. [Is the low/med/high within pair correlation in the right order in the output layer?](#is_the_low/med/high_within_pair_correlation_in_the_right_order_in_the_output_layer?)\n",
    "    3. [Is the low/med/high within pair correlation in the right order in the hidden layer?](#is_the_low/med/high_within_pair_correlation_in_the_right_order_in_the_hidden_layer?)\n",
    "    4. [Before vs After correlation](#before_vs_after_correlation)\n",
    "    5. [MDS](#MDS)\n",
    "7. [Plot # of shared units in hidden layer](#Plot_#_shared_units_in_hidden_layer)\n",
    "8. [Difference score](#within-pair_correlation_minus_across-pair_correlation._Done_in_the_hidden_layer._)\n",
    "9. [Center of mass](#CENTER_OF_MASS)\n",
    "10. [Analyze Scene Layer in Association Task](#Scene_Association_Task)\n",
    "11. [Analyze Pop Up Over Time](#Analyze_Pop_Up_Over_Time)\n",
    "    1. [Define functions to plot cycles](#Define_functions_to_plot_cycles)\n",
    "    2. [Checkpoint for scene layer pop up](#checkpoint_for_scene_layer_pop_up.)\n",
    "    3. [Output Layer: Pop Up](#Output_Layer:_Pop_Up)\n",
    "    4. [Hidden Layer: Pop Up](#Hidden_Layer:_Pop_Up) \n",
    "        1. [Assign units by initial activation](#First,_Assign_units_by_initial_activation)\n",
    "        2. [How many units in each category](#How_Many_in_each_category)\n",
    "        3. [Plot the hidden layer pop up](#Plot_the_hidden_layer_pop_up)\n",
    "        4. [Hidden Layer Pop Up over cycles PROPORTIONALLY](#Hidden_Layer_Pop_Up_over_cycles_PROPORTIONALLY)\n",
    "\n",
    "12. [XCAL](#XCAL)\n",
    "    1. [Some necessary setup for AvgSLrn](#XCAL)\n",
    "    2. [Plot the AvgSLrn in each layer for target, competitor, and shared units in first epoch of Output Recall Task](#Plot_the_AvgSLrn_in_each_layer_for_target,_competitor,_and_shared_units_in_first_epoch_of_Color_Recall_Task)\n",
    "    3. [Checkpoint for avgSLrn](#Checkpoint_for_avgSLrn)\n",
    "    4. [Calculate NMPH Learning curve](#calc NMPH curve)\n",
    "    4. [Print out param sheet for each projection type to easily paste into output_diff.go](#Print_out_param_sheet_for_each_projection_type_to_easily_paste_into_output_diff.go)\n",
    "    5. [Plot scatter plot of DWt vs. AvgSLrn coproducts](#plot_scatter_plot_DWt_vs_AvgSLrn_coproducts)\n",
    "12. [Add necessary checkpoint info](#Add_necessary_checkpoint_info)\n",
    "13. [Save](#Save)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "<a id='import_everything'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import os as os\n",
    "import sys as sys\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import MDS\n",
    "\n",
    "\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "from statsmodels.stats.multicomp import MultiComparison\n",
    "import traceback\n",
    "import pprint\n",
    "import cProfile, pstats, io\n",
    "import traceback\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "codeprofiler = cProfile.Profile()\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "sns.set_style(style='white')\n",
    "pd.set_option('display.max_columns', 30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of arguments: 3 arguments.\n",
      "Argument List: ['/usr/people/qanguyen/anaconda3/envs/leabra/lib/python3.8/site-packages/ipykernel_launcher.py', '-f', '/mnt/cup/people/qanguyen/.local/share/jupyter/runtime/kernel-71a479fa-4228-4d56-8b9a-e8c3ee19ee17.json']\n",
      "---\n",
      "/mnt/cup/people/qanguyen/.local/share/jupyter/runtime/kernel-71a479fa-4228-4d56-8b9a-e8c3ee19ee17.json\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print('Number of arguments:', len(sys.argv), 'arguments.')\n",
    "print('Argument List:', str(sys.argv))\n",
    "print('---')\n",
    "from_cmdLine = sys.argv[-1]\n",
    "print(from_cmdLine)\n",
    "\n",
    "print('---')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using script to set data\n"
     ]
    }
   ],
   "source": [
    "if from_cmdLine == 'cmd' :\n",
    "    data_file = sys.argv[-2]\n",
    "    print('using command line to set data')\n",
    "    dataDir = data_file + '/'\n",
    "else :\n",
    "    print('using script to set data')\n",
    "\n",
    "    #Set the date of the data we want to look at:\n",
    "\n",
    "    data_file = '2021-05-26-11-03-22' #2 runs\n",
    "#     data_file = '2021-05-31-16-41-55' #same trial, 20 runs\n",
    "#     data_file = '2021-05-31-16-46-29' #different trial, 20 runs\n",
    "\n",
    "    data_file = 'same_diff2/Same/'\n",
    "    \n",
    "    data_file = '2021-10-31-11-37-45'\n",
    "    data_file = '2021-10-31-12-03-00'\n",
    "    data_file = '2021-11-22-18-55-43'\n",
    "    data_file = '2022-02-05-18-51-59' # sample with just 3 runs\n",
    "#     data_file = '2021-12-09-00-09-59'\n",
    "    dataDir = 'data/' + data_file + '/'\n",
    "    dataDir = '/scratch/qanguyen/favila/alex_may_25_2022/results_--same_diff_flag=Same/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### set whether these analyses are done for this analysis or not\n",
    "<a id='set_whether_these_analyses_are_done_for_this_analysis_or_not'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_trial_done = 1\n",
    "train_trial_done = 1\n",
    "test_cycle_done = 0\n",
    "train_cycle_done = 0\n",
    "\n",
    "#Do you want this code to spit out a good NMPH curve based on the activity? \n",
    "#For regular analyses, that code chunk should get skipped.\n",
    "calculate_learning_curve = 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Load Data\n",
    "<a id='os.path.exists_checkpoint_fig_dir_load_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "figDir = dataDir + 'fig/'\n",
    "checkpoint_fig_dir = figDir + 'checkpoints/'\n",
    "results_fig_dir = figDir + 'results/'\n",
    "eps_dir = results_fig_dir + 'eps_files/'\n",
    "\n",
    "if not os.path.exists(figDir) :\n",
    "    os.mkdir(figDir)\n",
    "    \n",
    "if not os.path.exists(results_fig_dir) :\n",
    "    os.mkdir(results_fig_dir)\n",
    "    \n",
    "if not os.path.exists(checkpoint_fig_dir) :\n",
    "    os.mkdir(checkpoint_fig_dir)\n",
    "    \n",
    "if not os.path.exists(eps_dir) :\n",
    "    os.mkdir(eps_dir)\n",
    "\n",
    "if not os.path.exists(checkpoint_fig_dir + 'cycle_plots/') :\n",
    "    os.mkdir(checkpoint_fig_dir + 'cycle_plots/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_run = pd.read_csv(dataDir + 'output_diff_Base_run.csv', sep = '\\t')\n",
    "# print('max run: ' + str(data_run.iloc[-1]['|Run']))\n",
    "\n",
    "# data_run.iloc[:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_run[\"#Seed\"].to_numpy().std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codeprofiler.enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_epc = pd.read_csv(dataDir + 'favila_Base_epc.csv', sep = '\\t')\n",
    "# data_epc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test trial data\n",
      "done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>|Run</th>\n",
       "      <th>|Epoch</th>\n",
       "      <th>$CurrentTask</th>\n",
       "      <th>$CurrentTest</th>\n",
       "      <th>|Trial</th>\n",
       "      <th>$TrialName</th>\n",
       "      <th>#Scene_Err</th>\n",
       "      <th>#Scene_SSE</th>\n",
       "      <th>#Scene_AvgSSE</th>\n",
       "      <th>#Scene_CosDiff</th>\n",
       "      <th>#Category_Err</th>\n",
       "      <th>#Category_SSE</th>\n",
       "      <th>#Category_AvgSSE</th>\n",
       "      <th>#Category_CosDiff</th>\n",
       "      <th>#Output_Err</th>\n",
       "      <th>...</th>\n",
       "      <th>#OutActP[2:0,35]</th>\n",
       "      <th>#OutActP[2:0,36]</th>\n",
       "      <th>#OutActP[2:0,37]</th>\n",
       "      <th>#OutActP[2:0,38]</th>\n",
       "      <th>#OutActP[2:0,39]</th>\n",
       "      <th>#OutActP[2:0,40]</th>\n",
       "      <th>#OutActP[2:0,41]</th>\n",
       "      <th>#OutActP[2:0,42]</th>\n",
       "      <th>#OutActP[2:0,43]</th>\n",
       "      <th>#OutActP[2:0,44]</th>\n",
       "      <th>#OutActP[2:0,45]</th>\n",
       "      <th>#OutActP[2:0,46]</th>\n",
       "      <th>#OutActP[2:0,47]</th>\n",
       "      <th>#OutActP[2:0,48]</th>\n",
       "      <th>#OutActP[2:0,49]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>TaskColorWOOsc</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>0</td>\n",
       "      <td>med1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>TaskColorWOOsc</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>1</td>\n",
       "      <td>med2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TaskColorRecall</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>0</td>\n",
       "      <td>med1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>TaskColorRecall</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>1</td>\n",
       "      <td>med2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>TaskColorWOOsc</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>0</td>\n",
       "      <td>med1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>TaskColorRecall</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>1</td>\n",
       "      <td>med2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>49</td>\n",
       "      <td>-1</td>\n",
       "      <td>TaskColorWOOsc</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>0</td>\n",
       "      <td>med1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>49</td>\n",
       "      <td>-1</td>\n",
       "      <td>TaskColorWOOsc</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>1</td>\n",
       "      <td>med2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>TaskColorRecall</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>0</td>\n",
       "      <td>med1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>TaskColorRecall</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>1</td>\n",
       "      <td>med2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      |Run  |Epoch     $CurrentTask  $CurrentTest  |Trial $TrialName  \\\n",
       "0        0      -1   TaskColorWOOsc  TestColorAll       0       med1   \n",
       "1        0      -1   TaskColorWOOsc  TestColorAll       1       med2   \n",
       "2        0       0  TaskColorRecall  TestColorAll       0       med1   \n",
       "3        0       0  TaskColorRecall  TestColorAll       1       med2   \n",
       "42       1      -1   TaskColorWOOsc  TestColorAll       0       med1   \n",
       "...    ...     ...              ...           ...     ...        ...   \n",
       "2019    48       0  TaskColorRecall  TestColorAll       1       med2   \n",
       "2058    49      -1   TaskColorWOOsc  TestColorAll       0       med1   \n",
       "2059    49      -1   TaskColorWOOsc  TestColorAll       1       med2   \n",
       "2060    49       0  TaskColorRecall  TestColorAll       0       med1   \n",
       "2061    49       0  TaskColorRecall  TestColorAll       1       med2   \n",
       "\n",
       "      #Scene_Err  #Scene_SSE  #Scene_AvgSSE  #Scene_CosDiff  #Category_Err  \\\n",
       "0              0           0              0          0.9989              0   \n",
       "1              0           0              0          0.9994              0   \n",
       "2              0           0              0          0.9992              0   \n",
       "3              0           0              0          1.0000              0   \n",
       "42             0           0              0          0.9993              0   \n",
       "...          ...         ...            ...             ...            ...   \n",
       "2019           0           0              0          1.0000              0   \n",
       "2058           0           0              0          0.9993              0   \n",
       "2059           0           0              0          0.9997              0   \n",
       "2060           0           0              0          0.9991              0   \n",
       "2061           0           0              0          0.9994              0   \n",
       "\n",
       "      #Category_SSE  #Category_AvgSSE  #Category_CosDiff  #Output_Err  ...  \\\n",
       "0                 0                 0                  1            0  ...   \n",
       "1                 0                 0                  1            0  ...   \n",
       "2                 0                 0                  1            0  ...   \n",
       "3                 0                 0                  1            0  ...   \n",
       "42                0                 0                  1            0  ...   \n",
       "...             ...               ...                ...          ...  ...   \n",
       "2019              0                 0                  1            0  ...   \n",
       "2058              0                 0                  1            0  ...   \n",
       "2059              0                 0                  1            0  ...   \n",
       "2060              0                 0                  1            0  ...   \n",
       "2061              0                 0                  1            0  ...   \n",
       "\n",
       "      #OutActP[2:0,35]  #OutActP[2:0,36]  #OutActP[2:0,37]  #OutActP[2:0,38]  \\\n",
       "0         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "1         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "3         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "42        1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "...                ...               ...               ...               ...   \n",
       "2019      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2058      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2059      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2060      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2061      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "\n",
       "      #OutActP[2:0,39]  #OutActP[2:0,40]  #OutActP[2:0,41]  #OutActP[2:0,42]  \\\n",
       "0         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "1         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "3         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "42        1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "...                ...               ...               ...               ...   \n",
       "2019      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2058      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2059      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2060      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2061      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "\n",
       "      #OutActP[2:0,43]  #OutActP[2:0,44]  #OutActP[2:0,45]  #OutActP[2:0,46]  \\\n",
       "0         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "1         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "3         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "42        1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "...                ...               ...               ...               ...   \n",
       "2019      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2058      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2059      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2060      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2061      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "\n",
       "      #OutActP[2:0,47]  #OutActP[2:0,48]  #OutActP[2:0,49]  \n",
       "0         1.401000e-45      1.401000e-45      1.401000e-45  \n",
       "1         1.401000e-45      1.401000e-45      1.401000e-45  \n",
       "2         1.401000e-45      1.401000e-45      1.401000e-45  \n",
       "3         1.401000e-45      1.401000e-45      1.401000e-45  \n",
       "42        1.401000e-45      1.401000e-45      1.401000e-45  \n",
       "...                ...               ...               ...  \n",
       "2019      1.401000e-45      1.401000e-45      1.401000e-45  \n",
       "2058      1.401000e-45      1.401000e-45      1.401000e-45  \n",
       "2059      1.401000e-45      1.401000e-45      1.401000e-45  \n",
       "2060      1.401000e-45      1.401000e-45      1.401000e-45  \n",
       "2061      1.401000e-45      1.401000e-45      1.401000e-45  \n",
       "\n",
       "[200 rows x 239 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if (test_trial_done == 1) :\n",
    "    print('loading test trial data')\n",
    "    \n",
    "    data_test = pd.read_csv(dataDir + 'favila_Base_tsttrl.csv', sep = '\\t')\n",
    "    data_test = data_test[data_test['|Run'] != '|Run'] ## because of error where header line is repeated. remove that one lne\n",
    "    assert set(data_test['$TrialName']) == {'med1', 'med2'}, \"Trial name must be either med1 or med2\"\n",
    "    print('done')\n",
    "    \n",
    "data_test[(data_test[\"|Epoch\"] <1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fill_dummy_stim(data_test, task_type) :\n",
    "    \n",
    "#     remaining_columns = [c for c in data_test.columns if c not in ['|Run', '|Epoch', '$CurrentTask', '$CurrentTest', '$TrialName']]\n",
    "#     fake_data = data_test[data_test['$TrialName'] == 'med1'].reset_index(drop = True)\n",
    "\n",
    "#     dummy_df = pd.DataFrame()\n",
    "#     for loc in range(max(fake_data.index) + 1) : \n",
    "#         dummy_trial = 2\n",
    "#         for trialType in ['low1','low2', 'high1', 'high2'] :\n",
    "#             temp = fake_data.loc[[loc]]\n",
    "#             temp[remaining_columns] = 0\n",
    "#             temp['$TrialName'] = trialType\n",
    "#             temp['|Trial'] = dummy_trial\n",
    "#             dummy_trial += 1\n",
    "#             dummy_df = dummy_df.append(temp)\n",
    "\n",
    "#     dummy_df\n",
    "    \n",
    "#     data_test = data_test.append(dummy_df)\n",
    "# #     return(data_test)\n",
    "\n",
    "\n",
    "    if task_type == 'test' :\n",
    "        first_columns = [c for c in data_test.columns if c in ['|Run', '|Epoch', '$CurrentTask', '$CurrentTest']]\n",
    "        remaining_columns = [c for c in data_test.columns if c not in ['|Run', '|Epoch', '$CurrentTask', '$CurrentTest', '|Trial', '$TrialName']]\n",
    "\n",
    "    elif task_type == 'train':\n",
    "        first_columns = [c for c in data_test.columns if c in ['|Run', '|Epoch', '$CurrentTask', ]]\n",
    "        remaining_columns = [c for c in data_test.columns if c not in ['|Run', '|Epoch', '$CurrentTask', '|Trial', '$TrialName']]\n",
    "\n",
    "    numeric_columns = [c for c in remaining_columns if c not in ['|Run', '|Epoch', '$CurrentTask', '$CurrentTest', '$TrialName']]\n",
    "    ### DF 1:\n",
    "    #make a df with the columns that we want to be not-zero for our dummy values\n",
    "    df_1 = data_test[first_columns].drop_duplicates()\n",
    "\n",
    "    #add a dummy column so that we can do an outer merge later\n",
    "    df_1['dummy'] = 1\n",
    "    \n",
    "    ### DF2 :\n",
    "    #make a second df with just the trial number, trial names, and all the columns that will be zero\n",
    "    df_2 = pd.DataFrame(columns = remaining_columns)\n",
    "    \n",
    "    #add the rows taht are zeroed out for each of our fake stimuli\n",
    "    df_2 = df_2.append(pd.Series(0, index=df_2.columns), ignore_index=True)\n",
    "    df_2 = df_2.append(pd.Series(0, index=df_2.columns), ignore_index=True)\n",
    "    df_2 = df_2.append(pd.Series(0, index=df_2.columns), ignore_index=True)\n",
    "    df_2 = df_2.append(pd.Series(0, index=df_2.columns), ignore_index=True)\n",
    "\n",
    "\n",
    "    #add in a column with the values of each stim. This df now has 4 rows (one for each of our fake stim)\n",
    "    df_2.insert(0, \"$TrialName\", ['low1','low2','high1','high2'], False) \n",
    "    df_2.insert(0, \"|Trial\", [2,3,4,5], False) \n",
    "    \n",
    "    #add a dummy column so that we can do an outer merge\n",
    "    df_2['dummy'] = 1\n",
    "    df_2[numeric_columns] = df_2[numeric_columns].apply(pd.to_numeric)\n",
    "    #do an outer merge of the two dfs. This is everything we need for the fake stim.\n",
    "    fake_stim = pd.merge(df_1, df_2, on = 'dummy', how = 'outer')\n",
    "    fake_stim = fake_stim.drop(['dummy'], axis = 1)\n",
    "\n",
    "\n",
    "    #set everything to be numeric because for some reason it sets it not as numeric:\n",
    "#     fake_stim[numeric_columns] = fake_stim[numeric_columns].apply(pd.to_numeric)\n",
    "\n",
    "    #append to orginal dataframe. Sort.\n",
    "    data_test = data_test.append(fake_stim)\n",
    "    data_test = data_test.sort_values(by = ['|Run', '|Epoch', '|Trial']).reset_index(drop = True)\n",
    "\n",
    "    return data_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOOKS LIKE NOT ALL THE VARIABLES ARE HERE. MAKING DUMMY STIMULI\n"
     ]
    }
   ],
   "source": [
    "if 'high1' in data_test['$TrialName'].unique() :\n",
    "        ;\n",
    "else :\n",
    "    print('LOOKS LIKE NOT ALL THE VARIABLES ARE HERE. MAKING DUMMY STIMULI')\n",
    "\n",
    "    data_test = fill_dummy_stim(data_test, 'test')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>|Run</th>\n",
       "      <th>|Epoch</th>\n",
       "      <th>$CurrentTask</th>\n",
       "      <th>$CurrentTest</th>\n",
       "      <th>|Trial</th>\n",
       "      <th>$TrialName</th>\n",
       "      <th>#Scene_Err</th>\n",
       "      <th>#Scene_SSE</th>\n",
       "      <th>#Scene_AvgSSE</th>\n",
       "      <th>#Scene_CosDiff</th>\n",
       "      <th>#Category_Err</th>\n",
       "      <th>#Category_SSE</th>\n",
       "      <th>#Category_AvgSSE</th>\n",
       "      <th>#Category_CosDiff</th>\n",
       "      <th>#Output_Err</th>\n",
       "      <th>...</th>\n",
       "      <th>#OutActP[2:0,35]</th>\n",
       "      <th>#OutActP[2:0,36]</th>\n",
       "      <th>#OutActP[2:0,37]</th>\n",
       "      <th>#OutActP[2:0,38]</th>\n",
       "      <th>#OutActP[2:0,39]</th>\n",
       "      <th>#OutActP[2:0,40]</th>\n",
       "      <th>#OutActP[2:0,41]</th>\n",
       "      <th>#OutActP[2:0,42]</th>\n",
       "      <th>#OutActP[2:0,43]</th>\n",
       "      <th>#OutActP[2:0,44]</th>\n",
       "      <th>#OutActP[2:0,45]</th>\n",
       "      <th>#OutActP[2:0,46]</th>\n",
       "      <th>#OutActP[2:0,47]</th>\n",
       "      <th>#OutActP[2:0,48]</th>\n",
       "      <th>#OutActP[2:0,49]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>TaskColorWOOsc</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>0</td>\n",
       "      <td>med1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9989</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>TaskColorWOOsc</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>1</td>\n",
       "      <td>med2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>TaskColorWOOsc</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>2</td>\n",
       "      <td>low1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>TaskColorWOOsc</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>3</td>\n",
       "      <td>low2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>TaskColorWOOsc</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>4</td>\n",
       "      <td>high1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6295</th>\n",
       "      <td>49</td>\n",
       "      <td>19</td>\n",
       "      <td>TaskColorRecall</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>1</td>\n",
       "      <td>med2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "      <td>1.401000e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296</th>\n",
       "      <td>49</td>\n",
       "      <td>19</td>\n",
       "      <td>TaskColorRecall</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>2</td>\n",
       "      <td>low1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>49</td>\n",
       "      <td>19</td>\n",
       "      <td>TaskColorRecall</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>3</td>\n",
       "      <td>low2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298</th>\n",
       "      <td>49</td>\n",
       "      <td>19</td>\n",
       "      <td>TaskColorRecall</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>4</td>\n",
       "      <td>high1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6299</th>\n",
       "      <td>49</td>\n",
       "      <td>19</td>\n",
       "      <td>TaskColorRecall</td>\n",
       "      <td>TestColorAll</td>\n",
       "      <td>5</td>\n",
       "      <td>high2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6300 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      |Run  |Epoch     $CurrentTask  $CurrentTest  |Trial $TrialName  \\\n",
       "0        0      -1   TaskColorWOOsc  TestColorAll       0       med1   \n",
       "1        0      -1   TaskColorWOOsc  TestColorAll       1       med2   \n",
       "2        0      -1   TaskColorWOOsc  TestColorAll       2       low1   \n",
       "3        0      -1   TaskColorWOOsc  TestColorAll       3       low2   \n",
       "4        0      -1   TaskColorWOOsc  TestColorAll       4      high1   \n",
       "...    ...     ...              ...           ...     ...        ...   \n",
       "6295    49      19  TaskColorRecall  TestColorAll       1       med2   \n",
       "6296    49      19  TaskColorRecall  TestColorAll       2       low1   \n",
       "6297    49      19  TaskColorRecall  TestColorAll       3       low2   \n",
       "6298    49      19  TaskColorRecall  TestColorAll       4      high1   \n",
       "6299    49      19  TaskColorRecall  TestColorAll       5      high2   \n",
       "\n",
       "      #Scene_Err  #Scene_SSE  #Scene_AvgSSE  #Scene_CosDiff  #Category_Err  \\\n",
       "0              0           0              0          0.9989              0   \n",
       "1              0           0              0          0.9994              0   \n",
       "2              0           0              0          0.0000              0   \n",
       "3              0           0              0          0.0000              0   \n",
       "4              0           0              0          0.0000              0   \n",
       "...          ...         ...            ...             ...            ...   \n",
       "6295           0           0              0          0.9997              0   \n",
       "6296           0           0              0          0.0000              0   \n",
       "6297           0           0              0          0.0000              0   \n",
       "6298           0           0              0          0.0000              0   \n",
       "6299           0           0              0          0.0000              0   \n",
       "\n",
       "      #Category_SSE  #Category_AvgSSE  #Category_CosDiff  #Output_Err  ...  \\\n",
       "0                 0                 0                  1            0  ...   \n",
       "1                 0                 0                  1            0  ...   \n",
       "2                 0                 0                  0            0  ...   \n",
       "3                 0                 0                  0            0  ...   \n",
       "4                 0                 0                  0            0  ...   \n",
       "...             ...               ...                ...          ...  ...   \n",
       "6295              0                 0                  1            0  ...   \n",
       "6296              0                 0                  0            0  ...   \n",
       "6297              0                 0                  0            0  ...   \n",
       "6298              0                 0                  0            0  ...   \n",
       "6299              0                 0                  0            0  ...   \n",
       "\n",
       "      #OutActP[2:0,35]  #OutActP[2:0,36]  #OutActP[2:0,37]  #OutActP[2:0,38]  \\\n",
       "0         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "1         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2         0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "3         0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "4         0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "...                ...               ...               ...               ...   \n",
       "6295      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "6296      0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "6297      0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "6298      0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "6299      0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "\n",
       "      #OutActP[2:0,39]  #OutActP[2:0,40]  #OutActP[2:0,41]  #OutActP[2:0,42]  \\\n",
       "0         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "1         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2         0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "3         0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "4         0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "...                ...               ...               ...               ...   \n",
       "6295      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "6296      0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "6297      0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "6298      0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "6299      0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "\n",
       "      #OutActP[2:0,43]  #OutActP[2:0,44]  #OutActP[2:0,45]  #OutActP[2:0,46]  \\\n",
       "0         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "1         1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "2         0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "3         0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "4         0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "...                ...               ...               ...               ...   \n",
       "6295      1.401000e-45      1.401000e-45      1.401000e-45      1.401000e-45   \n",
       "6296      0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "6297      0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "6298      0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "6299      0.000000e+00      0.000000e+00      0.000000e+00      0.000000e+00   \n",
       "\n",
       "      #OutActP[2:0,47]  #OutActP[2:0,48]  #OutActP[2:0,49]  \n",
       "0         1.401000e-45      1.401000e-45      1.401000e-45  \n",
       "1         1.401000e-45      1.401000e-45      1.401000e-45  \n",
       "2         0.000000e+00      0.000000e+00      0.000000e+00  \n",
       "3         0.000000e+00      0.000000e+00      0.000000e+00  \n",
       "4         0.000000e+00      0.000000e+00      0.000000e+00  \n",
       "...                ...               ...               ...  \n",
       "6295      1.401000e-45      1.401000e-45      1.401000e-45  \n",
       "6296      0.000000e+00      0.000000e+00      0.000000e+00  \n",
       "6297      0.000000e+00      0.000000e+00      0.000000e+00  \n",
       "6298      0.000000e+00      0.000000e+00      0.000000e+00  \n",
       "6299      0.000000e+00      0.000000e+00      0.000000e+00  \n",
       "\n",
       "[6300 rows x 239 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train trial data\n"
     ]
    }
   ],
   "source": [
    "if (train_trial_done == 1) :\n",
    "    print('loading train trial data')\n",
    "    \n",
    "    data_train = pd.read_csv(dataDir + 'favila_Base_trntrl.csv', sep = '\\t')\n",
    "    data_train = data_train[data_train['|Run'] != '|Run'] ## because of error where header line is repeated. remove that one lne\n",
    "\n",
    "    print('done')\n",
    "    \n",
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'high1' in data_train['$TrialName'].unique() :\n",
    "        ;\n",
    "else :\n",
    "    print('LOOKS LIKE NOT ALL THE VARIABLES ARE HERE. MAKING DUMMY STIMULI')\n",
    "\n",
    "    data_train = fill_dummy_stim(data_train, 'train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (train_cycle_done == 1) :\n",
    "    print('loading train cycle data')\n",
    "    data_trn_cyc = pd.read_csv(dataDir + 'favila_Base_trncyc.csv', sep = '\\t')\n",
    "    data_trn_cyc.head(200)\n",
    "    print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (test_cycle_done == 1) : \n",
    "    print('loading test cycle data')\n",
    "    data_tst_cyc = pd.read_csv(dataDir +'favila_Base_tstcyc.csv', sep = '\\t')\n",
    "    data_tst_cyc.head(200)\n",
    "    print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codeprofiler.disable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['#OutActM[2:0,0]<2:1,50>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Set some values for indexing etc\n",
    "<a id='Set_some_values_for_indexing_etc'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set values for start and endpoints of output layer and hidden layer to use for indexing\n",
    "numPairs = 3\n",
    "\n",
    "scene_Start_AvgSLrn = '#SceneAvgSLrn[4:0,0,0,0]<4:2,1,1,3>'\n",
    "scene_End_AvgSLrn = '#SceneAvgSLrn[4:1,0,0,2]'\n",
    "\n",
    "outputM_Start = '#OutActM[2:0,0]<2:1,50>'\n",
    "outputM_End = '#OutActM[2:0,49]'\n",
    "\n",
    "\n",
    "sceneM_Start = '#SceneActM[4:0,0,0,0]<4:2,1,1,3>'\n",
    "sceneM_End = '#SceneActM[4:1,0,0,2]'\n",
    "\n",
    "output_Start = '#OutAct[2:0,0]<2:1,50>'\n",
    "output_End = '#OutAct[2:0,49]'\n",
    "\n",
    "output_Start_AvgS = '#OutAvgS[2:0,0]<2:1,50>'\n",
    "output_End_AvgS = '#OutAvgS[2:0,49]'\n",
    "\n",
    "output_Start_AvgM = '#OutAvgM[2:0,0]<2:1,50>'\n",
    "output_End_AvgM = '#OutAvgM[2:0,49]'\n",
    "\n",
    "output_Start_AvgSLrn = '#OutAvgSLrn[2:0,0]<2:1,50>'\n",
    "output_End_AvgSLrn = '#OutAvgSLrn[2:0,49]'\n",
    "\n",
    "filter_outM = [col for col in data_train if col.startswith('#OutActM[')]\n",
    "filter_HiddM = [col for col in data_train if col.startswith('#HiddenActM[')]\n",
    "filter_out_AvgSLrn = [col for col in data_train if col.startswith('#OutAvgSLrn[')]\n",
    "filter_Hidden_AvgSLrn = [col for col in data_train if col.startswith('#HiddenAvgSLrn[')]\n",
    "filter_outP = [col for col in data_train if col.startswith('#OutActP[')]\n",
    "filter_HiddenP = [col for col in data_train if col.startswith('#HiddenActP[')]\n",
    "if 'data_trn_cyc' in locals():\n",
    "    filter_out = [col for col in data_trn_cyc if col.startswith('#OutAct[')]\n",
    "    filter_scene = [col for col in data_trn_cyc if col.startswith('#SceneAct[')]\n",
    "\n",
    "\n",
    "hidden_dimensions = 1\n",
    "\n",
    "if hidden_dimensions == 1 :\n",
    "    study_task_run = 0;\n",
    "elif hidden_dimensions == 2 :\n",
    "    study_task_run = 1;\n",
    "    \n",
    "if hidden_dimensions == 2 :\n",
    "    \n",
    "    hiddenM_Start = '#HiddenActM[2:0,0]<2:10,10>'    \n",
    "    hiddenM_End = '#HiddenActM[2:9,9]'\n",
    "\n",
    "    hidden_Start = '#HiddenAct[2:0,0]<2:10,10>'    \n",
    "    hidden_End = '#HiddenAct[2:9,9]'\n",
    "\n",
    "    hidden_Start_AvgL = '#HiddenAvgL[2:0,0]<2:10,10>'    \n",
    "    hidden_End_AvgL = '#HiddenAvgL[2:9,9]'\n",
    "\n",
    "    hidden_Start_AvgM = '#HiddenAvgM[2:0,0]<2:10,10>'    \n",
    "    hidden_End_AvgM = '#HiddenAvgM[2:9,9]'\n",
    "\n",
    "    hidden_Start_AvgS = '#HiddenAvgS[2:0,0]<2:10,10>'    \n",
    "    hidden_End_AvgS = '#HiddenAvgS[2:9,9]'\n",
    "\n",
    "    hidden_Start_AvgSLrn = '#HiddenAvgSLrn[2:0,0]<2:10,10>'    \n",
    "    hidden_End_AvgSLrn = '#HiddenAvgSLrn[2:9,9]'\n",
    "    \n",
    "    \n",
    "elif hidden_dimensions == 1 :\n",
    "    \n",
    "    hiddenM_Start = '#HiddenActM[2:0,0]<2:1,50>'  \n",
    "    hiddenM_End = '#HiddenActM[2:0,49]'\n",
    "\n",
    "    hidden_Start = '#HiddenAct[2:0,0]<2:1,50>'  \n",
    "    hidden_End = '#HiddenAct[2:0,49]'\n",
    "\n",
    "    hidden_Start_AvgL = '#HiddenAvgL[2:0,0]<2:1,50>'   \n",
    "    hidden_End_AvgL = '#HiddenAvgL[2:0,49]'\n",
    "\n",
    "    hidden_Start_AvgM = '#HiddenAvgM[2:0,0]<2:1,50>'    \n",
    "    hidden_End_AvgM = '#HiddenAvgM[2:0,49]'\n",
    "\n",
    "    hidden_Start_AvgS = '#HiddenAvgS[2:0,0]<2:1,50>'    \n",
    "    hidden_End_AvgS = '#HiddenAvgS[2:0,49]'\n",
    "\n",
    "    hidden_Start_AvgSLrn = '#HiddenAvgSLrn[2:0,0]<2:1,50>'  \n",
    "    hidden_End_AvgSLrn = '#HiddenAvgSLrn[2:0,49]'\n",
    "\n",
    "\n",
    "\n",
    "hidden_to_hidden_weights_Start = '#HiddentoHiddenWeights[1:0]<1:9900>'\n",
    "hidden_to_hidden_weights_End = '#HiddentoHiddenWeights[1:9899]'\n",
    "\n",
    "output_to_hidden_weights_Start = '#OutputtoHiddenWeights[1:0]<1:5000>'\n",
    "output_to_hidden_weights_End = '#OutputtoHiddenWeights[1:4999]'\n",
    "\n",
    "hidden_to_output_weights_Start = '#HiddentoOutputWeights[1:0]<1:5000>'\n",
    "hidden_to_output_weights_End = '#HiddentoOutputWeights[1:4999]'\n",
    "\n",
    "hidden_to_hidden_DWt_Start = '#HiddentoHiddenDWt[1:0]<1:9900>'\n",
    "hidden_to_hidden_DWt_End = '#HiddentoHiddenDWt[1:9899]'\n",
    "\n",
    "output_to_hidden_DWt_Start = '#OutputtoHiddenDWt[1:0]<1:5000>'\n",
    "output_to_hidden_DWt_End = '#OutputtoHiddenDWt[1:4999]'\n",
    "\n",
    "hidden_to_output_DWt_Start = '#HiddentoOutputDWt[1:0]<1:5000>'\n",
    "hidden_to_output_DWt_End = '#HiddentoOutputDWt[1:4999]'\n",
    "\n",
    "scene_to_hidden_DWt_Start = '#ScenetoHiddenDWt[1:0]<1:600>'\n",
    "scene_to_hidden_DWt_End = '#ScenetoHiddenDWt[1:599]'\n",
    "\n",
    "hidden_to_scene_DWt_Start = '#HiddentoSceneDWt[1:0]<1:600>'\n",
    "hidden_to_scene_DWt_End = '#HiddentoSceneDWt[1:599]'\n",
    "\n",
    "obj_Start = '#ObjAct[2:0,0]<2:1,3>'\n",
    "obj_End = '#ObjAct[2:0,2]'\n",
    "\n",
    "#hidden net input:\n",
    "hidden_ge_start = '#HiddenGe[2:0,0]<2:10,10>'\n",
    "hidden_ge_end = '#HiddenGe[2:9,9]'\n",
    "\n",
    "if (numPairs == 2) :\n",
    "    stim_names = ['small1', 'small2', 'small3', 'small4']\n",
    "    \n",
    "elif (numPairs == 3) :\n",
    "    stim_names = ['low1','low2','med1', 'med2', 'high1','high2']\n",
    "    \n",
    "medium_only_analysis = True\n",
    "\n",
    "if medium_only_analysis == True :\n",
    "    stim_names = ['med1', 'med2']\n",
    "\n",
    "if (numPairs == 2) :\n",
    "    #post- pools:\n",
    "\n",
    "    scene_Start = '#SceneAct[4:0,0,0,0]<4:2,1,1,2>'\n",
    "    scene_End = '#SceneAct[4:1,0,0,1]'\n",
    "\n",
    "    #scene net input:\n",
    "    scene_ge_start = '#SceneGe[4:0,0,0,0]<4:2,1,1,2>'\n",
    "    scene_ge_end = '#SceneGe[4:1,0,0,1]'\n",
    "\n",
    "elif (numPairs==3) :\n",
    "    scene_Start = '#SceneAct[4:0,0,0,0]<4:2,1,1,3>'\n",
    "    scene_End = '#SceneAct[4:1,0,0,2]'\n",
    "\n",
    "    #scene net input:\n",
    "    scene_ge_start = '#SceneGe[4:0,0,0,0]<4:2,1,1,3>'\n",
    "    scene_ge_end = '#SceneGe[4:1,0,0,2]'\n",
    "\n",
    "\n",
    "#dictionary for scene layer to use for later analyses\n",
    "\n",
    "if (numPairs == 2) :\n",
    "    \n",
    "    sceneKey = {'#SceneAct[4:0,0,0,0]<4:2,1,1,2>' : 'small2', '#SceneAct[4:0,0,0,1]' : 'small4', '#SceneAct[4:1,0,0,0]': 'small1', '#SceneAct[4:1,0,0,1]': 'small3'}\n",
    "    sceneKey_ge = {'#SceneGe[4:0,0,0,0]<4:2,1,1,2>' : 'small2 Ge', '#SceneGe[4:0,0,0,1]' : 'small4 Ge', '#SceneGe[4:1,0,0,0]': 'small1 Ge', '#SceneGe[4:1,0,0,1]': 'small3 Ge'}\n",
    "\n",
    "elif (numPairs ==3) :\n",
    "    sceneKey = {'#SceneAct[4:0,0,0,0]<4:2,1,1,3>' : 'low2', '#SceneAct[4:0,0,0,1]' : 'med2', '#SceneAct[4:1,0,0,0]': 'low1', '#SceneAct[4:1,0,0,1]': 'med1', '#SceneAct[4:1,0,0,2]': 'high1', '#SceneAct[4:0,0,0,2]': 'high2'}\n",
    "    sceneKey_ge = {'#SceneGe[4:0,0,0,0]<4:2,1,1,3>' : 'low2 Ge', '#SceneGe[4:0,0,0,1]' : 'med2 Ge', '#SceneGe[4:1,0,0,0]': 'low1 Ge', '#SceneGe[4:1,0,0,1]': 'med1 Ge', '#SceneGe[4:1,0,0,2]': 'high1 Ge', '#SceneGe[4:0,0,0,2]': 'high2 Ge'}\n",
    "    sceneKeyM = {'#SceneActM[4:0,0,0,0]<4:2,1,1,3>' : 'low2_ActM', '#SceneActM[4:0,0,0,1]' : 'med2_ActM', '#SceneActM[4:1,0,0,0]': 'low1_ActM', '#SceneActM[4:1,0,0,1]': 'med1_ActM', '#SceneActM[4:1,0,0,2]': 'high1_ActM', '#SceneActM[4:0,0,0,2]': 'high2_ActM'}\n",
    "    \n",
    "sceneKey_AvgSLrn = {key.replace(\"Act\", \"AvgSLrn\"): value for key, value in sceneKey.items()}\n",
    "\n",
    "    \n",
    "nepochs = max(data_test['|Epoch'])\n",
    "nruns = max(data_test[data_test['|Epoch']==nepochs]['|Run']) # only get maximum run that reached the end. \n",
    "\n",
    "try: \n",
    "    epoch_end_ColorWOOsc = max(data_test[data_test['$CurrentTask'] == 'TaskColorWOOsc']['|Epoch'])\n",
    "except:\n",
    "    epoch_end_ColorWOOsc = 0\n",
    "    print('could not find any ColorWOOSC trials. May want to check this out.')\n",
    "\n",
    "# epoch_end_Scene = max(data_test[data_test['$CurrentTask'] == 'TaskSceneRecall']['|Epoch'])\n",
    "# epoch_end_initial = max(epoch_end_ColorWOOsc,epoch_end_Scene)\n",
    "epoch_end_initial = -1 # was epoch_end_ColorWOOsc\n",
    "\n",
    "if (numPairs == 2) :\n",
    "    scene_palette = {'small1' : (0.6, .3, .6), \n",
    "                       'small2' : (0.8, .5, .8), \n",
    "                       'small3' : (0.3, .5, .6),\n",
    "                       'small4' : (0.5, .7, .8)}\n",
    "\n",
    "    scene_palette_ge = {'small1 Ge' : (0.6, .3, .6), \n",
    "                       'small2 Ge' : (0.8, .5, .8), \n",
    "                       'small3 Ge' : (0.3, .5, .6),\n",
    "                       'small4 Ge' : (0.5, .7, .8)}\n",
    "    \n",
    "    hidden_palette = {'small1' : (0.6, .3, .6), \n",
    "                      'small2' : (0.8, .5, .8), \n",
    "                      'small12': (1, .7, 1),\n",
    "                      'small3' : (0., .5, .6),\n",
    "                      'small4' : (0.5, .7, .8),\n",
    "                      'small34' : (0.6, .85, .95),\n",
    "                      'cross-pair': (.7, .5, .5),\n",
    "                     'not active': (0.5, .5, .5)\n",
    "                     }\n",
    "    hidd_order=[\"small1\", \"small2\", \"small12\", 'small3','small4','small34','cross-pair', 'not active']\n",
    "    \n",
    "elif (numPairs == 3) :\n",
    "    scene_palette = {'low1' : (0.6, .3, .6), \n",
    "                   'low2' : (0.8, .5, .8), \n",
    "                   'med1' : (0.2, .3, .6),\n",
    "                   'med2' : (0.4, .5, .8),\n",
    "                   'high1': (.4, .7, .4),\n",
    "                   'high2' : (.6, .9, .6)}\n",
    "\n",
    "    scene_palette_ge = {'low1 Ge' : (0.6, .3, .6), \n",
    "                   'low2 Ge' : (0.8, .5, .8), \n",
    "                   'med1 Ge' : (0.2, .3, .6),\n",
    "                   'med2 Ge' : (0.4, .5, .8),\n",
    "                   'high1 Ge': (.4, .7, .4),\n",
    "                   'high2 Ge' : (.6, .9, .6)}\n",
    "    \n",
    "    category_palette = {'low' : (.7, .4, .7),\n",
    "                       'med': (.3, .4, .7),\n",
    "                       'high': (.5, .8, .5)}\n",
    "    hidden_palette = {'low1' : (0.6, .3, .6), \n",
    "                      'low2' : (0.8, .5, .8), \n",
    "                      'low1+2': (1, .7, 1),\n",
    "                      'med1' : (0.2, .3, .6),\n",
    "                      'med2' : (0.4, .5, .8),\n",
    "                      'med1+2' : (0.6, .7, .9),\n",
    "                      'high1' : (0.4, .7, .4),\n",
    "                      'high2' : (0.6, .9, .6),\n",
    "                      'high1+2' : (0.8, 1, .8),\n",
    "                      'cross-pair': (.7, .5, .5),\n",
    "                     'not active': (0.5, .5, .5)\n",
    "                     }\n",
    "    \n",
    "    correl_palette = {'high1-high2': (.5, .8, .5),\n",
    "                      'med1-med2' : (0.6, .7, .9),\n",
    "                      'low1-low2' : (.7, .4, .7),\n",
    "                      'across': (.7, .5, .5)\n",
    "        \n",
    "    }\n",
    "\n",
    "    hidd_order=[\"low1\", \"low2\", \"low1+2\", 'med1','med2','med1+2','high1','high2','high1+2','cross-pair', 'not active']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getKeysByValue(dictOfElements, valueToFind):\n",
    "    listOfKeys = list()\n",
    "    listOfItems = dictOfElements.items()\n",
    "    for item  in listOfItems:\n",
    "        if item[1] == valueToFind:\n",
    "            listOfKeys.append(item[0])\n",
    "    return  listOfKeys\n",
    "\n",
    "def competitor_trial(trial_name) :\n",
    "# if you have med1 as an input argument, it will return med2\n",
    "\n",
    "    overlap_type = trial_name[:-1]\n",
    "    pair_unit = int(trial_name[-1])\n",
    "    other_unit = pair_unit % 2 + 1\n",
    "    other_trial = overlap_type + str(other_unit)\n",
    "    return other_trial\n",
    "\n",
    "def get_parameter_values():\n",
    "    params_file = dataDir + \"favila_Base_Params_TaskColorRecall.csv\"\n",
    "    Layer_ThrP_NMPH_dict = {}\n",
    "    Layer_Drev_dict = {}\n",
    "    Layer_DThr_dict = {}\n",
    "    LTD_mult_TaskColorRecall = None\n",
    "    Layer_OscAmnt_dict = {}\n",
    "    Layer_Gi_dict = {}\n",
    "    overlap_dict = {}\n",
    "    \n",
    "    parameter_values = {}\n",
    "\n",
    "    with open(params_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if line[:6] == \"Layer:\": # get layer name\n",
    "                layername = line.split(\" \")[-1][:-1]\n",
    "\n",
    "            if line[:5] == \"Prjn:\": # get layer name\n",
    "                prjnname = line.split(\" \")[-1][:-1]\n",
    "                \n",
    "\n",
    "                \n",
    "            if \"OscAmnt\" in line: # get oscAmnt\n",
    "                Layer_OscAmnt_dict[layername] = float(line.split(\" \")[-2])\n",
    "            if \"Layer\" in line and \"Gi\" in line:\n",
    "                Layer_Gi_dict[layername] = float(line.split(\" \")[9])\n",
    "                \n",
    "            if \"ThrP_NMPH\" in line: # get AveL value (only occurs 4 times in csv file)\n",
    "                Layer_ThrP_NMPH_dict[prjnname] = float(line.split(\" \")[-8])\n",
    "            if \"DRev_NMPH\" in line: # get AveL value (only occurs 4 times in csv file)\n",
    "                Layer_Drev_dict[prjnname] = float(line.split(\" \")[-20])\n",
    "            if (LTD_mult_TaskColorRecall == None) and ('LTD_mult' in line):\n",
    "                LTD_mult_TaskColorRecall = float(line.split(\" \")[-2])\n",
    "            if \"DThr_NMPH\" in line:\n",
    "                Layer_DThr_dict[prjnname] = float(line.split(\" \")[-23])\n",
    "                \n",
    "            if 'SameDiffCondition' in line:\n",
    "                if prjnname == 'HiddenToOutput':\n",
    "                        line_split = line.split(\" \")\n",
    "                        overlap_dict['same_diff_condition'] = str(line_split[[i for i, x in enumerate(line_split) if \"SameDiffCondition\" in x][0] + 1])\n",
    "\n",
    "\n",
    "    params_file = dataDir + \"favila_Base_Params_TaskColorRecall.csv\"\n",
    "    Color_to_Hidden_wt_scale = {}\n",
    "    with open(params_file, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if line[:5] == \"Prjn:\": # get layer name\n",
    "                prjnname = line.split(\" \")[-1][:-1]\n",
    "            if \"Rel:\" in line: # get AveL value (only occurs 4 times in csv file)\n",
    "                Color_to_Hidden_wt_scale[prjnname] = float(line.split(\" \")[-1])\n",
    "            if \"NumOverlapUnits\" in line:\n",
    "                line_split = line.split(\" \")\n",
    "                overlap_dict['numOverlapUnits'] = int(line_split[[i for i, x in enumerate(line_split) if \"NumOverlapUnits\" in x][0] + 1])\n",
    "                overlap_dict['numTotalUnits'] = int(line_split[[i for i, x in enumerate(line_split) if \"NumTotalUnits\" in x][0] + 1])\n",
    "                overlap_dict['overlapType'] = str(overlap_dict['numOverlapUnits']) + '/' + str(overlap_dict['numTotalUnits'])\n",
    "\n",
    "    parameter_values['ThrP_NMPH'] = Layer_ThrP_NMPH_dict\n",
    "    parameter_values['DRev_NMPH'] = Layer_Drev_dict\n",
    "    parameter_values['DThr_NMPH'] = Layer_DThr_dict\n",
    "\n",
    "    parameter_values['LTD_mult'] = LTD_mult_TaskColorRecall\n",
    "    parameter_values['Wt_Scale'] = Color_to_Hidden_wt_scale\n",
    "    parameter_values['OscAmnt'] = Layer_OscAmnt_dict\n",
    "    parameter_values['Gi'] = Layer_Gi_dict\n",
    "    \n",
    "    parameter_values['Num_units_per_layer'] = {\n",
    "        'Object': 2, 'Scene': 6, 'Output': 50\n",
    "    }\n",
    "    if hidden_dimensions == 1:\n",
    "        parameter_values['Num_units_per_layer']['Hidden'] = 50\n",
    "    elif hidden_dimensions == 2:\n",
    "        parameter_values['Num_units_per_layer']['Hidden'] = 100\n",
    "\n",
    "    parameter_values['overlap'] = overlap_dict\n",
    "    return parameter_values\n",
    "\n",
    "# def get_parameter_values():\n",
    "#     params_file = dataDir + \"output_diff_Base_Params_TaskColorWOOsc.csv\"\n",
    "#     Color_to_Hidden_wt_scale = {}\n",
    "\n",
    "#     with open(params_file, 'r') as f:\n",
    "#         for line in f.readlines():\n",
    "#             if line[:5] == \"Prjn:\": # get layer name\n",
    "#                 prjnname = line.split(\" \")[-1][:-1]\n",
    "#             if \"Rel:\" in line: # get AveL value (only occurs 4 times in csv file)\n",
    "#                 Color_to_Hidden_wt_scale[prjnname] = float(line.split(\" \")[-1])\n",
    "\n",
    "#     parameter_values = {}\n",
    "#     parameter_values['Wt_Scale'] = Color_to_Hidden_wt_scale\n",
    "#     return parameter_values\n",
    "\n",
    "\n",
    "parameter_values = get_parameter_values() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_train.loc[:, slice(output_to_hidden_DWt_Start, output_to_hidden_DWt_End)].to_numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_train.loc[:, slice(hidden_to_output_DWt_Start, hidden_to_output_DWt_End)].to_numpy().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data_train.loc[:, slice(scene_to_hidden_DWt_Start, scene_to_hidden_DWt_End)].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re arranging data\n",
    "<a id='Rearranging_data'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Stacked Test and Cycle data\n",
    "Most of the analyses can be done with these two stacked dataframes. They're arranged so that the columns are the 4 trials, and all the values for each trial are in rows. \n",
    "\n",
    "It's a hierarchical dataframe, with multiple indices\n",
    "\n",
    "for data_test_stacked, the indices are Run, |Epoch, $CurrentTask, and then a column for all the value names. NOTE-- NEED TO ADD IN TITLE FOR THAT COLUMN. \n",
    "\n",
    "for data_test_stacked, the indices are Run, |Epoch, |Cycle, $CurrentTask, and then a column for all the value names. NOTE-- NEED TO ADD IN TITLE FOR THAT COLUMN. \n",
    "\n",
    "You can get a subset by using .loc with each index. i.e.\n",
    "#### To get the hidden layer activity in the final task for just the first (0th) run, that would be:\n",
    "    data_test_stacked.loc[('0', 'TaskColorRecall', slice(hidden_Start, hidden_End)),:]\n",
    "    \n",
    "#### To get the output layer activity in the baseline task for EACH run, that would be:\n",
    "    data_test_stacked.loc[(slice(None), 'TaskColorWOOsc', slice(outputM_Start, outputM_End)),:]\n",
    "    \n",
    "#### To get the SSE in the final task for EACH run, that would be:\n",
    "    data_test_stacked.loc[(slice(None), 'TaskColorRecall', '#SSE'),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codeprofiler.enable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (test_cycle_done == 1) :\n",
    "    #make stacked data for cycles. Explanation below.\n",
    "    data_tst_cyc_stacked = data_tst_cyc.set_index(['|Run', '|Epoch', '|Cycle', '$TrialName', '$CurrentTask', '$CurrentTest']).stack().unstack(level='$TrialName')\n",
    "    data_tst_cyc_stacked.index.names = ['|Run', '|Epoch', '|Cycle', '$CurrentTask', '$CurrentTest','key']\n",
    "\n",
    "    data_tst_cyc_stacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (train_cycle_done == 1 ) :\n",
    "    #make stacked data for cycles. Explanation below.\n",
    "    data_trn_cyc_stacked = data_trn_cyc.set_index(['|Run', '|Epoch', '|Cycle', '$TrialName', '$CurrentTask']).stack().unstack(level='$TrialName')\n",
    "    data_trn_cyc_stacked.index.names = ['|Run', '|Epoch', '|Cycle', '$CurrentTask', 'key']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (test_trial_done == 1) :\n",
    "    #make stacked data. Explanation below.\n",
    "    data_test_stacked = data_test.set_index(['|Run', '|Epoch', '$TrialName', '$CurrentTask', '$CurrentTest']).stack().unstack(level='$TrialName')\n",
    "\n",
    "    data_test_stacked.head()\n",
    "    data_test_stacked.index.names = ['|Run', '|Epoch', '$CurrentTask', '$CurrentTest', 'key']\n",
    "    # data_test_stacked = pd.DataFrame(currData.stack())# data_test_stacked.index.names = ['|Run', '|Epoch', '$CurrentTask', 'key']\n",
    "    data_test_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[data_test.duplicated(subset= ['|Run','|Epoch','$CurrentTask', '$TrialName'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = data_test.set_index(['|Run', '|Epoch', '$TrialName', '$CurrentTask', '$CurrentTest']).stack().reset_index()\n",
    "b = data_train_stacked = data_train.set_index(['|Run', '|Epoch', '$TrialName', '$CurrentTask']).stack().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[a['level_5'] == '#Hidden_ActM.Avg'].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[b['level_4'] == '#Hidden_ActM.Avg'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (train_trial_done == 1) :\n",
    "    #make stacked data. Explanation below.\n",
    "    data_train_stacked = data_train.set_index(['|Run', '|Epoch', '$TrialName', '$CurrentTask']).stack().unstack(level='$TrialName')\n",
    "\n",
    "    data_train_stacked.head()\n",
    "    data_train_stacked.index.names = ['|Run', '|Epoch', '$CurrentTask', 'key']\n",
    "    data_train_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_stacked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make stacked data epoch. Explanation below.\n",
    "\n",
    "data_epc_stacked = pd.DataFrame(data_epc.set_index(['|Run', '|Epoch', '$CurrentTask']).stack())\n",
    "data_epc_stacked.index.names = ['|Run', '|Epoch', '$CurrentTask','key']\n",
    "data_epc_stacked.rename(columns = {0: 'value'});\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Some potentially useful other ways of arranging the test data\n",
    "#### Really this can be updated, but these dfs were made first for some of the correlation analyses...\n",
    "\n",
    "# get the task specific data\n",
    "\n",
    "#data after outputs are learned:\n",
    "data_baseline_all = data_test[data_test['$CurrentTask'] == 'TaskColorWOOsc']\n",
    "\n",
    "## get just the last epoch for this task\n",
    "data_baseline = data_test[(data_test['$CurrentTask'] == 'TaskColorWOOsc') & (data_test['|Epoch'] == epoch_end_initial)]\n",
    "\n",
    "#data after oscillations:\n",
    "\n",
    "data_final_all = data_test[data_test['$CurrentTask'] == 'TaskColorRecall']\n",
    "\n",
    "## get just the last epoch for this task\n",
    "try:\n",
    "    max_final_epoch = max(data_test[data_test['$CurrentTask'] == 'TaskColorRecall']['|Epoch'])\n",
    "except: ## sometimes we don't have TaskColorRecall for testing purposes\n",
    "    traceback.print_exc()\n",
    "\n",
    "    max_final_epoch = max(data_test[data_test['$CurrentTask'] == 'TaskColorWOOsc']['|Epoch'])\n",
    "data_final = data_test[(data_test['$CurrentTask'] == 'TaskColorRecall') & (data_test['|Epoch'] == max_final_epoch)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET ORDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Get the initial order: \n",
    "\n",
    "data_train_order = data_train.copy()\n",
    "data_train_order= data_train_order[['|Run','|Epoch', '$CurrentTask', '|Trial', '$TrialName']]\n",
    "data_train_order = data_train_order[data_train_order['$CurrentTask'] == 'TaskColorRecall']\n",
    "data_train_order = data_train_order[data_train_order['$TrialName'].isin(['med1','med2'])]\n",
    "\n",
    "data_train_order = data_train_order[data_train_order['|Epoch'] == min(data_train_order['|Epoch']) ]\n",
    "print(data_train_order)\n",
    "\n",
    "order_map_dict = {0: 'first', 1:'second'}\n",
    "data_train_order['order'] = data_train_order['|Trial'].map(order_map_dict)\n",
    "data_train_order = data_train_order[['|Run', '$TrialName', 'order']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Analyses\n",
    "<a id='Start_Analyses'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoints_df = pd.DataFrame(columns = ['checkpoint', 'TF', 'Value', 'Info'])\n",
    "results_df = pd.DataFrame(columns = ['result', 'TF', 'Value', 'Info'])\n",
    "analyses_df = pd.DataFrame(columns = ['analysis', 'TF', 'Info'])\n",
    "    \n",
    "def add_analysis_to_analyses_df(analyses_df, title, true_or_false, info = \"\"):\n",
    "    \"\"\"\n",
    "    First argument: analyses_df data frame\n",
    "    Second argument: name of the analysis that was executed\n",
    "    Third argument: whether the analysis succeeded\n",
    "    Fourth argument: info -- any extra information can be added as a string\n",
    "    \"\"\"\n",
    "    temp_series = pd.Series([title, true_or_false, \"\"], index = analyses_df.columns)\n",
    "    return analyses_df.append(temp_series, ignore_index = True)\n",
    "    \n",
    "    \n",
    "# temp = ['first', True, .5]\n",
    "# temp_series = pd.Series(temp, index = results_df.columns)\n",
    "# temp_series\n",
    "# results_df.append(temp_series, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Accuracy (SSE ) over time\n",
    "<a id='Learning_Accuracy_SSE_over_time'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotSSE(data, taskType, testOrTrain, palette_type, analyses_df):\n",
    "    title = 'SSE in Output Layer During ' + testOrTrain.capitalize() + 'ing'\n",
    "    try:\n",
    "        if (testOrTrain == 'Test') :\n",
    "            currData = data.loc[(slice(None), slice(None), slice(None),taskType, '#Output_AvgSSE'),:]\n",
    "\n",
    "        elif (testOrTrain == 'Train') :\n",
    "            currData = data.loc[(slice(None), slice(None), taskType, '#Output_AvgSSE'),:]\n",
    "\n",
    "\n",
    "        currData = pd.DataFrame(currData.stack()) # get a column of just the SSE\n",
    "        currData = currData.rename(columns = {0: 'SSE'})\n",
    "        currData = currData.reset_index()\n",
    "\n",
    "        print(currData['$CurrentTask'].unique())\n",
    "        plt.clf\n",
    "        plt.axhline(y=0, color='k', linestyle='-')\n",
    "\n",
    "        g = sns.lineplot(x=\"|Epoch\", y=\"SSE\", palette = palette_type,\n",
    "               data=currData)\n",
    "\n",
    "    #     g.set_ylim(-1, 1)\n",
    "\n",
    "\n",
    "        if (taskType == 'TestColorAll') or (taskType == 'TaskColorWOOsc') or (taskType == 'TaskColorRecall'):\n",
    "            learningType = 'Color'\n",
    "        elif (taskType == 'TestSceneAll') or (taskType == 'TaskSceneRecall') :\n",
    "            learningType = 'Scene'\n",
    "\n",
    "\n",
    "        minX = min(data.index.levels[1])\n",
    "        maxX = max(data.index.levels[1])\n",
    "\n",
    "        plt.xlim(minX,maxX)\n",
    "        plt.ylim(0, 2)\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.savefig(checkpoint_fig_dir + title +'.png', bbox_inches = \"tight\")\n",
    "        plt.show()\n",
    "        \n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, True) \n",
    "\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) \n",
    "    return analyses_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Look at SSE split by overlap type\n",
    "def plotSSEbyCat(data, testOrTrain, palette_type, analyses_df) :\n",
    "    title = 'SSE in Output Layer During ' + testOrTrain.capitalize() + 'ing by Overlap'\n",
    "    try:\n",
    "        if testOrTrain == 'train' :\n",
    "            sse = data.loc[idx[:,:,:,'#Output_AvgSSE'],:].reset_index().drop(columns= 'key')\n",
    "        elif testOrTrain == 'test' :\n",
    "            sse = data.loc[idx[:,:,:,'TestColorAll', '#Output_AvgSSE'],:].reset_index().drop(columns= ['$CurrentTest','key'])\n",
    "\n",
    "    #     sse = sse.reset_index().drop(columns= 'key')\n",
    "        sse_melt = pd.melt(sse, id_vars = ['|Run', '|Epoch', '$CurrentTask'], var_name = 'trial_type', value_name = 'SSE')\n",
    "\n",
    "        sse_melt['Overlap'] = sse_melt.trial_type.str[:-1]\n",
    "\n",
    "        g = sns.lineplot(x = '|Epoch', y = 'SSE', hue = 'Overlap', palette = palette_type, data = sse_melt)\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.xlim(-1,40)\n",
    "        plt.savefig(checkpoint_fig_dir + title +'.png', bbox_inches = \"tight\")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, True)\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, False)\n",
    "    return analyses_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data_train_stacked\n",
    "testOrTrain = 'train'\n",
    "palette_type = category_palette\n",
    "if testOrTrain == 'train' :\n",
    "    sse = data.loc[idx[:,:,:,'#Output_AvgSSE'],:].reset_index().drop(columns= 'key')\n",
    "elif testOrTrain == 'test' :\n",
    "    sse = data.loc[idx[:,:,:,'TestColorAll', '#Output_AvgSSE'],:].reset_index().drop(columns= ['$CurrentTest','key'])\n",
    "\n",
    "#     sse = sse.reset_index().drop(columns= 'key')\n",
    "sse_melt = pd.melt(sse, id_vars = ['|Run', '|Epoch', '$CurrentTask'], var_name = 'trial_type', value_name = 'SSE')\n",
    "\n",
    "# sse_melt['Overlap'] = sse_melt.trial_type.str[:-1]\n",
    "\n",
    "# sse_melt\n",
    "# g = sns.lineplot(x = '|Epoch', y = 'SSE', hue = 'Overlap', palette = palette_type, data = sse_melt)\n",
    "# title = 'SSE in Output Layer During ' + testOrTrain.capitalize() + 'ing by Overlap'\n",
    "# plt.title(title)\n",
    "# plt.ylim(0, 1)\n",
    "# plt.savefig(checkpoint_fig_dir + title +'.png', bbox_inches = \"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = data_train_stacked\n",
    "testOrTrain = 'train'\n",
    "palette_type = category_palette\n",
    "if testOrTrain == 'train' :\n",
    "    sse = data.loc[idx[:,:,:,'#Output_AvgSSE'],:].reset_index().drop(columns= 'key')\n",
    "elif testOrTrain == 'test' :\n",
    "    sse = data.loc[idx[:,:,:,'TestColorAll', '#Output_AvgSSE'],:].reset_index().drop(columns= ['$CurrentTest','key'])\n",
    "\n",
    "#     sse = sse.reset_index().drop(columns= 'key')\n",
    "sse_melt = pd.melt(sse, id_vars = ['|Run', '|Epoch', '$CurrentTask'], var_name = 'trial_type', value_name = 'SSE')\n",
    "\n",
    "# sse_melt['Overlap'] = sse_melt.trial_type.str[:-1]\n",
    "\n",
    "# sse_melt\n",
    "# g = sns.lineplot(x = '|Epoch', y = 'SSE', hue = 'Overlap', palette = palette_type, data = sse_melt)\n",
    "# title = 'SSE in Output Layer During ' + testOrTrain.capitalize() + 'ing by Overlap'\n",
    "# plt.title(title)\n",
    "# plt.ylim(0, 1)\n",
    "# plt.savefig(checkpoint_fig_dir + title +'.png', bbox_inches = \"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyses_df = plotSSEbyCat(data_train_stacked, 'train', category_palette, analyses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyses_df = plotSSEbyCat(data_test_stacked, 'test', category_palette, analyses_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotSSE(data_test_stacked, 'TestSceneAll', 'Test', scene_palette, analyses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotSSE(data_test_stacked, 'TestColorAll', 'Test', scene_palette, analyses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if study_task_run == 1:\n",
    "    analyses_df = plotSSE(data_train_stacked, 'TaskColorWOOsc', 'Train', scene_palette, analyses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotSSE(data_train_stacked, 'TaskSceneRecall', 'Train', scene_palette, analyses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyses_df = plotSSE(data_train_stacked, 'TaskColorRecall', 'Train', scene_palette, analyses_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print checkpoint\n",
    "<a id='Checkpoint_0:_istheoutputoutputshowncorrectlythroughoutthelearningtask'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checkpoint 0: is the output output shown correctly throughout the learning task\n",
    "\n",
    "if study_task_run == 1 :\n",
    "    sse = data_train_stacked.loc[idx[:,:,:,'#Output_AvgSSE'],:]\n",
    "    sse_mean_task = sse.groupby('$CurrentTask').mean()\n",
    "\n",
    "    baseline_SSE = sse_mean_task.loc['TaskColorWOOsc']\n",
    "    print(baseline_SSE.mean())\n",
    "\n",
    "    if baseline_SSE.mean() < .001 :\n",
    "        checkpoint_TF = True\n",
    "    else :\n",
    "        checkpoint_TF = False\n",
    "    temp = ['Scene SSE train', checkpoint_TF, baseline_SSE.mean(), 'is the output output shown correctly throughout the learning task - value ']\n",
    "    temp_series = pd.Series(temp, index = checkpoints_df.columns)\n",
    "    checkpoints_df = checkpoints_df.append(temp_series, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#checkpoint 1 : is the object input correctly shown throughout the learning and recall phase?\n",
    "## ADD THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sse = data_train_stacked.loc[idx[:,:,:,'#Category_AvgSSE'],:]\n",
    "# sse_mean_task = sse.groupby('$CurrentTask').mean()\n",
    "sse_mean = sse.mean(axis = 1).mean(axis = 0)\n",
    "sse_mean \n",
    "\n",
    "if sse_mean < .001 :\n",
    "    checkpoint_TF = True\n",
    "else :\n",
    "    checkpoint_TF = False\n",
    "temp = ['Category SSE train', checkpoint_TF, sse_mean, 'is the object input correctly shown throughout the learning and recall phase?']\n",
    "temp_series = pd.Series(temp, index = checkpoints_df.columns)\n",
    "checkpoints_df = checkpoints_df.append(temp_series, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#checkpoint 2: is the scene input correctly shown throughout the learning and recall phase?\n",
    "## ADD THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sse = data_train_stacked.loc[idx[:,:,:,'#Scene_AvgSSE'],:]\n",
    "# sse_mean_task = sse.groupby('$CurrentTask').mean()\n",
    "sse_mean = sse.mean(axis = 1).mean(axis = 0)\n",
    "sse_mean \n",
    "\n",
    "if sse_mean < .001 :\n",
    "    checkpoint_TF = True\n",
    "else :\n",
    "    checkpoint_TF = False\n",
    "temp = ['scene SSE train', checkpoint_TF, sse_mean, 'is the scene input correctly shown throughout the learning and recall phase?']\n",
    "temp_series = pd.Series(temp, index = checkpoints_df.columns)\n",
    "checkpoints_df = checkpoints_df.append(temp_series, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#checkpoint 3: are the outputs learned by the end of the study phase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if study_task_run == 1 :\n",
    "    sse = data_test_stacked.loc[idx[:,epoch_end_initial,'TaskColorWOOsc', 'TestColorAll','#Output_AvgSSE'],:]\n",
    "\n",
    "    final_learning_SSE_per_run = sse.mean(axis = 1)\n",
    "    final_learning_SSE = final_learning_SSE_per_run.mean()\n",
    "    print(final_learning_SSE)\n",
    "\n",
    "    if final_learning_SSE < .015 :\n",
    "        checkpoint_TF = True\n",
    "    else :\n",
    "        checkpoint_TF = False\n",
    "    temp = ['scene learned at baseline', checkpoint_TF, final_learning_SSE, 'are the scenes learned by the end of the study phase?']\n",
    "    temp_series = pd.Series(temp, index = checkpoints_df.columns)\n",
    "    checkpoints_df = checkpoints_df.append(temp_series, ignore_index=True)\n",
    "\n",
    "    checkpoints_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the output layer at each epoch\n",
    "<a id='Visualizetheoutputlayerateachepoch'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def prep_output_output_test(data, name, test_or_train, filter_outM, run) : \n",
    "    #run can be 'all' or a specific integer for a run to look at. \n",
    "    \n",
    "    if name == 'TestColorAll' :\n",
    "        data = data.loc[(slice(None), slice(None), slice(None), name, filter_outM),:]\n",
    "    elif name == 'TaskColorRecall' :\n",
    "\n",
    "\n",
    "        data = data.loc[(slice(None), slice(None), name, filter_outM),:]\n",
    "\n",
    "\n",
    "    data = data.reset_index()\n",
    "\n",
    "    if (run == 'all') :\n",
    "\n",
    "        data = data.groupby(['|Epoch', 'key']).mean().drop(['|Run'], axis = 1).stack().unstack('key')\n",
    "\n",
    "    else : ## specific run\n",
    "\n",
    "        data = data[data['|Run'] == run]\n",
    "        data = data.drop(columns= ['|Run', '$CurrentTask', test_or_train])\n",
    "        data = data.set_index(['|Epoch', 'key']).stack().unstack(level = 'key')\n",
    "\n",
    "    data = data[filter_outM] #put columns back in the correct order\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "# # plot the output layer at test\n",
    "# for stim in stim_names :\n",
    "#     data = prep_output_output_test(data_test_stacked, 'TestColorAll', '$CurrentTest', filter_outM, 'all')\n",
    "#     plt.figure(figsize=(6,6))\n",
    "#     plt.imshow(data.loc[(slice(None), stim),:])\n",
    "#     title = 'Output Representation Over Time: ' + stim.capitalize()\n",
    "#     plt.title(title)\n",
    "#     plt.ylabel('Epoch #')\n",
    "#     plt.xlabel('Output Layer Unit #')\n",
    "#     plt.savefig(results_fig_dir + title + '.png', bbox_inches = \"tight\")\n",
    "#     plt.show()\n",
    "#     analyses_df = add_analysis_to_analyses_df(analyses_df, title, True)\n",
    "\n",
    "\n",
    "\n",
    "# for stim in stim_names :\n",
    "#     data = prep_output_output_test(data_train_stacked, 'TaskColorRecall', '$CurrentTask', filter_outM, 'all')\n",
    "#     plt.figure(figsize=(6,6))\n",
    "#     plt.imshow(data.loc[(slice(None), stim),:])\n",
    "#     title = 'Output Representation Over Time: ' + stim.capitalize()\n",
    "#     plt.title(title)\n",
    "#     plt.ylabel('Epoch #')\n",
    "#     plt.xlabel('Output Layer Unit #')\n",
    "#     plt.savefig(results_fig_dir + title + '.png', bbox_inches = \"tight\")\n",
    "#     plt.show()\n",
    "#     analyses_df = add_analysis_to_analyses_df(analyses_df, title, True)\n",
    "\n",
    "filter_HiddM\n",
    "filter_out_AvgSLrn\n",
    "# plot the output layer at train\n",
    "\n",
    "def plot_visual_layer(runN, analyses_df, all_epochs = True):\n",
    "    try: \n",
    "        \n",
    "        for type_run in ['Train', 'Test'] :\n",
    "            print('------------------')\n",
    "            if type_run == 'Test' :\n",
    "                data_t= data_test_stacked\n",
    "                name = 'TestColorAll'\n",
    "                test_or_train = '$CurrentTest'\n",
    "            elif type_run == 'Train' :\n",
    "                data_t = data_train_stacked\n",
    "                name = 'TaskColorRecall'\n",
    "                test_or_train = '$CurrentTask'\n",
    "\n",
    "            for layer in ['Output', 'Hidden'] : \n",
    "                if layer == 'Output' :\n",
    "                    if type_run == 'Train' :\n",
    "                        units = filter_outP\n",
    "                    else:\n",
    "                        units = filter_outM\n",
    "                elif layer == 'Hidden' :\n",
    "                    if type_run == 'Train' :\n",
    "                        units = filter_HiddenP\n",
    "                    else:\n",
    "                        units = filter_HiddM\n",
    "\n",
    "                for stim in stim_names :\n",
    "                    data = prep_output_output_test(data_t, name, test_or_train, units, runN)\n",
    "                    plt.figure(figsize=(6,6))\n",
    "                    plt.clf()\n",
    "                    \n",
    "                    if all_epochs==False:\n",
    "                        min_epoch = data.reset_index()['|Epoch'].min()\n",
    "                        max_epoch = data.reset_index()['|Epoch'].max()\n",
    "\n",
    "                        plt.imshow(data.loc[([min_epoch,max_epoch], stim),:])\n",
    "                        plt.colorbar()\n",
    "\n",
    "                    if all_epochs==True:\n",
    "                        plt.imshow(data.loc[(slice(None), stim),:])\n",
    "                    title = layer + ' Over Time: ' + type_run + ': ' + stim.capitalize()\n",
    "                    plt.title(title)\n",
    "                    plt.ylabel('Epoch #')\n",
    "                    plt.xlabel(layer + ' Layer Unit #')\n",
    "                    plt.tight_layout()\n",
    "                    \n",
    "                    \n",
    "                    if all_epochs ==True:\n",
    "                        \n",
    "                        plt.savefig(results_fig_dir + title + '.pdf', bbox_inches = \"tight\")\n",
    "                    else:\n",
    "                        plt.savefig(eps_dir + 'run '+ str(runN) + title + '.eps', bbox_inches = \"tight\")\n",
    "\n",
    "                    if from_cmdLine != 'cmd' :\n",
    "                        plt.show()\n",
    "                    analyses_df = add_analysis_to_analyses_df(analyses_df, title, True)\n",
    "\n",
    "                    if layer == 'Hidden' :\n",
    "                        if type_run == 'Test':\n",
    "                            data2 = data\n",
    "                    plt.close()\n",
    "                            \n",
    "                    \n",
    "\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) \n",
    "    return analyses_df\n",
    "\n",
    "\n",
    "plot_visual_layer('all', analyses_df, all_epochs = True)\n",
    "\n",
    "if nruns < 10:\n",
    "    num_runs_to_save_act = nruns\n",
    "    \n",
    "else:\n",
    "    num_runs_to_save_act = 10\n",
    "\n",
    "for r in range(num_runs_to_save_act):\n",
    "    plot_visual_layer(r, analyses_df, all_epochs = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Analysis\n",
    "<a id='Correlation_AnalysisFirstsetupcorrelationmatricesforfinalepochineachtask'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First set up correlation matrices for final epoch in each task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "hiddenData = data_test_stacked.loc[(slice(None), slice(None), slice(None),slice(None),slice(hiddenM_Start, hiddenM_End)),:]\n",
    "\n",
    "outputData = data_test_stacked.loc[(slice(None),  slice(None), slice(None),slice(None), slice(outputM_Start, outputM_End)),:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Within Pair Correlation Over Time\n",
    "<a id='Plot_Within_Pair_Correlation_Over_Time'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_corr_long(dataframe, LayerType, testType, numPairs) :\n",
    "\n",
    "    df = dataframe.loc[(slice(None),  slice(None), slice(None),slice(testType), slice(None)),:]\n",
    "    df_corr = df.groupby(['|Run','|Epoch','$CurrentTask', '$CurrentTest']).corr()\n",
    "\n",
    "    df_corr.index.names = ['|Run', '|Epoch', '$CurrentTask', '$CurrentTest', 'firstItem']\n",
    "    df_corr_long = pd.DataFrame(df_corr.stack())\n",
    "    df_corr_long.head()\n",
    "    df_corr_long.index.names = ['|Run', '|Epoch', '$CurrentTask','$CurrentTest', 'firstItem', 'secondItem']\n",
    "    df_corr_long = df_corr_long.rename(columns = {0: 'correlation'})\n",
    "    df_corr_long = df_corr_long.reset_index()\n",
    "    df_corr_long['pair'] = df_corr_long[['firstItem', 'secondItem']].apply(lambda x: '-'.join(x), axis = 1)\n",
    "\n",
    "    df_corr_long\n",
    "\n",
    "\n",
    "    if (numPairs ==2) :\n",
    "        pairtypeDict = {'small1-small1': 'identity', \n",
    "                   'small1-small2': 'within',\n",
    "                   'small1-small3': 'across',\n",
    "                   'small1-small4': 'across',\n",
    "                   'small2-small1': 'redundant',\n",
    "                   'small2-small2': 'identity',\n",
    "                   'small2-small3': 'across',\n",
    "                   'small2-small4': 'across',\n",
    "                   'small3-small1': 'redundant',\n",
    "                   'small3-small2': 'redundant',\n",
    "                   'small3-small3': 'identity',\n",
    "                   'small3-small4': 'within',\n",
    "                   'small4-small1': 'redundant',\n",
    "                   'small4-small2': 'redundant',\n",
    "                   'small4-small3': 'redundant',\n",
    "                   'small4-small4': 'identity'}\n",
    "        \n",
    "    elif (numPairs == 3) :\n",
    "        pairtypeDict = {'low1-low1': 'identity',\n",
    "                       'low1-low2': 'low1-low2',\n",
    "                       'low1-med1': 'across', \n",
    "                       'low1-med2': 'across',\n",
    "                       'low1-high1': 'across',\n",
    "                       'low1-high2': 'across',\n",
    "                       'low2-low1': 'redundant',\n",
    "                       'low2-low2': 'identity',\n",
    "                       'low2-med1': 'across',\n",
    "                       'low2-med2': 'across',\n",
    "                       'low2-high1': 'across',\n",
    "                       'low2-high2': 'across',\n",
    "                        'med1-low1': 'redundant',\n",
    "                        'med1-low2': 'redundant',\n",
    "                        'med1-med1': 'identity',\n",
    "                        'med1-med2': 'med1-med2',\n",
    "                        'med1-high1': 'across',\n",
    "                        'med1-high2': 'across',\n",
    "                        'med2-low1': 'redundant',\n",
    "                        'med2-low2': 'redundant',\n",
    "                        'med2-med1': 'redundant',\n",
    "                        'med2-med2': 'identity',\n",
    "                        'med2-high1': 'across',\n",
    "                        'med2-high2': 'across',\n",
    "                        'high1-low1': 'redundant',\n",
    "                        'high1-low2': 'redundant',\n",
    "                        'high1-med1': 'redundant',\n",
    "                        'high1-med2': 'redundant',\n",
    "                        'high1-high1': 'identity',\n",
    "                        'high1-high2': 'high1-high2',\n",
    "                        'high2-low1': 'redundant',\n",
    "                        'high2-low2': 'redundant',\n",
    "                        'high2-med1': 'redundant',\n",
    "                        'high2-med2': 'redundant',\n",
    "                        'high2-high1': 'redundant',\n",
    "                        'high2-high2': 'identity',\n",
    "                       }\n",
    "\n",
    "\n",
    "    df_corr_long['pair_type'] = df_corr_long['pair'].map(pairtypeDict)\n",
    "    return df_corr_long\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_correlation_over_time(dataframe, LayerType, testType, numPairs, analyses_df) :\n",
    "    #dataframe_corr is either outputData_corr_long or hiddenData_corr_long. \n",
    "    #layer type is for the plot title - hidden or output.\n",
    "    #testType is TestColorAll or TestSceneAll\n",
    "    \n",
    "    title = 'Pair Correlation (' + LayerType + ' Layer)'\n",
    "    try:\n",
    "        if (numPairs == 2) :\n",
    "            df_corr_long_plot = dataframe[dataframe['pair_type'].isin(['within', 'across'])]\n",
    "        elif (numPairs == 3) :\n",
    "            df_corr_long_plot = dataframe[dataframe['pair_type'].isin(['low1-low2','med1-med2', 'high1-high2', 'across'])]\n",
    "        #plot!\n",
    "    #     plt.figure(figsize=(8,8))\n",
    "        sns.set_palette(\"husl\", 2)\n",
    "\n",
    "        g = sns.lineplot(x=\"|Epoch\", y=\"correlation\",\n",
    "        hue=\"pair_type\", palette = correl_palette, \n",
    "                 data=df_corr_long_plot)\n",
    "            \n",
    "        if study_task_run == 1 :\n",
    "            g = sns.lineplot(x=\"|Epoch\", y=\"correlation\",\n",
    "                    hue=\"pair_type\",  style = \"$CurrentTask\", palette = correl_palette, \n",
    "                             data=df_corr_long_plot)\n",
    "        elif study_task_run == 0 : \n",
    "            g = sns.lineplot(x=\"|Epoch\", y=\"correlation\",\n",
    "            hue=\"pair_type\", palette = correl_palette, \n",
    "                 data=df_corr_long_plot)\n",
    "\n",
    "#         print(df_corr_long_plot.head())\n",
    "        g.set_xlabel('Time (Epoch #)')\n",
    "        g.set_ylim(-1, 1.1)\n",
    "        plt.title(title)\n",
    "        g.axhline(0, ls='-', color = 'gray')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "        plt.savefig(results_fig_dir + title + '.png', bbox_inches = \"tight\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, True) \n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) \n",
    "    return analyses_df\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_final_correlation_over_time(dataframe, LayerType, analyses_df) :\n",
    "    title = 'final within pair correlation by type : ' + LayerType + ' Layer'\n",
    "    try:\n",
    "        temp = dataframe[dataframe['pair_type'].isin(['med1-med2', 'low1-low2','high1-high2'])]\n",
    "        final_corr = temp[temp['|Epoch'] == max_final_epoch]\n",
    "    #     sns.swarmplot(x = 'pair_type', y = 'correlation', data=final_corr)\n",
    "        sns.boxplot(x = 'pair_type', y = 'correlation', order = ['low1-low2', 'med1-med2', 'high1-high2'],\n",
    "                    palette = correl_palette, data=final_corr)\n",
    "        plt.ylim(-1.1,1.1)\n",
    "        plt.axhline(0, ls='-', color ='gray')\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        sns.swarmplot(x = 'pair_type', y = 'correlation',  order = ['low1-low2', 'med1-med2', 'high1-high2'], \n",
    "                       palette = correl_palette, data=final_corr)\n",
    "        plt.ylim(-1.1,1.1)\n",
    "        plt.axhline(0, ls='-', color = 'gray')\n",
    "        title = 'final within pair correlation by type : ' + LayerType + ' Layer'\n",
    "        plt.title(title)\n",
    "        plt.savefig(results_fig_dir + title + '.png')\n",
    "        plt.show()\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, True) \n",
    "        return final_corr, analyses_df\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) \n",
    "        return \"error\", analyses_df\n",
    "    \n",
    "    \n",
    "    # sns.swarm(x=)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_within_pair_correlation(final_corr_df) :\n",
    "    \n",
    "    # this takes output_just_main_corr or hidden_just_main_corr as inputs, which are output from plot_final_correlation_over_time\n",
    "    \n",
    "    \n",
    "    \n",
    "    # high_corr = final_corr_df[final_corr_df['pair_type'] == 'high1-high2']['correlation']\n",
    "    # low_corr = final_corr_df[final_corr_df['pair_type'] == 'low1-low2']['correlation']\n",
    "    # med_corr = final_corr_df[final_corr_df['pair_type'] == 'med1-med2']['correlation']\n",
    "\n",
    "    # stats.f_oneway(high_corr, med_corr, low_corr)\n",
    "\n",
    "    ##################\n",
    "\n",
    "    mod = ols('correlation ~ C(pair_type)', data = final_corr_df).fit()\n",
    "    print(mod.summary())\n",
    "\n",
    "    print('-------------------')\n",
    "    aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "    print('HERE')\n",
    "    print(aov_table)\n",
    "\n",
    "    print('\\n\\n\\n -------------------\\n')\n",
    "    print(\"IS THERE A SIGNIFICANT DIFFERENCE BETWEEN GROUPS? \\n\\n\")\n",
    "    if aov_table.iloc[0]['PR(>F)'] < .05 :\n",
    "        print('yes, p = ' + str(aov_table.iloc[0]['PR(>F)']) +'\\n')\n",
    "\n",
    "        mc = MultiComparison(final_corr_df['correlation'], final_corr_df['pair_type'])\n",
    "        mc_results = mc.tukeyhsd()\n",
    "        print(mc_results)\n",
    "        group_diff = True\n",
    "    else :\n",
    "        print('no')\n",
    "        group_diff = False\n",
    "\n",
    "\n",
    "    #########\n",
    "    print('\\n\\n ARE THE MEAN WITHIN PAIR CORRELATIONS IN TH ORDER MED < LOW < HIGH? \\n\\n')\n",
    "    corr_mean = final_corr_df.groupby('pair_type').mean()\n",
    "\n",
    "    if corr_mean.loc['med1-med2', 'correlation'] < corr_mean.loc['low1-low2', 'correlation'] and corr_mean.loc['low1-low2', 'correlation'] < corr_mean.loc['high1-high2', 'correlation']:\n",
    "        print('yes\\n')\n",
    "        group_order = True\n",
    "    else: \n",
    "        print('no\\n')\n",
    "        sortedmeans = corr_mean.sort_values(by=['correlation']).index.get_level_values(0)\n",
    "        print(list(sortedmeans))\n",
    "        group_order = False\n",
    "\n",
    "\n",
    "    #########\n",
    "\n",
    "    high_corr = final_corr_df[final_corr_df['pair_type'] == 'high1-high2']['correlation']\n",
    "    low_corr = final_corr_df[final_corr_df['pair_type'] == 'low1-low2']['correlation']\n",
    "    med_corr = final_corr_df[final_corr_df['pair_type'] == 'med1-med2']['correlation']\n",
    "\n",
    "    if med_corr.mean() < 0 :\n",
    "        print('\\n\\n IS MEDIUM PAIR WITHIN CORRELATION SIGNIFICANTLY BELOW 0?')\n",
    "        result = stats.ttest_1samp(med_corr, 0)\n",
    "        print('t : ' + str(result[0]) + 'p : ' + str(result[1]))\n",
    "        if result[1] < .05 :\n",
    "            print('yes')\n",
    "\n",
    "        else :\n",
    "            print('no')\n",
    "\n",
    "\n",
    "    if high_corr.mean() >0 :\n",
    "        print('\\n\\n IS HIGH PAIR WITHIN CORRELATION SIGNIFICANTLY ABOVE 0?')\n",
    "        result = stats.ttest_1samp(high_corr, 0)\n",
    "        print('t : ' + str(result[0]) + 'p : ' + str(result[1]))\n",
    "        if result[1] < .05 :\n",
    "            print('yes')\n",
    "\n",
    "        else :\n",
    "            print('no')\n",
    "\n",
    "    return mod, group_diff, group_order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_correlation_comparison(dataframe, LayerType, analyses_df) :\n",
    "    try:\n",
    "        temp = dataframe[dataframe['pair_type'].isin(['med1-med2', 'low1-low2','high1-high2'])]\n",
    "        final_corr = temp[temp['|Epoch'].isin([epoch_end_initial, max_final_epoch])]\n",
    "        g = sns.FacetGrid(final_corr, col = \"pair_type\", hue = '|Run', col_order = ['low1-low2', 'med1-med2', 'high1-high2'])\n",
    "        g.map(sns.pointplot, \"|Epoch\", \"correlation\", color=\"xkcd:plum\", alpha = .5);\n",
    "\n",
    "        title = 'correlation before and after: ' + LayerType + ' Layer'\n",
    "        plt.subplots_adjust(top=0.8)\n",
    "        g.fig.suptitle(title.title()) # can also get the figure from plt.gcf()\n",
    "        axes = g.axes.flatten()\n",
    "        axes[0].set_title(\"Low\")\n",
    "        axes[1].set_title(\"Medium\")\n",
    "        axes[2].set_title(\"High\")\n",
    "        g.set(ylim=(-1.1, 1.1))\n",
    "\n",
    "        for col in range(numPairs) :\n",
    "            g.axes[0][col].axhline(y = 0, color='black', ls='--', linewidth=2, alpha=.7)\n",
    "\n",
    "        plt.savefig(results_fig_dir + title + '.png')\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        g = sns.FacetGrid(final_corr, col = \"pair_type\", col_order = ['low1-low2', 'med1-med2', 'high1-high2'])\n",
    "        g.map(sns.pointplot, \"|Epoch\", \"correlation\", color=\"xkcd:plum\");\n",
    "\n",
    "        title = 'correlation before and after Ave: ' + LayerType + ' Layer'\n",
    "        plt.subplots_adjust(top=0.8)\n",
    "        g.fig.suptitle(title.title()) # can also get the figure from plt.gcf()\n",
    "        axes = g.axes.flatten()\n",
    "        axes[0].set_title(\"Low\")\n",
    "        axes[1].set_title(\"Medium\")\n",
    "        axes[2].set_title(\"High\")\n",
    "        g.set(ylim=(-1.1, 1.1))\n",
    "\n",
    "        for col in range(numPairs) :\n",
    "            g.axes[0][col].axhline(y = 0, color='black', ls='--', linewidth=2, alpha=.7)\n",
    "\n",
    "        plt.savefig(results_fig_dir + title + '.png')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    #     sns.violinplot(x = 'pair_type', y = 'correlation',  order = ['low1-low2', 'med1-med2', 'high1-high2'], \n",
    "    #         hue = '|Epoch', data=final_corr)\n",
    "    #     plt.show()\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, True) \n",
    "        return final_corr, analyses_df\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) \n",
    "        return \"error\", analyses_df\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer: Is the low/med/high within pair correlation in the right order in the color layer?\n",
    "\n",
    "<a id='is_the_low/med/high_within_pair_correlation_in_the_right_order_in_the_output_layer?'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_corr_long = make_corr_long(outputData, 'Color', 'TestColorAll', numPairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "analyses_df = plot_correlation_over_time(output_corr_long, 'Color', 'TestColorAll', numPairs, analyses_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "output_just_main_corr, analyses_df = plot_final_correlation_over_time(output_corr_long, 'output', analyses_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "output_just_main_corr, analyses_df = plot_correlation_comparison(output_corr_long, 'output', analyses_df) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use try except block to not break the script if there's an error\n",
    "## This is useful for the Post_analyses.py where sometimes we run test parameter searches \n",
    "\n",
    "title = \"is the low/med/high within pair correlation in the right order in the output layer?\"\n",
    "try:\n",
    "\n",
    "    print('-------------------')\n",
    "    \n",
    "    if study_task_run == 1 :\n",
    "        aov_table = sm.stats.anova_lm(mod, typ=2)\n",
    "\n",
    "        mod, group_diff, group_order = analyze_within_pair_correlation(output_just_main_corr)\n",
    "\n",
    "        ## is the model significant? i.e. is low / med / high different?\n",
    "        temp = ['Output w_corr difference', group_diff, 0, 'Output within pair correlation-- is there a difference between low/med/high']\n",
    "        temp_series = pd.Series(temp, index = results_df.columns)\n",
    "        results_df = results_df.append(temp_series, ignore_index = True)\n",
    "\n",
    "\n",
    "\n",
    "        ## is the low/med/high within pair correlation in the right order?\n",
    "        temp = ['Output w_corr order', group_order, 0, 'Output within pair correlation-- is low/med/high in the right order']\n",
    "        temp_series = pd.Series(temp, index = results_df.columns)\n",
    "        results_df = results_df.append(temp_series, ignore_index = True)\n",
    "\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, True) \n",
    "except:\n",
    "    traceback.print_exc()\n",
    "    \n",
    "    \n",
    "    \n",
    "    analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Layer: Is the low/med/high within pair correlation in the right order in the color layer?\n",
    "<a id='is_the_low/med/high_within_pair_correlation_in_the_right_order_in_the_hidden_layer?'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_corr_long = make_corr_long(hiddenData, 'Hidden', 'TestColorAll', numPairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "analyses_df = plot_correlation_over_time(hidden_corr_long, 'Hidden', 'TestColorAll', numPairs, analyses_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hidden_corr_long = plot_correlation_over_time(hiddenData, 'Hidden', 'TestSceneAll', numPairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "hidden_just_main_corr, analyses_df = plot_final_correlation_over_time(hidden_corr_long, 'hidden', analyses_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use try except block to not break the script if there's an error\n",
    "## This is useful for the Post_analyses.py where sometimes we run test parameter searches \n",
    "title = \"is the low/med/high within pair correlation in the right order in the hidden layer?\"\n",
    "try:\n",
    "\n",
    "    if study_task_run == 1:\n",
    "        mod, group_diff, group_order = analyze_within_pair_correlation(hidden_just_main_corr)\n",
    "\n",
    "\n",
    "        ## is the model significant? i.e. is low / med / high different?\n",
    "        temp = ['Hidden w_corr difference', group_diff, 0, 'Hidden within pair correlation-- is there a difference between low/med/high']\n",
    "        temp_series = pd.Series(temp, index = results_df.columns)\n",
    "        results_df = results_df.append(temp_series, ignore_index = True)\n",
    "\n",
    "        ## is the low/med/high within pair correlation in the right order?\n",
    "        temp = ['Hidden w_corr order', group_order, 0, 'Hidden within pair correlation-- is low/med/high in the right order']\n",
    "        temp_series = pd.Series(temp, index = results_df.columns)\n",
    "        results_df = results_df.append(temp_series, ignore_index = True)\n",
    "\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, True) \n",
    "except:\n",
    "    traceback.print_exc()\n",
    "    analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "hidden_just_main_corr, analyses_df = plot_correlation_comparison(hidden_corr_long, 'hidden', analyses_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_corr_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before vs after correlation\n",
    "<a id='before_vs_after_correlation'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_pre_post_correlation(data, layer):\n",
    "    plt.clf()\n",
    "    data=data.reset_index()\n",
    "\n",
    "\n",
    "    ## get first and last epochs\n",
    "    first_epoch = data['|Epoch'].min()\n",
    "    last_epoch = data['|Epoch'].max()\n",
    "\n",
    "    ## Reorganize the data frame\n",
    "    data = data[data['|Epoch'].isin([first_epoch, last_epoch])]\n",
    "    data = data.drop(columns = ['$CurrentTask', 'high1', 'high2', 'low1', 'low2'])\n",
    "    data = data.melt(var_name='Trial', value_name='actM', value_vars=['med1', 'med2'], id_vars=['|Run', '|Epoch', '$CurrentTest', 'key'] )\n",
    "    data = data.pivot(index=['|Run', '$CurrentTest', 'key', 'Trial'], columns = '|Epoch', values='actM').reset_index()\n",
    "    data = data.sort_values(['|Run', '$CurrentTest', 'Trial', 'key'])\n",
    "\n",
    "    ## Get the correlation values:\n",
    "    data.head(30)\n",
    "    df_pre_post_corr = data.groupby(['|Run', '$CurrentTest','Trial']).corr().reset_index()\n",
    "\n",
    "    ## Reorganize the dataframe again:\n",
    "    df_pre_post_corr = df_pre_post_corr.rename(columns={'|Epoch':'pre_post1'})\n",
    "    df_pre_post_corr = df_pre_post_corr.melt(id_vars = ['|Run', '$CurrentTest', 'Trial', 'pre_post1'], var_name='pre_post2', value_vars=[first_epoch, last_epoch], value_name='correlation')\n",
    "\n",
    "    ## We only care about correlation pre vs post:\n",
    "    df_pre_post_corr = df_pre_post_corr[(df_pre_post_corr['pre_post1'] == first_epoch) & (df_pre_post_corr['pre_post2'] == last_epoch)]\n",
    "\n",
    "    ## get the order (which trial came first or second)\n",
    "    df_pre_post_corr = pd.merge(data_train_order, df_pre_post_corr, left_on = ['|Run', '$TrialName'], right_on = ['|Run', 'Trial'])\n",
    "\n",
    "    ## add the trial type\n",
    "    df_pre_post_corr['same_diff_condition'] = parameter_values['overlap']['same_diff_condition']\n",
    "\n",
    "    ## Plot\n",
    "    sns.swarmplot(x = 'order', y = 'correlation', data = df_pre_post_corr)\n",
    "    plt.ylim(-1.1,1.1)\n",
    "    title = 'Item Pre-Post Correlation: ' + layer.capitalize() + ' Layer - ' + parameter_values['overlap']['same_diff_condition']\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_fig_dir + title + '.png')\n",
    "    if from_cmdLine != 'cmd' :\n",
    "        plt.show()\n",
    "    \n",
    "    return df_pre_post_corr\n",
    "\n",
    "\n",
    "df_pre_post_corr = plot_pre_post_correlation(hiddenData, 'hidden')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_values['overlap']['same_diff_condition']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MDS\n",
    "<a id='MDS'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def find_order_data_test(row, data_train_order) :\n",
    "\n",
    "    curr_stim = row['$TrialName']\n",
    "    curr_run = row['|Run']\n",
    "\n",
    "    order = data_train_order[(data_train_order['|Run'] == curr_run) & (data_train_order['$TrialName'] == curr_stim)]['order']   \n",
    "\n",
    "    order = order.iloc[0]\n",
    "    return order\n",
    "\n",
    "\n",
    "def prepare_MDS_data(data) :\n",
    "    \n",
    "    run = 0\n",
    "    \n",
    "    col = ['|Run', '|Epoch', '$CurrentTask', '$CurrentTest', '$TrialName']\n",
    "    col.extend(filter_HiddM)\n",
    "\n",
    "#     color_task = data['$CurrentTask'] == 'TaskColorRecall'\n",
    "    color_test = data['$CurrentTest'] == 'TestColorAll'\n",
    "\n",
    "\n",
    "\n",
    "    select_data = data[color_test][col]\n",
    "    select_data= select_data[select_data['$TrialName'].isin(['med1', 'med2'])]\n",
    "    select_data['order'] = select_data.apply(lambda row : find_order_data_test(row, data_train_order), axis = 1)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    all_data = np.empty([0, 50])\n",
    "    all_runs = np.empty([0])\n",
    "    all_names = np.empty([0])\n",
    "    all_trialnames = np.empty([0])\n",
    "    for run in range(nruns + 1):\n",
    "\n",
    "        run_data = select_data[select_data['|Run'] == run]\n",
    "        pre = run_data['|Epoch'] == run_data['|Epoch'].min()\n",
    "        post = run_data['|Epoch'] == run_data['|Epoch'].max()\n",
    "        first = run_data['order'] == 'first'\n",
    "        second = run_data['order'] == 'second'\n",
    "        \n",
    "        \n",
    "        first_pre = run_data[first & pre][filter_HiddM].to_numpy()\n",
    "        first_post = run_data[first & post][filter_HiddM].to_numpy()\n",
    "\n",
    "        second_pre = run_data[second & pre][filter_HiddM].to_numpy()\n",
    "        second_post = run_data[second & post][filter_HiddM].to_numpy()\n",
    "\n",
    "        run_array = np.array([first_pre[0], first_post[0], second_pre[0], second_post[0]])\n",
    "\n",
    "\n",
    "        \n",
    "        all_data = np.append(all_data, run_array,0)\n",
    "    \n",
    "        all_runs = np.append(all_runs, np.repeat(np.round(run), 4))\n",
    "        all_names = np.append(all_names, ['first_pre','first_post', 'second_pre', 'second_post'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "        all_trialnames = np.append(all_trialnames, \n",
    "                                   np.concatenate([np.tile(run_data[first & pre]['$TrialName'].iloc[0],2),\n",
    "                                   np.tile(run_data[second & pre]['$TrialName'].iloc[0],2)]))\n",
    "    \n",
    "    \n",
    "    \n",
    "        MDS_data = {'data' : all_data, 'runs': all_runs, 'names': all_names, 'trial_names': all_trialnames}\n",
    "        \n",
    "\n",
    "    if MDS_data['data'].shape[0] != MDS_data['runs'].shape[0] or MDS_data['data'].shape[0] != MDS_data['names'].shape[0]:\n",
    "        raise ValueError\n",
    "        print('Something wrong with the dimensions here')\n",
    "    return MDS_data\n",
    "\n",
    "MDS_data = prepare_MDS_data(data_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"running MDS analysis\", flush=True)\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import matplotlib.collections as mcoll\n",
    "\n",
    "def multicolored_lines():\n",
    "    \"\"\"\n",
    "    http://nbviewer.ipython.org/github/dpsanders/matplotlib-examples/blob/master/colorline.ipynb\n",
    "    http://matplotlib.org/examples/pylab_examples/multicolored_line.html\n",
    "    \"\"\"\n",
    "\n",
    "    x = np.linspace(0, 4. * np.pi, 100)\n",
    "    y = np.sin(x)\n",
    "    fig, ax = plt.subplots()\n",
    "    lc = colorline(x, y, cmap='hsv')\n",
    "    plt.colorbar(lc)\n",
    "    plt.xlim(x.min(), x.max())\n",
    "    plt.ylim(-1.0, 1.0)\n",
    "    plt.show()\n",
    "\n",
    "def colorline(ax,\n",
    "        x, y, z=None, cmap='copper', norm=plt.Normalize(0.0, 1.0),\n",
    "        linewidth=3, alpha=1.0):\n",
    "    \"\"\"\n",
    "    http://nbviewer.ipython.org/github/dpsanders/matplotlib-examples/blob/master/colorline.ipynb\n",
    "    http://matplotlib.org/examples/pylab_examples/multicolored_line.html\n",
    "    Plot a colored line with coordinates x and y\n",
    "    Optionally specify colors in the array z\n",
    "    Optionally specify a colormap, a norm function and a line width\n",
    "    \"\"\"\n",
    "\n",
    "    # Default colors equally spaced on [0,1]:\n",
    "    if z is None:\n",
    "        z = np.linspace(0.0, 1.0, len(x))\n",
    "\n",
    "    # Special case if a single number:\n",
    "    # to check for numerical input -- this is a hack\n",
    "    if not hasattr(z, \"__iter__\"):\n",
    "        z = np.array([z])\n",
    "\n",
    "    z = np.asarray(z)\n",
    "\n",
    "    segments = make_segments(x, y)\n",
    "    lc = mcoll.LineCollection(segments, array=z, cmap=cmap, norm=norm,\n",
    "                              linewidth=linewidth, alpha=alpha)\n",
    "\n",
    "    ax.add_collection(lc)\n",
    "\n",
    "    return lc\n",
    "\n",
    "def make_segments(x, y):\n",
    "    \"\"\"\n",
    "    Create list of line segments from x and y coordinates, in the correct format\n",
    "    for LineCollection: an array of the form numlines x (points per line) x 2 (x\n",
    "    and y) array\n",
    "    \"\"\"\n",
    "\n",
    "    points = np.array([x, y]).T.reshape(-1, 1, 2)\n",
    "    segments = np.concatenate([points[:-1], points[1:]], axis=1)\n",
    "    return segments\n",
    "\n",
    "def MDS_plot_procrustes(MDS_data, run, distance_func=\"euclidean\") :\n",
    "    def euclidean(x,y):\n",
    "        return np.linalg.norm(x-y)\n",
    "    def pearsoncorr(x,y):\n",
    "        return stats.stats.pearsonr(x, y)[0]\n",
    "    if distance_func == \"euclidean\":\n",
    "        distance_metric = euclidean\n",
    "    else:\n",
    "        distance_metric = pearsoncorr\n",
    "        \n",
    "    def show_activation(data):\n",
    "        plt.clf()\n",
    "        plt.imshow(data, cmap='plasma')\n",
    "        plt.show()\n",
    "    \n",
    "    def show_distance_matrices_activation_embds(data, embds):\n",
    "        plt.clf()\n",
    "        fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(12,5))\n",
    "        run_distances = np.zeros((4, 4))\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                run_distances[i, j] = distance_metric(data[i],data[j])\n",
    "        ax0.imshow(run_distances, cmap='plasma')\n",
    "        # We want to show all ticks...\n",
    "        ax0.set_xticks(np.arange(4))\n",
    "        ax0.set_yticks(np.arange(4))\n",
    "        ax0.set_xticklabels(labels)\n",
    "        ax0.set_yticklabels(labels)\n",
    "        # Rotate the tick labels and set their alignment.\n",
    "        plt.setp(ax0.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "                     rotation_mode=\"anchor\")\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                text = ax0.text(j, i, \"%.2f\" %(run_distances[i, j]),\n",
    "                               ha=\"center\", va=\"center\", color=\"gray\")\n",
    "\n",
    "        run_distances_copy = np.zeros((4, 4))\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                run_distances_copy[i, j] = distance_metric(embds[i],embds[j])\n",
    "        \n",
    "        ax1.imshow(run_distances_copy, cmap='plasma')\n",
    "        # We want to show all ticks...\n",
    "        ax1.set_xticks(np.arange(4))\n",
    "        ax1.set_yticks(np.arange(4))\n",
    "        ax1.set_xticklabels(labels)\n",
    "        ax1.set_yticklabels(labels)\n",
    "        # Rotate the tick labels and set their alignment.\n",
    "        plt.setp(ax1.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "                     rotation_mode=\"anchor\")\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                text = ax1.text(j, i, \"%.2f\" %(run_distances[i, j]),\n",
    "                               ha=\"center\", va=\"center\", color=\"gray\")\n",
    "                \n",
    "        plt.show()\n",
    "        \n",
    "    def show_scatter_pre_post_transform(pre, post, names):\n",
    "        plt.clf()\n",
    "        fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(12,5))\n",
    "        ax0.scatter(pre[:,0], pre[:,1], c = [color_dict[name] for name in names], \n",
    "                alpha = .9)\n",
    "        ax1.scatter(post[:,0], post[:,1], c = [color_dict[name] for name in names], \n",
    "                alpha = .9)\n",
    "        plt.xlim(-2.5, 2.5)\n",
    "        plt.ylim(-2.5, 2.5)\n",
    "        plt.show()\n",
    "    \n",
    "    def get_polar_angle(x, y):\n",
    "        return np.arctan2(y, x) \n",
    "    \n",
    "    def procrustes(data1):\n",
    "        mtx1 = data1\n",
    "\n",
    "        if mtx1.ndim != 2:\n",
    "            raise ValueError(\"Input matrices must be two-dimensional\")\n",
    "        if mtx1.size == 0:\n",
    "            raise ValueError(\"Input matrices must be >0 rows and >0 cols\")\n",
    "            \n",
    "        # translate all the data to the origin\n",
    "        \n",
    "        translate = mtx1[[0]]\n",
    "        temp = mtx1 - mtx1[[0]]\n",
    "        theta = get_polar_angle(temp[1, 0], temp[1, 1])\n",
    "        rotation_matrix = np.array([[np.cos(-theta), -np.sin(-theta)],\n",
    "                                    [np.sin(-theta), np.cos(-theta)]])\n",
    "        scale = np.linalg.norm(temp[1])\n",
    "        \n",
    "        \n",
    "        return translate, rotation_matrix, scale\n",
    "    color_dict = {'first_pre': [.4, .8, .3], 'first_post': [.4, .5, .9],\n",
    "                  'second_pre': [.9, .3, .3], 'second_post': [.6, .1, .6],\n",
    "                  'mean_first': [.4, .65, .6], 'mean_second': [.75, .2, .45]\n",
    "                 }\n",
    "        \n",
    "\n",
    "    data = MDS_data['data']\n",
    "    names = MDS_data['names']\n",
    "    labels = ['first_pre', 'first_post', 'second_pre', 'second_post']\n",
    "    \n",
    "    \n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    embedding = MDS(n_components = 2)\n",
    "    data = np.roll(MDS_data[\"data\"], -1, axis=-1)\n",
    "    # Flip embeddings across midline if trial starts with med2\n",
    "    for run in range(nruns+1):\n",
    "        if MDS_data[\"trial_names\"][4 * run] == \"med2\":\n",
    "            data[4 * run:4 * run+4] = np.fliplr(data[4 * run:4 * run+4])\n",
    "    X_transformed = embedding.fit_transform(data)\n",
    "    translate = X_transformed[[0]]\n",
    "    X_transformed -= translate\n",
    "    theta = get_polar_angle(X_transformed[2, 0], X_transformed[2, 1])\n",
    "    rotation_matrix = np.array([[np.cos(-theta), -np.sin(-theta)],\n",
    "                                [np.sin(-theta), np.cos(-theta)]])\n",
    "\n",
    "    scale = np.linalg.norm(X_transformed[2])\n",
    "    X_transformed =1/scale* (rotation_matrix@X_transformed.T).T + np.random.randn(*X_transformed.shape)*0.03\n",
    "    \n",
    "    # Flip across y-axis if most second-post points are below y-axis\n",
    "    if np.mean(X_transformed[3::4, 1] > 0) < 0.5:\n",
    "        X_transformed *= np.array([[1, -1]])\n",
    "            \n",
    "    scatter = ax.scatter(X_transformed[:,0], X_transformed[:,1], \n",
    "                         c = [color_dict[name] for name in names], \n",
    "            alpha = 1.0, marker='+', s=150,zorder=2, linewidths=1.10)\n",
    "    \n",
    "    \n",
    "    for run in range(nruns+1):\n",
    "        cm = LinearSegmentedColormap.from_list(\n",
    "        \"Custom\", [color_dict['first_pre'], color_dict['first_post']], N=20)\n",
    "        x = np.linspace(X_transformed[4*run+0,0],X_transformed[4*run+1,0],100)\n",
    "        y = np.linspace(X_transformed[4*run+0,1],X_transformed[4*run+1,1],100)\n",
    "        lc = colorline(ax, x, y, cmap=cm, alpha=0.1)\n",
    "\n",
    "        cm = LinearSegmentedColormap.from_list(\n",
    "        \"Custom\", [color_dict['second_pre'], color_dict['second_post']], N=20)\n",
    "        x = np.linspace(X_transformed[4*run+2,0],X_transformed[4*run+3,0],100)\n",
    "        y = np.linspace(X_transformed[4*run+2,1],X_transformed[4*run+3,1],100)\n",
    "        lc = colorline(ax, x, y, cmap=cm, alpha=0.1)\n",
    "        \n",
    "    #plt.axis('square')\n",
    "    \n",
    "    legend_elements = [\n",
    "                   Line2D([0], [0], marker='+', color=color_dict['first_pre'], label='first_pre',\n",
    "                          markersize=10, lw = 0),\n",
    "                    Line2D([0], [0], marker='+', color=color_dict['first_post'], label='first_post',\n",
    "                                      markersize=10, lw = 0),\n",
    "                    Line2D([0], [0], marker='+', color=color_dict['second_pre'], label='second_pre',\n",
    "                                      markersize=10, lw = 0),\n",
    "                    Line2D([0], [0], marker='+', color=color_dict['second_post'], label='second_post',\n",
    "                                      markersize=10, lw = 0)\n",
    "    ]\n",
    "\n",
    "    ax.legend(handles = legend_elements, bbox_to_anchor = (1.05, 1), loc = 2, borderaxespad=0., fontsize=15)\n",
    "    title = parameter_values['overlap']['same_diff_condition'] + ' hidden data MDS rotated by run'\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(15)\n",
    "\n",
    "    \n",
    "    \n",
    "    plt.xlim(-1.25, 2.25)\n",
    "    plt.ylim(-1.25, 2.25)\n",
    "    plt.xticks([0,1])\n",
    "    plt.yticks([0,1])\n",
    "    plt.tick_params(length=7.5, bottom=True, left=True, direction=\"in\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_fig_dir + title + '.png')\n",
    "    plt.savefig(eps_dir + title + '.eps')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# MDS_plot(MDS_data, 0)\n",
    "transformed_X_list = MDS_plot_procrustes(MDS_data, 'all')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(MDS_data[\"trial_names\"])\n",
    "# plt.clf()\n",
    "# fig, ax = plt.subplots(figsize = (10,20))\n",
    "# plt.xticks(np.arange(0, 50, 5))\n",
    "# _ = np.roll(MDS_data[\"data\"], 0, axis=-1)\n",
    "# im = ax.imshow(_, cmap='plasma')\n",
    "# [plt.axhline(i*4-0.5) for i in range(20)]\n",
    "# title = 'hidden data MDS embedding'\n",
    "# plt.title(title)\n",
    "# plt.savefig(results_fig_dir + title + '.png')\n",
    "# plt.show()\n",
    "\n",
    "plt.clf()\n",
    "fig, ax = plt.subplots(figsize = (10,20))\n",
    "_ = np.roll(MDS_data[\"data\"], -1, axis=-1)\n",
    "plt.xticks(np.arange(0, 50, 5))\n",
    "im = ax.imshow(np.flip(_,axis=-1), cmap='plasma')\n",
    "[plt.axhline(i*4-0.5) for i in range(nruns+1)]\n",
    "title = 'hidden data MDS embedding'\n",
    "plt.title(title)\n",
    "plt.savefig(results_fig_dir + title + '.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def distance_matrix_plot(MDS_data, run, distance_func = \"euclidean\") :\n",
    "#     plt.clf()\n",
    "#     def euclidean(x,y):\n",
    "#         return np.linalg.norm(x-y)\n",
    "#     def pearsoncorr(x,y):\n",
    "#         return stats.stats.pearsonr(x, y)[0]\n",
    "#     if distance_func == \"euclidean\":\n",
    "#         distance_metric = euclidean\n",
    "#     else:\n",
    "#         distance_metric = pearsoncorr\n",
    "#     plt.clf()\n",
    "#     color_dict = {'first_pre': [.5, .7, .3], 'first_post': [.4, .5, .9],\n",
    "#                   'second_pre': [.9, .3, .3], 'second_post': [.6, .1, .6]}\n",
    "#     labels = ['first_pre', 'first_post', 'second_pre', 'second_post']\n",
    "        \n",
    "#     if run != 'all':\n",
    "#         indices = np.where(MDS_data['runs']== run)\n",
    "#         data= MDS_data['data'][indices]\n",
    "#         names = MDS_data['names'][indices]\n",
    "\n",
    "#     else:\n",
    "#         data = MDS_data['data']\n",
    "#         names = MDS_data['names']\n",
    "        \n",
    "#     all_runs_distances = []\n",
    "#     for run in range(0, nruns):\n",
    "#         run_data = data[(4 * run):(4 * run + 4)]\n",
    "#         # Compute pairwise distance and save into matrix\n",
    "        \n",
    "#         run_distances = np.zeros((4, 4))\n",
    "#         for i in range(4):\n",
    "#             for j in range(i, 4):\n",
    "#                 run_distances[i, j] = distance_metric(run_data[i],run_data[j])\n",
    "\n",
    "#         # Make distance matrix symmetric\n",
    "#         run_distances = (run_distances + run_distances.T) - np.diag(np.diag(run_distances)) \n",
    "#         all_runs_distances.append(run_distances)\n",
    "#     all_runs_distances = np.mean(np.stack(all_runs_distances), axis=0)\n",
    "#     print(all_runs_distances)\n",
    "#     fig, ax = plt.subplots(figsize = (10,7))\n",
    "#     title = \"Distance matrix (averaged over runs) with distance function - \" +  distance_func\n",
    "#     plt.title(title)\n",
    "#     im = ax.imshow(all_runs_distances, cmap='plasma')\n",
    "\n",
    "#     # We want to show all ticks...\n",
    "#     ax.set_xticks(np.arange(4))\n",
    "#     ax.set_yticks(np.arange(4))\n",
    "#     ax.set_xticklabels(labels)\n",
    "#     ax.set_yticklabels(labels)\n",
    "#     # Rotate the tick labels and set their alignment.\n",
    "#     plt.setp(ax.get_xticklabels(), rotation=90, ha=\"right\",\n",
    "#                  rotation_mode=\"anchor\")\n",
    "#     for i in range(4):\n",
    "#         for j in range(4):\n",
    "#             text = ax.text(j, i, \"%.2f\" %(all_runs_distances[i, j]),\n",
    "#                            ha=\"center\", va=\"center\", color=\"gray\")\n",
    "    \n",
    "\n",
    "#     plt.savefig(results_fig_dir + title + '.png')\n",
    "#     plt.show()\n",
    "    \n",
    "# distance_matrix_plot(MDS_data, \"all\", distance_func = \"euclidean\")\n",
    "# distance_matrix_plot(MDS_data, \"all\", distance_func = \"corr\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability each unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS ISNT DONE-- EDITING\n",
    "\n",
    "first_pre_index = np.where(MDS_data['names']== 'second_post')\n",
    "print(first_pre_index)\n",
    "\n",
    "med1_index = np.where(MDS_data['trial_names']== 'med1')\n",
    "print(med1_index)\n",
    "med2_index = np.where(MDS_data['trial_names']== 'med2')\n",
    "\n",
    "common_indices = np.intersect1d(first_pre_index, med1_index)\n",
    "print(common_indices)\n",
    "\n",
    "just_med1_first = MDS_data[\"data\"][common_indices]\n",
    "print(just_med1_first)\n",
    "average = np.average(just_med1_first, axis=0)\n",
    "print(average)\n",
    "new = np.reshape(average,(1,50))\n",
    "plt.imshow(new)\n",
    "plt.show()\n",
    "\n",
    "common_indices = np.intersect1d(first_pre_index, med2_index)\n",
    "print(common_indices)\n",
    "just_med2_first = MDS_data[\"data\"][common_indices]\n",
    "print(just_med2_first)\n",
    "average = np.average(just_med2_first, axis=0)\n",
    "print(average)\n",
    "new = np.reshape(average,(1,50))\n",
    "plt.imshow(new)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot # Shared units in hidden layer \n",
    "<a id = 'Plot_#_shared_units_in_hidden_layer' ></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "curr_data = data_test\n",
    "\n",
    "is_med = curr_data['$TrialName'].isin(['med1','med2'])\n",
    "curr_data = curr_data[is_med]\n",
    "hidden_cols = [col for col in curr_data if col.startswith('#HiddenActM[')]\n",
    "\n",
    "column_names = ['|Run', '|Epoch', '$CurrentTask', '$CurrentTest', '$TrialName']\n",
    "column_names_all = column_names + hidden_cols\n",
    "\n",
    "\n",
    "curr_data = curr_data[column_names_all]\n",
    "\n",
    "curr_data = curr_data.melt(id_vars=column_names, var_name='Unit_Name', value_name='act')\n",
    "curr_data['act_bool'] = np.where(curr_data['act']> 0.1, 1,0)\n",
    "curr_data = curr_data.sort_values(column_names)\n",
    "\n",
    "\n",
    "curr_data_piv = curr_data.pivot(index = ['|Run', '|Epoch', '$CurrentTask', '$CurrentTest', 'Unit_Name'], columns='$TrialName', values='act_bool').reset_index()\n",
    "\n",
    "curr_data_piv['shared'] = np.where((curr_data_piv['med1'] == 1) & (curr_data_piv['med2'] == 1), 1, 0)\n",
    "shared_total = curr_data_piv.groupby(['|Run', '|Epoch'])['shared'].sum()\n",
    "shared_total = shared_total.reset_index()\n",
    "total_act = curr_data.groupby(['|Run', '|Epoch', '$TrialName'])['act_bool'].sum().reset_index()\n",
    "total_act = total_act.pivot(index = ['|Run', '|Epoch'], columns='$TrialName', values='act_bool').reset_index()\n",
    "\n",
    "num_shared_units_df = pd.merge(shared_total, total_act, on = ['|Run', '|Epoch'])\n",
    "num_shared_units_melt_df = num_shared_units_df.melt(id_vars=['|Run', '|Epoch'], var_name='type', value_name='num_units')\n",
    "\n",
    "# put in the correct order:\n",
    "num_shared_units_melt_df = pd.merge(num_shared_units_melt_df, data_train_order, how = 'left',left_on = ['|Run', 'type'], right_on = ['|Run', '$TrialName'])\n",
    "num_shared_units_melt_df['order'].fillna(num_shared_units_melt_df['type'], inplace = True)\n",
    "num_shared_units_melt_df = num_shared_units_melt_df.drop(columns = '$TrialName')\n",
    "num_shared_units_melt_df = num_shared_units_melt_df.rename(columns = {'type': '$TrialName', 'order': 'type'})\n",
    "\n",
    "\n",
    "\n",
    "#Plot the # of shared vs # of total units in the representation\n",
    "sns.lineplot(x = '|Epoch', y = 'num_units', data = num_shared_units_melt_df, hue = 'type')\n",
    "title = 'Number of Units in for each stimulus in Hidden Layer'\n",
    "plt.title(title)\n",
    "plt.ylim([0,8])\n",
    "plt.savefig(results_fig_dir + title + '.png')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "num_shared_units_df['same_diff_condition'] = parameter_values['overlap']['same_diff_condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference score\n",
    "<a id='within-pair_correlation_minus_across-pair_correlation._Done_in_the_hidden_layer._'></a>\n",
    "#### within-pair correlation minus across-pair correlation. Done in the hidden layer. \n",
    "as in Favila et al 2016, we expect that by the end, the high competition group should have a positive score indicating that the representations are more similar to each other than to other items. Medium overlap should have a negative score, and low overlap should be near zero. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if medium_only_analysis == False :\n",
    "\n",
    "    def diff_score(data, layer, analyses_df) :\n",
    "        title = 'Correlation Difference Score in ' + layer + ' Layer'\n",
    "        try:\n",
    "            df_diff_score = pd.DataFrame(columns = ['run', 'epoch', 'pair', 'diff_score'])\n",
    "\n",
    "            #Difference score \n",
    "            names = data['firstItem'].unique()\n",
    "            names = [n[:-1] for n in names]\n",
    "            names = list(set(names))\n",
    "            epochs_to_compare = [epoch_end_initial, max_final_epoch]\n",
    "            for run in range(data_train['|Run'].max()) :\n",
    "                #for loop run\n",
    "                for epoch in epochs_to_compare :\n",
    "\n",
    "                    for cat_overlap in names : \n",
    "\n",
    "                        first_item = cat_overlap + '1'\n",
    "                        second_item = cat_overlap + '2'\n",
    "                        pair = [first_item, second_item]\n",
    "\n",
    "                        is_run = data['|Run'] == run\n",
    "                        is_last_epoch  = data['|Epoch'] == epoch\n",
    "                        is_first_trial = data['firstItem'] == first_item\n",
    "                        is_second_trial = data['firstItem'] == second_item\n",
    "\n",
    "\n",
    "                        #first pairmate, all correlations\n",
    "                        first_item_all = data[is_first_trial & is_run & is_last_epoch]\n",
    "\n",
    "                        #within pair correlation\n",
    "                        within = first_item_all[first_item_all['secondItem'] == second_item]\n",
    "                        within = within.iloc[0]['correlation']\n",
    "\n",
    "                        #second pairmate, all correlations\n",
    "                        second_item_all = data[is_second_trial & is_run & is_last_epoch]\n",
    "\n",
    "                        #first pairmate, non pair correlations\n",
    "                        other1 = first_item_all[-first_item_all['secondItem'].isin(pair)]\n",
    "                        #second pairmate, non pair correlations\n",
    "                        other2 = second_item_all[-second_item_all['secondItem'].isin(pair)]\n",
    "\n",
    "                        #put them together and take mean\n",
    "                        other = other1.append(other2)\n",
    "                        other_corr_mean = other['correlation'].mean()\n",
    "\n",
    "                        #calculate difference score\n",
    "                        difference_score = within - other_corr_mean\n",
    "\n",
    "\n",
    "                        #add to dataframe\n",
    "                        temp = [run, epoch, cat_overlap, difference_score]\n",
    "                        temp_series = pd.Series(temp, index =df_diff_score.columns)\n",
    "                        df_diff_score = df_diff_score.append(temp_series, ignore_index =True)\n",
    "\n",
    "            df_diff_score\n",
    "\n",
    "            sns.barplot(x = 'pair', y = 'diff_score', hue='epoch', data = df_diff_score)\n",
    "            plt.ylim(-1.5,1.5)\n",
    "\n",
    "            plt.title(title)\n",
    "\n",
    "            plt.savefig(results_fig_dir + title + '.png')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            analyses_df = add_analysis_to_analyses_df(analyses_df, title, True) \n",
    "            return df_diff_score, analyses_df\n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) \n",
    "            return \"error\", analyses_df\n",
    "\n",
    "\n",
    "    plt.clf()\n",
    "    df_diff_score_hidden, analyses_df = diff_score(hidden_corr_long, 'Hidden', analyses_df)\n",
    "    plt.clf()\n",
    "    df_diff_score_output, analyses_df = diff_score(output_corr_long, 'Color', analyses_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include only a subset of runs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# runs_to_include = []\n",
    "# names = output_corr_long['firstItem'].unique()\n",
    "# names = [n[:-1] for n in names]\n",
    "# names = list(set(names))\n",
    "\n",
    "## if you only want where within pair correlation at end is lower than at baseline: \n",
    "# for run in range(nruns) :\n",
    "#     counter = 0\n",
    "#     for cat_overlap in names : \n",
    "\n",
    "#         first_item = cat_overlap + '1'\n",
    "#         second_item = cat_overlap + '2'\n",
    "#         pair = [first_item, second_item]\n",
    "\n",
    "#         is_run = output_corr_long['|Run'] == run\n",
    "#         is_last_epoch_baseline  = output_corr_long['|Epoch'] == epoch_end_initial\n",
    "\n",
    "#         is_last_epoch  = output_corr_long['|Epoch'] == max_final_epoch\n",
    "#         is_first_trial = output_corr_long['firstItem'] == first_item\n",
    "#         is_second_trial = output_corr_long['secondItem'] == second_item\n",
    "\n",
    "#         last = output_corr_long[is_run & is_first_trial & is_second_trial & is_last_epoch][['correlation']]\n",
    "#         first = output_corr_long[is_run & is_first_trial & is_second_trial & is_last_epoch_baseline][['correlation']]\n",
    "\n",
    "#         #if it ends lower than it started:\n",
    "#         if last.iloc[0]['correlation'] < first.iloc[0]['correlation'] :\n",
    "#             counter = counter + 1\n",
    "\n",
    "\n",
    "#     if counter == len(names) : \n",
    "#         runs_to_include.append(run)\n",
    "\n",
    "#option 2, if you only want where within/pair correlation ends as negative:\n",
    "\n",
    "# for run in range(nruns) :\n",
    "#     counter = 0\n",
    "#     include = 1\n",
    "#     for cat_overlap in names : \n",
    "#         first_item = cat_overlap + '1'\n",
    "#         second_item = cat_overlap + '2'\n",
    "#         pair = [first_item, second_item]\n",
    "\n",
    "#         is_run = output_corr_long['|Run'] == run\n",
    "#         is_last_epoch_baseline  = output_corr_long['|Epoch'] == epoch_end_initial\n",
    "\n",
    "#         is_last_epoch  = output_corr_long['|Epoch'] == max_final_epoch\n",
    "#         is_first_trial = output_corr_long['firstItem'] == first_item\n",
    "#         is_second_trial = output_corr_long['secondItem'] == second_item\n",
    "\n",
    "#         last = output_corr_long[is_run & is_first_trial & is_second_trial & is_last_epoch][['correlation']]\n",
    "#         first = output_corr_long[is_run & is_first_trial & is_second_trial & is_last_epoch_baseline][['correlation']]\n",
    "\n",
    "#         if last.iloc[0]['correlation'] > 0 :\n",
    "            \n",
    "#             include = 0\n",
    "#             break\n",
    "            \n",
    "    \n",
    "#     if include == 1 :\n",
    "#         runs_to_include.append(run)\n",
    "        \n",
    "\n",
    "# runs_to_include\n",
    "# temp = output_corr_long[output_corr_long['|Run'].isin(runs_to_include)]\n",
    "\n",
    "\n",
    "# analyses_df = plot_correlation_over_time(temp, 'Color', 'TestColorAll', numPairs, analyses_df)\n",
    "# output_just_main_corr, analyses_df = plot_final_correlation_over_time(temp, 'output', analyses_df) \n",
    "\n",
    "# temp = hidden_corr_long[hidden_corr_long['|Run'].isin(runs_to_include)]\n",
    "# analyses_df = plot_correlation_over_time(temp, 'Color', 'TestColorAll', numPairs, analyses_df)\n",
    "# output_just_main_corr, analyses_df = plot_final_correlation_over_time(temp, 'output', analyses_df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CENTER OF MASS \n",
    "<a id='CENTER_OF_MASS'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_center_of_mass(act_array):\n",
    "    unit_num = np.arange(1,51)\n",
    "\n",
    "    weighted = unit_num * act_array\n",
    "    weighted_sum = weighted.sum()\n",
    "    mass_sum = act_array.sum() + 1e-30\n",
    "    center_temp = weighted_sum / mass_sum\n",
    "    \n",
    "    return center_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_coa_true() :\n",
    "    numTotalUnits = parameter_values['overlap']['numTotalUnits']\n",
    "    numOverlapUnits = parameter_values['overlap']['numOverlapUnits'] \n",
    "\n",
    "    print(\"Warning: Assuming med2 output representation starts at index 25\")\n",
    "    unique = numTotalUnits - numOverlapUnits\n",
    "    true_val_dict = {}\n",
    "    \n",
    "    if parameter_values['overlap']['same_diff_condition'] == 'Different':\n",
    "\n",
    "        true_val_dict['med1'] = 26\n",
    "        true_val_dict['med2'] = 30\n",
    "    \n",
    "    elif parameter_values['overlap']['same_diff_condition'] == 'Same':\n",
    "        true_val_dict['med1'] = 26\n",
    "        true_val_dict['med2'] = 26\n",
    "    \n",
    "    return true_val_dict\n",
    "\n",
    "true_val_dict = calc_coa_true()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_center_of_mass(data, epoch, trial, run, layer) :\n",
    "#     center_of_mass = np.empty(0)\n",
    "#     for run in range(data_train['|Run'].max()):\n",
    "    \n",
    "    if_curr_run = data_test['|Run'] == run\n",
    "    if_baseline_epoch = data_test['|Epoch'] == epoch\n",
    "    if_trial = data_test['$TrialName'] == trial\n",
    "\n",
    "    if layer == 'output':\n",
    "        col_str = '#OutActM[' \n",
    "    elif layer == 'hidden' :\n",
    "        col_str = '#HiddenActM['\n",
    "        \n",
    "\n",
    "    layer_col = [col for col in data.columns if col.startswith(col_str)]\n",
    "    \n",
    "#     if layer == 'output' :\n",
    "#         layer_col = [col for col in data.columns if col.startswith('#OutActM[')]\n",
    "#     elif layer == 'hidden' :\n",
    "#         layer_col = [col for col in data.columns if col.startswith('#HiddenActM[')]\n",
    "\n",
    "    curr = data_test[if_curr_run & if_baseline_epoch & if_trial][layer_col].reset_index(drop = True)\n",
    "\n",
    "    curr_np = curr.iloc[[0]].to_numpy()\n",
    "    \n",
    "    center_temp = calc_center_of_mass(curr_np)\n",
    "#     print(curr_np)\n",
    "    \n",
    "\n",
    "# #     plt.imshow(curr)\n",
    "# #     plt.show()\n",
    "\n",
    "#     unit_num = np.arange(1,51)\n",
    "\n",
    "\n",
    "#     weighted = unit_num * curr_np\n",
    "#     weighted_sum = weighted.sum()\n",
    "#     mass_sum = curr_np.sum()\n",
    "#     center_temp = weighted_sum / mass_sum\n",
    "    return center_temp\n",
    "#     center_of_mass = np.append(center_of_mass, center_temp)\n",
    "#     return center_of_mass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_center_mass_df(data, layer) :\n",
    "    center_of_mass_df = pd.DataFrame(columns = ['run', 'time', 'type','stim', 'layer', 'c_o_m'])\n",
    "\n",
    "    for run in range(data_train['|Run'].max()) :\n",
    "        for time in ['pre', 'post'] :\n",
    "            if time == 'pre' :\n",
    "                epoch = epoch_end_initial\n",
    "\n",
    "            elif time == 'post' :\n",
    "                epoch = max_final_epoch\n",
    "\n",
    "            for item in ['low1', 'low2', 'med1', 'med2', 'high1', 'high2']:\n",
    "    #     for item in ['pre_low1', 'pre_low2', 'pre_med1', 'pre_med2' ,'pre_high1', 'pre_high2'] :\n",
    "    #         itemName = item[4:]\n",
    "\n",
    "                c_o_a = find_center_of_mass(data, epoch, item, run, layer = layer)\n",
    "                temp = [run, time, 'raw', item, layer, c_o_a]\n",
    "                temp_series = pd.Series(temp, index = center_of_mass_df.columns)\n",
    "                center_of_mass_df = center_of_mass_df.append(temp_series, ignore_index = True)\n",
    "\n",
    "\n",
    "    return center_of_mass_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "is_output_test = data_test['$CurrentTest'] == 'TestColorAll'\n",
    "is_output_recall = data_test['$CurrentTask'] == 'TaskColorRecall'\n",
    "\n",
    "curr_data_test = data_test[is_output_test & is_output_recall]\n",
    "\n",
    "\n",
    "\n",
    "output_center_of_mass_df = get_center_mass_df(curr_data_test, 'output')\n",
    "hidden_center_of_mass_df = get_center_mass_df(curr_data_test, 'hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare to true center of mass\n",
    "This can't be done with the hidden layer, since there isn't really a \"true\" center of mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def read_stim_dat_file_into_dataframe():\n",
    "#     with open(\"output_diff_stim.dat\", \"r\") as f:\n",
    "#         outputfile_external_from_dat = f.readlines()\n",
    "#         num_output_units = parameter_values['Num_units_per_layer']['Hidden']\n",
    "#         columns = [\"stim\"] + [f\"ext{i}\" for i in range(num_output_units)]\n",
    "#         outputdatframe_external_from_dat = pd.DataFrame(columns=columns)\n",
    "#         for idx, row in enumerate(range(-1, -3, -1)[::-1]):\n",
    "#             line = outputfile_external_from_dat[row].strip('\\n').split(\"\\t\")\n",
    "#             outputdatframe_external_from_dat.loc[idx] = ([line[1]] + line[-num_output_units:])\n",
    "#     return outputdatframe_external_from_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# correct_val_df = read_stim_dat_file_into_dataframe()\n",
    "# correct_val_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flip_error(row, true_val_dict):\n",
    "    \n",
    "    curr_stim = row['stim']\n",
    "    \n",
    "    if curr_stim[-1] == '1' :\n",
    "        other_stim_n = '2'\n",
    "    elif curr_stim[-1] == '2' :\n",
    "        other_stim_n = '1'\n",
    "        \n",
    "    other_stim = curr_stim[:-1] + other_stim_n\n",
    "    \n",
    "    dist_size = true_val_dict[other_stim] - true_val_dict[curr_stim]\n",
    "\n",
    "    ### NOTE: THIS ONLY WORKS RIGHT NOW DIST SIZE IS LESS THAN 180\n",
    "    if dist_size < 0 :\n",
    "        rev_error = -1 * row['raw_error']\n",
    "    else :\n",
    "        rev_error = row['raw_error']\n",
    "\n",
    "    \n",
    "    return rev_error \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "true_val_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_error(c_o_a_df_output, true_val_dict) :\n",
    "    \n",
    "    c_o_a_df_color =c_o_a_df_output.dropna()\n",
    "\n",
    "    c_o_a_df_output['true_c_o_m'] = c_o_a_df_output['stim'].map(true_val_dict)\n",
    "    \n",
    "    print(c_o_a_df_output)\n",
    "\n",
    "    c_o_a_df_output['raw_error'] = round(c_o_a_df_output['c_o_m'] - c_o_a_df_output['true_c_o_m'], 5)\n",
    "    \n",
    "    c_o_a_df_output['rev_error'] = c_o_a_df_output.apply(lambda row: flip_error(row, true_val_dict), axis=1)\n",
    "    \n",
    "\n",
    "    return c_o_a_df_output\n",
    "    \n",
    "    ## This is where we'd run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_center_of_mass_df = output_center_of_mass_df[output_center_of_mass_df['stim'].isin(['med1','med2'])]\n",
    "output_center_of_mass_df = calc_error(output_center_of_mass_df, true_val_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_center_of_mass_df = hidden_center_of_mass_df[hidden_center_of_mass_df['stim'].isin(['med1','med2'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_error(data) :\n",
    "    \n",
    "    is_post = data['time'] == 'post'\n",
    "\n",
    "    subset_data = data[is_post ]\n",
    "\n",
    "    sns.stripplot(x='stim', y = 'rev_error',data = subset_data)\n",
    "    plt.axhline(0, ls = '-', color ='gray')\n",
    "    title = 'Output Error By Condition'\n",
    "    plt.title(title)\n",
    "    plt.ylim([-10,10])\n",
    "    plt.ylabel(' # units away from true value')\n",
    "    plt.show()\n",
    "    plt.savefig(results_fig_dir + title + '.png')\n",
    "\n",
    "\n",
    "plot_error(output_center_of_mass_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_center_of_mass_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Order effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_center_of_mass_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_center_of_mass_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output_center_of_mass_df[(output_center_of_mass_df['stim'].isin(['med1','med2'])) & (output_center_of_mass_df['run']==1)]\n",
    "\n",
    "def find_order(row, data_train_order) :\n",
    "    plt.clf()\n",
    "\n",
    "    curr_stim = row['stim']\n",
    "    curr_run = row['run']\n",
    "    order = data_train_order[(data_train_order['|Run'] == curr_run) & (data_train_order['$TrialName'] == curr_stim)]['order']   \n",
    "    order = order.iloc[0]\n",
    "    return order\n",
    "\n",
    "output_center_of_mass_df['order'] = output_center_of_mass_df.apply(lambda row : find_order(row, data_train_order), axis = 1)\n",
    "hidden_center_of_mass_df['order'] = hidden_center_of_mass_df.apply(lambda row : find_order(row, data_train_order), axis = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_error_order(data) :\n",
    "    plt.clf()\n",
    "    is_post = data['time'] == 'post'\n",
    "\n",
    "    subset_data = data[is_post]\n",
    "\n",
    "    sns.stripplot(x='order', y = 'rev_error', data = subset_data)\n",
    "    plt.axhline(0, ls = '-', color ='gray')\n",
    "    title = 'Output Error By Order'\n",
    "    plt.title(title)\n",
    "    \n",
    "    plt.ylim([-10,10])\n",
    "    plt.ylabel(' # units away from true value')\n",
    "    plt.savefig(results_fig_dir + title + '.png')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_error_order(output_center_of_mass_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_center_of_mass_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot distance center of mass - can be done for both color and hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_c_o_a_distance(center_of_mass_df, layer) :\n",
    "    for run in range(data_train['|Run'].max()) :\n",
    "        for time in ['pre', 'post'] :\n",
    "            pair = 'med' #this is only for med right now\n",
    "            is_run = center_of_mass_df['run']==run\n",
    "            is_time = center_of_mass_df['time']== time\n",
    "\n",
    "            item1 = pair + '1'\n",
    "            item2 = pair + '2'\n",
    "\n",
    "            val2 = center_of_mass_df[is_run & is_time  & (center_of_mass_df['stim'] == item2)][['c_o_m']].to_numpy()\n",
    "            val1 = center_of_mass_df[is_run & is_time  & (center_of_mass_df['stim'] == item1)][['c_o_m']].to_numpy()\n",
    "\n",
    "            diff = val2 - val1\n",
    "            diff = diff[0][0]\n",
    "            name = pair + '_diff'\n",
    "            \n",
    "            if layer != 'hidden' :\n",
    "                temp = [run, time, 'diff', name, layer, diff, np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "            elif layer == 'hidden' :\n",
    "                temp = [run, time, 'diff', name, layer, diff, np.nan]\n",
    "\n",
    "            temp_series = pd.Series(temp, index = center_of_mass_df.columns)\n",
    "\n",
    "            center_of_mass_df = center_of_mass_df.append(temp_series, ignore_index = True)# for item in ['post_low1', 'post_low2', 'post_med1', 'post_med2' ,'post_high1', 'post_high2'] :\n",
    "\n",
    "    return center_of_mass_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_center_of_mass_dist(center_of_mass_df, layer) :\n",
    "    ## Use try except block to not break the script if there's an error\n",
    "    ## This is useful for the Post_analyses.py where sometimes we run test parameter searches \n",
    "    title = 'Distance Between Center of Masses: ' + layer \n",
    "    \n",
    "    try:\n",
    "        plt.clf()\n",
    "#         temp = center_of_mass_df[center_of_mass_df['stim'].isin(['med_diff'])]\n",
    "\n",
    "#         print(temp.head())\n",
    "        if study_task_run == 1 :\n",
    "            ax = sns.violinplot(x=\"stim\", y=\"c_o_m\", hue=\"time\", data=center_of_mass_df, dodge=True)\n",
    "        elif study_task_run ==0 :\n",
    "            ax = sns.swarmplot(x = \"stim\", y=\"c_o_m\", hue=\"time\", data=center_of_mass_df, alpha = .2)\n",
    "\n",
    "        ax = sns.pointplot(x = \"stim\", y=\"c_o_m\", hue=\"time\", data=center_of_mass_df, legend = False)\n",
    "        # sns.swarmplot(x=\"key\", y=\"value\", hue=\"time\", data=temp, color ='white', dodge=True)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        l = plt.legend(handles[0:2], labels[0:2], bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "        plt.ylim(0,12)\n",
    "        plt.ylabel('units apart')\n",
    "        plt.title(title)\n",
    "        plt.savefig(results_fig_dir + title + '.png')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        print('this is assuming just medium overlap condition:')\n",
    "        units_apart = center_of_mass_df.dropna()\n",
    "        units_apart[units_apart['time'] == 'post']\n",
    "#         tstat, pvalue = stats.ttest_1samp(units_apart[units_apart['time'] == 'post']['c_o_m'], 4)\n",
    "#         print('is post-difference significantly different from 4 (pre training unit apart distance)?')\n",
    "#         print('t = ' + str(tstat))\n",
    "#         print('p = ' + str(pvalue))\n",
    "\n",
    "#         print('pre: ' + str(units_apart[units_apart['time'] == 'pre'].c_o_m.mean()))\n",
    "#         print('post: ' + str(units_apart[units_apart['time'] == 'post'].c_o_m.mean()))\n",
    "\n",
    "\n",
    "#         if study_task_run == 1:\n",
    "#             model = ols('c_o_m ~ C(time)*C(stim)', temp).fit()\n",
    "#             print(f\"Overall model F({model.df_model: .0f},{model.df_resid: .0f}) = {model.fvalue: .3f}, p = {model.f_pvalue: .4f}\")\n",
    "#             print('----')\n",
    "#             print('MODEL SUMMARY: ')\n",
    "#             print(model.summary())\n",
    "#             print('----')\n",
    "#             res = sm.stats.anova_lm(model, typ= 2)\n",
    "#             print(res)\n",
    "\n",
    "#             analyses_df = add_analysis_to_analyses_df(analyses_df, title, True) \n",
    "\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_center_of_mass_df = calc_c_o_a_distance(hidden_center_of_mass_df, 'hidden')\n",
    "hidden_distance_df = hidden_center_of_mass_df[hidden_center_of_mass_df['stim'].isin(['med_diff'])]\n",
    "hidden_distance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_center_of_mass_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_center_of_mass_df = calc_c_o_a_distance(output_center_of_mass_df, 'layer')\n",
    "output_distance_df = output_center_of_mass_df[output_center_of_mass_df['stim'].isin(['med_diff'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_center_of_mass_dist(output_distance_df, 'Output')\n",
    "plot_center_of_mass_dist(hidden_distance_df, 'Hidden')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_center_of_mass_DFs(output_c_m_DF, hidden_c_m_DF) :\n",
    "    \n",
    "    output_c_m_DF['layer'] = 'output'\n",
    "    hidden_c_m_DF['layer'] = 'hidden'\n",
    "\n",
    "    new_df = output_c_m_DF.append(hidden_c_m_DF)\n",
    "    \n",
    "    new_df['overlap'] = parameter_values['overlap']['overlapType']\n",
    "    return new_df\n",
    "\n",
    "center_of_mass_df = join_center_of_mass_DFs(output_center_of_mass_df,hidden_center_of_mass_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "center_of_mass_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Post Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is better for the Favila task, to see differentiation, since we can't look at distortion in the color layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_corr_long"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Scene Layer in Association Task\n",
    "<a id='Scene_Association_Task'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_type_scene(row) :\n",
    "    scene_dict = {'med1': {'low1_ActM': 'other',\n",
    "                      'low2_ActM': 'other',\n",
    "                      'med1_ActM': 'target', \n",
    "                      'med2_ActM': 'competitor',\n",
    "                      'high1_ActM': 'other', \n",
    "                      'high2_ActM': 'other'},\n",
    "            'med2': {'low1_ActM': 'other',\n",
    "                      'low2_ActM': 'other',\n",
    "                      'med1_ActM': 'competitor', \n",
    "                      'med2_ActM': 'target',\n",
    "                      'high1_ActM': 'other', \n",
    "                      'high2_ActM': 'other'}}\n",
    "    \n",
    "    if row['$TrialName'] in scene_dict :\n",
    "        unit_type = scene_dict[row['$TrialName']][row['unit']]\n",
    "    else :\n",
    "        \n",
    "        unit_type = np.NAN\n",
    "\n",
    "    return unit_type\n",
    "\n",
    "print('assuming only med1 and med2 -- every other trial type here set to NAN')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scene_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_scene_act_df() :\n",
    "    plt.clf()\n",
    "    scene_columns = [col for col in data_test.columns if col.startswith('#SceneActM')]\n",
    "    columns = ['|Run', '|Epoch', '$CurrentTask', '$CurrentTest', '|Trial', '$TrialName']\n",
    "    initial_columns = columns.copy()\n",
    "    columns.extend(scene_columns)\n",
    "\n",
    "    is_scene_test = data_test['$CurrentTest']=='TestSceneAll'\n",
    "    is_Task = data_test['$CurrentTask'] == 'TaskColorRecall'\n",
    "    is_med = data_test['$TrialName'].isin(['med1','med2'])\n",
    "\n",
    "    relevant_data = data_test[is_scene_test & is_Task & is_med]\n",
    "    relevant_data[columns]\n",
    "\n",
    "    scene_data_df = relevant_data[columns].rename(columns = sceneKeyM)\n",
    "    scene_data_df = scene_data_df.melt(id_vars = initial_columns, value_name = 'Act_M', var_name = 'unit', value_vars=['low1_ActM','low2_ActM', 'med1_ActM', 'med2_ActM', 'high1_ActM', 'high2_ActM'])\n",
    "    print(scene_data_df)\n",
    "\n",
    "    #     scene_data_df['type'] = scene_data_df.apply(lambda row: assign_type_scene(row), axis = 1)\n",
    "    \n",
    "    scene_data_df['overlap'] = parameter_values['overlap']['overlapType']\n",
    "    \n",
    "    sns.lineplot(x = '|Epoch', y = 'Act_M', hue='type', data = scene_data_df)\n",
    "    title ='Scene Layer Activity Over Time'\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Scene Unit Activity')\n",
    "    plt.savefig(results_fig_dir + title + '.png')\n",
    "    plt.show()\n",
    "\n",
    "    return scene_data_df\n",
    "\n",
    "if scene_test == True: \n",
    "    scene_data_df = get_scene_act_df()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_error_scene_unit_relationship_specific(scene_data_df, center_of_mass_df, scene_unit_type): \n",
    "\n",
    "    palette = {'target': [.4 ,.6, .6], 'other': [.8, .4, .3], 'competitor': [.8, .4, .7]}\n",
    "    final_scene = scene_data_df[scene_data_df['|Epoch'] == scene_data_df['|Epoch'].max()]\n",
    "    final_scene_specific_unit = final_scene[final_scene['type'] == scene_unit_type]\n",
    "    final_scene_specific_unit_ave = final_scene_specific_unit.groupby('|Run')['Act_M'].mean().reset_index()\n",
    "\n",
    "    center_of_mass_post = center_of_mass_df[center_of_mass_df['time'] == 'post']\n",
    "\n",
    "    center_of_mass_post = center_of_mass_post[center_of_mass_post['stim'].isin(['med_diff'])]\n",
    "    center_of_mass_post = center_of_mass_post[center_of_mass_post['layer'] == 'output']\n",
    "    merged_df_scene_error = pd.merge(center_of_mass_post, final_scene_specific_unit_ave, left_on=['run'], right_on=['|Run'])\n",
    "    ax = sns.regplot(x = 'c_o_m', y = 'Act_M', data = merged_df_scene_error, label = scene_unit_type, color =palette[scene_unit_type])   \n",
    "    ax.legend()\n",
    "\n",
    "    #######\n",
    "\n",
    "def plot_error_scene_unit_relationship(scene_data_df, center_of_mass_df) :\n",
    "    plt.clf()\n",
    "    plot_error_scene_unit_relationship_specific(scene_data_df,center_of_mass_df, 'target')\n",
    "    plot_error_scene_unit_relationship_specific(scene_data_df,center_of_mass_df, 'competitor')\n",
    "    plot_error_scene_unit_relationship_specific(scene_data_df,center_of_mass_df, 'other')\n",
    "    ax = plt.gca()\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    ax = plt.axhline(y = 0, ls = '--', color ='grey')\n",
    "\n",
    "    plt.ylabel('Scene Unit Activity')\n",
    "    plt.xlabel('# Units Apart')\n",
    "    plt.ylim(-.1,1)\n",
    "    title = 'Memory Repulsion and Scene Test'\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(results_fig_dir + title + '.png')\n",
    "    if from_cmdLine != 'cmd' :\n",
    "        plt.show()\n",
    "\n",
    "    #####\n",
    "    \n",
    "    for type_overlap in ['competitor', 'target', 'other']:\n",
    "        plt.clf()\n",
    "        plot_error_scene_unit_relationship_specific(scene_data_df,center_of_mass_df, type_overlap)\n",
    "        ax = plt.gca()\n",
    "        box = ax.get_position()\n",
    "        ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "        plt.ylabel('Scene Unit Activity')\n",
    "        plt.xlabel('# Units Apart')\n",
    "        plt.ylim(-.1,1)\n",
    "        plt.axhline(y = 0, ls = '--', color ='grey')\n",
    "\n",
    "        title = 'Memory Repulsion and Scene Test: ' + type_overlap.capitalize()\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "if scene_test == True: \n",
    "\n",
    "    plot_error_scene_unit_relationship(scene_data_df, center_of_mass_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_probability_scene_unit(all_scene_df) :\n",
    "    \n",
    "    temp = all_scene_df.groupby(['|Run', '|Epoch', 'type'])['Act_M'].mean().reset_index()\n",
    "    temp = temp.pivot(index=['|Run', '|Epoch'], columns='type', values='Act_M').reset_index()\n",
    "    temp['Selected_Scene'] = temp[['competitor', 'other', 'target']].idxmax(axis = 1)\n",
    "    \n",
    "    indiv_amounts = temp.groupby(['|Epoch'])['Selected_Scene'].value_counts()\n",
    "    total_amounts = temp.groupby(['|Epoch']).size()\n",
    "    probability_scene_df = indiv_amounts.div(total_amounts).reset_index()\n",
    "    probability_scene_df= probability_scene_df.rename(columns={0: 'probability'})\n",
    "    return probability_scene_df\n",
    "    \n",
    "\n",
    "if scene_test == True: \n",
    "    probability_scene_df = get_probability_scene_unit(scene_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_probability_all(probability_scene_df):\n",
    "    sns.lineplot(x = '|Epoch', y = 'probability', hue='Selected_Scene', data = probability_scene_df)\n",
    "    title = 'Probability of Choosing Correct Scene Unit'\n",
    "    plt.title(title)\n",
    "    plt.ylabel('% trials Unit was chosen')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.show()\n",
    "    plt.savefig(results_fig_dir + title + '.png')\n",
    "\n",
    "if scene_test == True: \n",
    "\n",
    "    plot_probability_all(probability_scene_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Pop Up Over Time\n",
    "<a id='Analyze_Pop_Up_Over_Time'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions to plot cycles\n",
    "<a id='Define_functions_to_plot_cycles'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def cycleByEpoch(sceneLayerCycle, selectedEpoch, selectedTrial, ciType, type, scene_palette, numPairs) :\n",
    "\n",
    "    title = 'Scene Layer Cycle ' + type + ': Epoch #' + str(selectedEpoch)\n",
    "\n",
    "    #CHANGE THIS SO IT's NOT HARD CODED AS 6\n",
    "    tdata = sceneLayerCycle[sceneLayerCycle['|Epoch'] == selectedEpoch]\n",
    "\n",
    "    if (numPairs == 2) :\n",
    "        if (type == 'Ge') : \n",
    "            scene_order = ['small1 Ge','small2 Ge','small3 Ge','small4 Ge']\n",
    "\n",
    "        elif (type == 'Act') :\n",
    "            scene_order = ['small1','small2','small3','small4']\n",
    "    elif (numPairs == 3) :\n",
    "        if (type == 'Ge') : \n",
    "            scene_order = ['low1 Ge','low2 Ge','med1 Ge','med2 Ge', 'high1 Ge', 'high2 Ge']\n",
    "\n",
    "        elif (type == 'Act') :\n",
    "            scene_order = ['low1', 'low2', 'med1', 'med2', 'high1', 'high2']\n",
    "\n",
    "    g = sns.lineplot(x=\"|Cycle\", y=selectedTrial,\n",
    "                 hue=\"Scene Unit\", ci = ciType, palette = scene_palette,hue_order = scene_order,\n",
    "                 data=tdata)\n",
    "\n",
    "    g.set_xlabel('Time: Cycle #')\n",
    "\n",
    "    if (type == 'Act') :\n",
    "        g.set_ylim(-1, 1.3)\n",
    "    elif (type == 'Ge') :\n",
    "        g.set_ylim(-1, 2.5)\n",
    "\n",
    "\n",
    "    plt.title(title)\n",
    "    g.axhline(0, ls='-', color ='gray')\n",
    "\n",
    "    plt.savefig(checkpoint_fig_dir + 'cycle_plots/' + title, bbox_inches = \"tight\")\n",
    "    plt.show()\n",
    "        \n",
    "    \n",
    "    \n",
    "def plotEveryCycle(sceneLayerCycle, selectedTrial, scene_palette, type, numPairs, analyses_df, ciType = 95) :\n",
    "    \n",
    "    title = f\"plotEveryCycle in {selectedTrial} trial of {type} units\"\n",
    "    try:\n",
    "        print(ciType)\n",
    "        for i in range(max(sceneLayerCycle['|Epoch'])) :   \n",
    "            cycleByEpoch(sceneLayerCycle, i, selectedTrial, ciType, type, scene_palette, numPairs)\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, True) \n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) \n",
    "    return analyses_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This takes a long time, so default to having it uncommented. It prints out every cycle for each epoch. It takes a while because of the confidence intervals-- So set ciType to be none if you want to speed up, or leave it out to have it be 95% confidence interval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_cycle_data(data, unit_start, unit_end, layer, key = sceneKey) :\n",
    "\n",
    "    LayerCycle = data_trn_cyc_stacked.loc[(slice(None),  slice(None), slice(None), slice(None), slice(unit_start, unit_end)),:]\n",
    "\n",
    "    LayerCycle.head()\n",
    "\n",
    "    LayerCycle.reset_index(inplace=True) \n",
    "    \n",
    "    if (layer == 'Scene') :\n",
    "        LayerCycle = LayerCycle.rename(columns={\"key\": \"Scene Unit\"})\n",
    "        LayerCycle[\"Scene Unit\"].replace(key, inplace = True)\n",
    "    \n",
    "    return LayerCycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### train cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if train_cycle_done == 1 :\n",
    "\n",
    "#     sceneLayerCycle = prep_cycle_data(data_trn_cyc_stacked, scene_ge_start, scene_ge_end, 'Scene', key = sceneKey_ge)\n",
    "\n",
    "#     sceneLayerCycle.head()\n",
    "#     plotEveryCycle(sceneLayerCycle, 'low1', scene_palette_ge, 'Ge', numPairs, ciType= 95) \n",
    "    # plotEveryCycle(sceneLayerCycle, 'small2') \n",
    "    #plotEveryCycle(sceneLayerCycle, 'small3') \n",
    "    #plotEveryCycle(sceneLayerCycle, 'small4') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if train_cycle_done == 1 :\n",
    "\n",
    "    sceneLayerCycle = prep_cycle_data(data_trn_cyc_stacked, scene_Start, scene_End, 'Scene', key = sceneKey)\n",
    "\n",
    "    analyses_df = plotEveryCycle(sceneLayerCycle, 'med1', scene_palette, 'Act', numPairs, analyses_df, ciType= None) \n",
    "    # plotEveryCycle(sceneLayerCycle, 'small2') \n",
    "    #plotEveryCycle(sceneLayerCycle, 'small3') \n",
    "    #plotEveryCycle(sceneLayerCycle, 'small4') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if train_cycle_done == 1 :\n",
    "    analyses_df = plotEveryCycle(sceneLayerCycle, 'high1', scene_palette, 'Act', numPairs, analyses_df, ciType= None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if train_cycle_done == 1 :\n",
    "    analyses_df = plotEveryCycle(sceneLayerCycle, 'low1', scene_palette, 'Act', numPairs, analyses_df, ciType= None) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if test_cycle_done == 1 :\n",
    "    sceneLayerCycle = prep_cycle_data(data_tst_cyc_stacked, scene_Start, scene_End, sceneKey)\n",
    "    analyses_df = plotEveryCycle(sceneLayerCycle, 'small1', scene_palette, 'Act', analyses_df, ciType= 1) \n",
    "    # plotEveryCycle(sceneLayerCycle, 'small2') \n",
    "    #plotEveryCycle(sceneLayerCycle, 'small3') \n",
    "    #plotEveryCycle(sceneLayerCycle, 'small4') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checkpoint for scene layer pop up. \n",
    "<a id='checkpoint_for_scene_layer_pop_up.'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if train_cycle_done == 1 :\n",
    "    is_epoch_start_recall = data_trn_cyc['|Epoch'] == epoch_end_initial + 1\n",
    "    is_Q1 = data_trn_cyc['|Cycle'].between(0, 24)\n",
    "    is_Q2 = data_trn_cyc['|Cycle'].between(25, 49)\n",
    "    is_Q3 = data_trn_cyc['|Cycle'].between(50, 74)\n",
    "    is_Q4 = data_trn_cyc['|Cycle'].between(75, 99)\n",
    "\n",
    "    Q1_cycles = data_trn_cyc[is_epoch_start_recall & is_Q1]\n",
    "    Q2_cycles = data_trn_cyc[is_epoch_start_recall & is_Q2]\n",
    "    Q3_cycles = data_trn_cyc[is_epoch_start_recall & is_Q3]\n",
    "    Q4_cycles = data_trn_cyc[is_epoch_start_recall & is_Q4]\n",
    "\n",
    "    #check that in Q1, only correct unit is active: Q1_just_trial_unit\n",
    "    Q1_cycles.head()\n",
    "    Q1_just_trial_unit_list = []\n",
    "    Q2_just_trial_unit_list = []\n",
    "    Q3_trial_and_competitor_list = []\n",
    "    Q3_no_other_unit = [];\n",
    "\n",
    "    temp = Q1_cycles.groupby(['|Run', '|Epoch', '$TrialName']).mean()[filter_scene]\n",
    "\n",
    "    for i, v in temp.iterrows() :\n",
    "        currentTrial = i[2]\n",
    "        scene_unit_currentTrial = getKeysByValue(sceneKey, currentTrial)\n",
    "        scene_unit_currentTrial = scene_unit_currentTrial[0]\n",
    "        if v[scene_unit_currentTrial] > .8 and v.drop(scene_unit_currentTrial).sum() < .1 : \n",
    "            Q1_just_trial_unit_list == Q1_just_trial_unit_list.append(True)\n",
    "        else :\n",
    "            Q1_just_trial_unit_list == Q1_just_trial_unit_list.append(False)\n",
    "\n",
    "    if False in Q1_just_trial_unit_list : \n",
    "        Q1_just_trial_unit = False\n",
    "    else :\n",
    "        Q1_just_trial_unit = True\n",
    "\n",
    "\n",
    "    Q1_just_trial_unit\n",
    "\n",
    "\n",
    "    # same thing again for quarter 2: Q2_just_trial_unit\n",
    "\n",
    "    temp = Q2_cycles.groupby(['|Run', '|Epoch', '$TrialName']).mean()[filter_scene]\n",
    "\n",
    "    for i, v in temp.iterrows() :\n",
    "        currentTrial = i[2]\n",
    "        scene_unit_currentTrial = getKeysByValue(sceneKey, currentTrial)\n",
    "        scene_unit_currentTrial = scene_unit_currentTrial[0]\n",
    "        if v[scene_unit_currentTrial] > .8 and v.drop(scene_unit_currentTrial).sum() < .1 : \n",
    "            Q2_just_trial_unit_list == Q2_just_trial_unit_list.append(True)\n",
    "        else :\n",
    "            Q2_just_trial_unit_list == Q2_just_trial_unit_list.append(False)\n",
    "\n",
    "    if False in Q2_just_trial_unit_list : \n",
    "        Q2_just_trial_unit = False\n",
    "    else :\n",
    "        Q2_just_trial_unit = True\n",
    "\n",
    "    # Q3 - only trial unit and competitor: Q3_trial_and_competitor\n",
    "\n",
    "    temp = Q3_cycles.groupby(['|Epoch', '$TrialName']).mean()[filter_scene]\n",
    "\n",
    "    for i, v in temp.iterrows() :\n",
    "        currentTrial = i[1]\n",
    "        scene_unit_currentTrial = getKeysByValue(sceneKey, currentTrial)\n",
    "        scene_unit_currentTrial = scene_unit_currentTrial[0]\n",
    "        competitor = competitor_trial(currentTrial)\n",
    "        scene_unit_competitor = getKeysByValue(sceneKey, competitor)\n",
    "        scene_unit_competitor = scene_unit_competitor[0]\n",
    "        if v[scene_unit_currentTrial] > .8 and v[scene_unit_competitor] > .1 and v.drop(scene_unit_currentTrial).drop(scene_unit_competitor).sum() < .1 : \n",
    "            Q3_trial_and_competitor_list == Q3_trial_and_competitor_list.append(True)\n",
    "        else :\n",
    "            Q3_trial_and_competitor_list == Q3_trial_and_competitor_list.append(False)\n",
    "\n",
    "    if False in Q3_trial_and_competitor_list : \n",
    "        Q3_pop_up = False\n",
    "    else :\n",
    "         Q3_pop_up = True\n",
    "\n",
    "\n",
    "    if Q1_just_trial_unit and Q2_just_trial_unit and Q3_pop_up :\n",
    "        pop_up_ok = True\n",
    "\n",
    "    else :\n",
    "        pop_up_ok = False\n",
    "\n",
    "        # Checkpoint ?? #: is the pop up ok\n",
    "\n",
    "\n",
    "    temp = ['competitor pop up: scene layer', pop_up_ok, 0, 'is the scene layer pop up correct']\n",
    "    temp_series = pd.Series(temp, index = checkpoints_df.columns)\n",
    "    checkpoints_df = checkpoints_df.append(temp_series, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer: Pop Up\n",
    "<a id='Output_Layer:_Pop_Up'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_output_classification_dictionary():\n",
    "    output_classes = []\n",
    "    \n",
    "    unit_names = list(data_train_stacked.loc[idx[0,0,:,outputM_Start:outputM_End],:].reset_index()['key'])\n",
    "    for unit in range(50):\n",
    "        if unit < 6:\n",
    "            output_classes.append(\"low1\")\n",
    "        elif unit == 6:\n",
    "            output_classes.append(\"low1+2\")\n",
    "        elif unit < 13:\n",
    "            output_classes.append(\"low2\")\n",
    "        elif unit < 19:\n",
    "            output_classes.append(\"not_active\")\n",
    "        elif unit < 23:\n",
    "            output_classes.append(\"med1\")\n",
    "        elif unit < 26:\n",
    "            output_classes.append(\"med1+2\")\n",
    "        elif unit < 30:\n",
    "            output_classes.append(\"med2\")\n",
    "        elif unit < 36:\n",
    "            output_classes.append(\"not_active\")\n",
    "        elif unit < 38:\n",
    "            output_classes.append(\"high1\")\n",
    "        elif unit < 43:\n",
    "            output_classes.append(\"high1+2\")\n",
    "        elif unit < 45:\n",
    "            output_classes.append(\"high2\")\n",
    "        else:\n",
    "            output_classes.append(\"not_active\")\n",
    "    output_dict = {unit_names[idx]: unit for idx, unit in enumerate(output_classes)}\n",
    "    return output_dict\n",
    "\n",
    "output_classification_dict = get_output_classification_dictionary()\n",
    "output_classification_dict_Act = {key.replace(\"ActM\", \"Act\"): value for key, value in output_classification_dict.items()}\n",
    "\n",
    "output_classification_dict_AvgSLrn = {key.replace(\"ActM\", \"AvgSLrn\"): value for key, value in output_classification_dict.items()}\n",
    "\n",
    "output_classification_dict_AvgS = {key.replace(\"ActM\", \"AvgS\"): value for key, value in output_classification_dict.items()}\n",
    "\n",
    "output_classification_dict_AvgM = {key.replace(\"ActM\", \"AvgM\"): value for key, value in output_classification_dict.items()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if train_cycle_done == 1 :\n",
    "    #prep the output data \n",
    "    output_temp = prep_cycle_data(data_trn_cyc_stacked, output_Start, output_End, 'Color')\n",
    "    output_temp_multi = output_temp.set_index(['|Run', '|Epoch', '|Cycle', '$CurrentTask', 'key'])\n",
    "    output_temp_multi = output_temp_multi.stack().unstack(level='key')\n",
    "    output_cycle = output_temp_multi.reset_index()\n",
    "\n",
    "\n",
    "    def image_output_cycle(data,epoch,trial, filter_out, analyses_df, run = 'all'):\n",
    "\n",
    "        temp = data[(data['$TrialName'] == trial) & (data['|Epoch'] == epoch)]\n",
    "        try:\n",
    "            if (run != 'all') :\n",
    "                temp = temp[temp['|Run'] == run]\n",
    "            elif (run == 'all') :\n",
    "                temp = temp.groupby(['|Cycle', '$TrialName']).mean().drop(['|Run', '|Epoch'],axis = 1)\n",
    "            temp=temp[filter_out]\n",
    "\n",
    "\n",
    "            plt.imshow(temp)\n",
    "            title = 'Output Layer Cycle Act: ' + trial.capitalize() + ' Epoch #' + str(epoch)\n",
    "            plt.title(title)\n",
    "            plt.ylabel('Cycle #')\n",
    "            plt.xlabel('Output Unit #')\n",
    "            plt.savefig(checkpoint_fig_dir + 'cycle_plots/' + title +'.png', bbox_inches = \"tight\")\n",
    "\n",
    "            plt.show()\n",
    "            analyses_df = add_analysis_to_analyses_df(analyses_df, title, True) \n",
    "        except:\n",
    "            traceback.print_exc()\n",
    "            analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) \n",
    "        return analyses_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if train_cycle_done == 1:\n",
    "    for epoch in range(nepochs + 1) :\n",
    "        analyses_df = image_output_cycle(output_cycle,epoch,'low1', filter_out, analyses_df, run ='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if train_cycle_done == 1:\n",
    "    for epoch in range(nepochs + 1) :\n",
    "        analyses_df = image_output_cycle(output_cycle,epoch,'med1', filter_out, analyses_df, run = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if train_cycle_done == 1:\n",
    "    for epoch in range(nepochs + 1) :\n",
    "        analyses_df = image_output_cycle(output_cycle,epoch,'high1', filter_out, analyses_df, run = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## set up output layer cycle data with the output category labels for analysis:\n",
    "if train_cycle_done == 1 :\n",
    "    def prepCycleDataOutput(data_trn_cyc_stacked, unit_dict_list, output_S, output_E) :\n",
    "\n",
    "        outputLayerCycle = data_trn_cyc_stacked.loc[(slice(None),  slice(None), slice(None), slice(None), slice(output_S, output_E)),:]\n",
    "\n",
    "        outputLayerCycle.reset_index(inplace = True)\n",
    "\n",
    "        # Categorize the units in each run\n",
    "        def unitmapper(row):\n",
    "\n",
    "            try:\n",
    "                return unit_dict_list[row['key']]\n",
    "\n",
    "            except:\n",
    "                ;\n",
    "\n",
    "\n",
    "        outputLayerCycle.loc[slice(None),\"Categorization\"] = outputLayerCycle.apply(unitmapper, axis = 1) # use the dictionary to set the category\n",
    "\n",
    "        # hiddenLayerCycle.head()\n",
    "        return outputLayerCycle\n",
    "\n",
    "    outputLayerCycle_act = prepCycleDataOutput(data_trn_cyc_stacked, output_classification_dict_Act, output_Start, output_End)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_categorized_cycle(selectedEpoch, dataLayerCycle, analysisType, Layer, analyses_df, selectedTrial = 'small1', selectedRun = 'all') :\n",
    "    #if selectedRun is 'all', then it will be an aggragate of all runs. otherwise, set to be a specific run. \n",
    "    title = Layer + ' Layer Cycle ' + analysisType + ' ' + selectedTrial.capitalize() + ' Epoch #' + str(selectedEpoch)\n",
    "    try:\n",
    "        tdata = dataLayerCycle[dataLayerCycle['|Epoch'] == selectedEpoch]\n",
    "\n",
    "        if (selectedRun != 'all') :\n",
    "\n",
    "            tdata = tdata[tdata['|Run'] == selectedRun]\n",
    "\n",
    "        else:\n",
    "            ;\n",
    "\n",
    "        g = sns.lineplot(x=\"|Cycle\", y=selectedTrial,\n",
    "                         hue=\"Categorization\", hue_order = hidd_order, palette = hidden_palette,\n",
    "                         data=tdata)\n",
    "\n",
    "        g.set_xlabel('Time')\n",
    "        g.set_ylim(-1, 1)\n",
    "\n",
    "        \n",
    "    #     if analysisType == 'Act':\n",
    "    #         title = 'Hidden Layer Cycle Activation: ' + selectedTrial.capitalize() + ' Epoch #' + str(selectedEpoch)\n",
    "\n",
    "    #     elif analysisType == 'AvgM':\n",
    "    #         title = 'Hidden Layer Cycle AvgM: ' + selectedTrial.capitalize() + ' Epoch #' + str(selectedEpoch)\n",
    "\n",
    "    #     elif analysisType == 'Ge':\n",
    "    #         title = 'Hidden Layer Cycle Ge: ' + selectedTrial.capitalize() + ' Epoch #' + str(selectedEpoch)\n",
    "\n",
    "        plt.title(title)\n",
    "        g.axhline(0, ls='-', color ='gray')\n",
    "        g.axhline(0, ls='-', color ='gray')\n",
    "\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "        plt.savefig(checkpoint_fig_dir + 'cycle_plots/' + title + '.png', bbox_inches = \"tight\")\n",
    "        plt.show()\n",
    "        \n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, True) \n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) \n",
    "        \n",
    "    return analyses_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if train_cycle_done ==1 :\n",
    "    analyses_df = plot_categorized_cycle(epoch_end_initial+1, outputLayerCycle_act, 'Act', 'Color', analyses_df, selectedTrial = 'low1', selectedRun='all')\n",
    "    analyses_df = plot_categorized_cycle(epoch_end_initial+1, outputLayerCycle_act, 'Act', 'Color', analyses_df, selectedTrial = 'med1', selectedRun='all')\n",
    "    analyses_df = plot_categorized_cycle(epoch_end_initial+1, outputLayerCycle_act, 'Act', 'Color', analyses_df, selectedTrial = 'high1', selectedRun='all')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hidden Layer: Pop Up\n",
    "<a id='Hidden_Layer:_Pop_Up'></a>\n",
    "##### First, Assign units by initial activation\n",
    "<a id='First,_Assign_units_by_initial_activation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTES FOR THIS: \n",
    "final test epoch in the TaskColorWOOsc task, a hidden unit will get classified depending on activation. That classification get's applied on a per-run basis (since the activation patterns will be different each time)\n",
    "\n",
    "\"active\" means minus phase activation above .01. \n",
    "\n",
    "* same1 = units only active for same1\n",
    "* same2 = units only active for same2\n",
    "* same12 = units active for same 1 and same 2 (but not same 3 or same 4)\n",
    "* same3 = units only active for same 3\n",
    "* same4 = units only active for same 4\n",
    "* same34 = units active for same 3 and same 4 (but not same 1 or same 2)\n",
    "* not active = units that have no activity for same1, 2, 3, or 4\n",
    "* cross-pair = units that don't fall into the above (i.e. active for same 1 and same 3)\n",
    "\n",
    "Eventually will use with hiddenData, stacked dataframe, to get average activation and cycle over time for each of the above groups. Maybe best for now to have the above categories as keys in a dictionary?\n",
    "\n",
    "Note -- this process has to be done *separately* for each 'run', since the units active for each trial will change for each run. \n",
    "\n",
    "The data to look at this is in the variable 'hiddenData', which is just a subset of data_test_stacked, but only includes the hiddenActM rows. We want to specifically categorize based on activation from the final epoch run in TaskColorWOOsc. So, if the highest epoch number in that task is 5, you get just those trials with the following line of code (where .loc takes an input for each of index of the hierarchical)\n",
    "\n",
    "hiddenData.loc[(slice(None), 5, 'TaskColorWOOsc', slice(None)), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classify units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get a list of the names of columns storing hidden unit values\n",
    "hiddenunitnames = []\n",
    "\n",
    "for rowname in hiddenData.loc[(0, epoch_end_initial, slice(None), 'TestColorAll', slice(None)), :][\"low1\"].index.values:\n",
    "    hiddenunitnames.append(rowname[-1])\n",
    "    \n",
    "def get_hidden_id(unit_name, hidden_dimensions = hidden_dimensions):\n",
    "    if hidden_dimensions == 1:\n",
    "        xy = (unit_name.split(\":\")[1].split(\",\")[-1].split(\"]\")[0] )\n",
    "        return int(xy)  \n",
    "    elif hidden_dimensions == 2:\n",
    "        xy = list(unit_name.split(\":\")[1][:3])\n",
    "        return int(xy[0]) * 10 + int(xy[2])\n",
    "\n",
    "def get_scene_id(unit_name):\n",
    "    xy = list(unit_name.split(\":\")[1][:7])\n",
    "    return int(xy[0]) * 3 + int(xy[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our previous scheme, units that were active in [high1, high2, med1] trials were classified as cross-pair. I classified these as [high1, high2] because they are active in both similar trials. We can remove this, but I think this removes a lot of the noise in the cross-pair hidden units.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_units(activeunits, unit_dict, name):\n",
    "    def are_units_active(units, where): # units have to be active in all of these trials to return True\n",
    "        for unit in units:\n",
    "            if unit not in units:\n",
    "                return False\n",
    "        return True \n",
    "    if hidden_dimensions == 1:\n",
    "        hidden_unit_id = get_hidden_id(name)\n",
    "        if 22 <= hidden_unit_id <= 25:\n",
    "            unit_dict['med1'].append(name)\n",
    "        elif 26 <= hidden_unit_id <= 27:\n",
    "            unit_dict['med1+2'].append(name)\n",
    "        elif 28 <= hidden_unit_id <= 31:\n",
    "            unit_dict['med2'].append(name)\n",
    "        else:\n",
    "            unit_dict['not active'].append(name)\n",
    "    elif hidden_dimensions == 2:\n",
    "        where = list(np.where(np.array(activeunits.iloc[0]))[0])\n",
    "        if numPairs == 3:\n",
    "            if where == [0]:\n",
    "                unit_dict['high1'].append(name)\n",
    "            elif where == [1]:\n",
    "                unit_dict['high2'].append(name)\n",
    "            elif where == [0,1]:\n",
    "                unit_dict['high1+2'].append(name)\n",
    "            elif where == [2]:\n",
    "                unit_dict['low1'].append(name)\n",
    "            elif where == [3]:\n",
    "                unit_dict['low2'].append(name)\n",
    "            elif where == [2,3]:\n",
    "                unit_dict['low1+2'].append(name)\n",
    "            elif where == [4]:\n",
    "                unit_dict['med1'].append(name)\n",
    "            elif where == [5]:\n",
    "                unit_dict['med2'].append(name)\n",
    "            elif where == [4,5]:\n",
    "                unit_dict['med1+2'].append(name)\n",
    "            elif where == []:\n",
    "                unit_dict['not active'].append(name)\n",
    "            else:\n",
    "                unit_dict[\"cross-pair\"].append(name)\n",
    "    #             if are_units_active([0, 1], where):\n",
    "    #                 unit_dict['high1+2'].append(name)\n",
    "    #             elif are_units_active([2, 3], where):\n",
    "    #                 unit_dict['low1+2'].append(name)\n",
    "    #             elif are_units_active([4, 5], where):\n",
    "    #                 unit_dict['med1+2'].append(name)\n",
    "    #             else:\n",
    "    #                 print(where)\n",
    "    #                 unit_dict[\"cross-pair\"].append(name)\n",
    "\n",
    "        elif numPairs == 2:\n",
    "            if where == [0]:\n",
    "                unit_dict['small1'].append(name)\n",
    "            elif where == [1]:\n",
    "                unit_dict['small2'].append(name)\n",
    "            elif where == [0,1]:\n",
    "                unit_dict['small12'].append(name)\n",
    "            elif where == [2]:\n",
    "                unit_dict['small3'].append(name)\n",
    "            elif where == [3]:\n",
    "                unit_dict['small4'].append(name)\n",
    "            elif where == [2,3]:\n",
    "                unit_dict['small34'].append(name)\n",
    "            elif where == []:\n",
    "                unit_dict['not active'].append(name)\n",
    "            else:\n",
    "                unit_dict[\"cross-pair\"].append(name)\n",
    "    return unit_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if train_trial_done == 1:\n",
    "    unit_dict_list = [] # a list of all unit dictionaries for every run\n",
    "\n",
    "    threshold_hid_act = .5 #threshold above which to consider activity. was .1 initially.\n",
    "    for run in range(nruns +1): # because we index from 0 and nruns = Max Run (9)\n",
    "\n",
    "        unit_dict = defaultdict(list) # a dictionary for every run\n",
    "        for name in hiddenunitnames:\n",
    "    #         name_noM = name.replace('M', '') #because for cycle activity, there's no M\n",
    "\n",
    "            activeunits = hiddenData.loc[(run, epoch_end_initial+1, slice(None), 'TestColorAll', name), :] > threshold_hid_act\n",
    "            unit_dict = classify_units(activeunits, unit_dict, name)\n",
    "        unit_dict_list.append(unit_dict)\n",
    "    #     for k in ['small1', 'small2', 'small12', 'small3', 'small4', 'small34','not active','cross-pair']:\n",
    "    #          print(k, unit_dict[k])\n",
    "    #     break\n",
    "\n",
    "\n",
    "    #[\"$TrialName\",:]\n",
    "\n",
    "    unit_dict_list_2 = [] # reverse key, so each unit is the key and the value is the category\n",
    "    for run in range(nruns +1) : \n",
    "\n",
    "        temp = {v_0:k for k, v in unit_dict_list[run].items() for v_0 in v}\n",
    "        unit_dict_list_2.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_unit_dict(nruns, unit_dict_list_2, to_be_replaced, to_replace): #iterates over each run\n",
    "    new_dict_list =  [None] * (nruns+1)\n",
    "\n",
    "    for n in range(nruns+1) :\n",
    "        new_dict_list[n] = print_dict(unit_dict_list_2[n], to_be_replaced, to_replace)\n",
    "    \n",
    "    return new_dict_list\n",
    "\n",
    "def print_dict(d, to_be_replaced, to_replace): #iterates over each unit, within one run. \n",
    "    new = {}\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            v = print_dict(v)\n",
    "        new[k.replace(to_be_replaced, to_replace)] = v\n",
    "    return new\n",
    "\n",
    "\n",
    "#replace the keys for the relevant analyses\n",
    "unit_dict_list_act = new_unit_dict(nruns, unit_dict_list_2, 'M', '')   #because in cycle data, there's no actM, it's just Act\n",
    "unit_dict_list_actM = new_unit_dict(nruns, unit_dict_list_2, '', '')   #because in cycle data, there's no actM, it's just Act\n",
    "unit_dict_list_avgM = new_unit_dict(nruns, unit_dict_list_2, 'ActM', 'AvgM')   #because in cycle data, there's no actM, it's just Act\n",
    "unit_dict_list_avgS = new_unit_dict(nruns, unit_dict_list_2, 'ActM', 'AvgS')   #because in cycle data, there's no actM, it's just Act\n",
    "unit_dict_list_ge = new_unit_dict(nruns, unit_dict_list_2, 'ActM', 'Ge')\n",
    "unit_dict_list_AvgSLrn = new_unit_dict(nruns, unit_dict_list_2, 'ActM', 'AvgSLrn')   #because in cycle data, there's no actM, it's just Act\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit_dict_list_AvgSLrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Many in each category\n",
    "<a id='How_Many_in_each_category'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_number_of_units_per_category(analyses_df):\n",
    "    title = 'Hidden Unit Classification Count'\n",
    "    try:\n",
    "        plt.clf()\n",
    "        ## how many in each category?\n",
    "        catList = []\n",
    "        catNames = ['low1','low2', 'low1+2', 'med1','med2', 'med1+2', 'high1','high2', 'high1+2', 'not active' ,'cross-pair']\n",
    "        for cat in catNames:\n",
    "            catList.append(cat)\n",
    "\n",
    "        catList.sort()\n",
    "\n",
    "        print(catList)\n",
    "\n",
    "        hiddCountDf = pd.DataFrame(columns = catList, index = range(nruns) )\n",
    "\n",
    "        for r in range(nruns+1) : \n",
    "\n",
    "            count_dict = defaultdict(int)\n",
    "\n",
    "            for cat in unit_dict_list[r] :\n",
    "\n",
    "\n",
    "                count = len(unit_dict_list[r][cat])\n",
    "\n",
    "\n",
    "                count_dict[cat] = count\n",
    "        #     print(pd.Series(count_dict))\n",
    "            hiddCountDf.loc[r] = pd.Series(count_dict)\n",
    "\n",
    "        hiddCountDf = hiddCountDf.reset_index()\n",
    "        hiddCountDf = hiddCountDf.rename(columns={'index':'run'})\n",
    "\n",
    "        pd.set_option('display.max_columns', 30)\n",
    "\n",
    "        # hiddCountDf.set_index('run').stack().unstack(level = 'run')\n",
    "\n",
    "        # b = hiddCountDf.set_index('run').stack()\n",
    "\n",
    "        # b = pd.DataFrame(b)\n",
    "        # b\n",
    "        plt.clf\n",
    "\n",
    "        hiddCountDf_melt = hiddCountDf.melt(id_vars =['run']).sort_values(by=['run'])\n",
    "\n",
    "        hiddCountDf_melt\n",
    "        fig = plt.figure(figsize=(8,8))\n",
    "        ax = sns.barplot(x=\"value\", y=\"variable\", data=hiddCountDf_melt, palette = hidden_palette, order = hidd_order)\n",
    "        ax.set_xlabel('count')\n",
    "        ax.set_ylabel('hidden unit classification')\n",
    "        \n",
    "        plt.title(title)\n",
    "        plt.savefig(checkpoint_fig_dir + title + '.png', bbox_inches = \"tight\")\n",
    "        plt.show()\n",
    "        \n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, True) \n",
    "        return hiddCountDf_melt, analyses_df\n",
    "    except:\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) \n",
    "        return \"error\", analyses_df \n",
    "\n",
    "if train_trial_done == 1:\n",
    "    hiddCountDf_melt, analyses_df = plot_number_of_units_per_category(analyses_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## checkpoint # ? Check that hidden layer has minimum units assigned to each category\n",
    "if train_trial_done == 1:\n",
    "    hiddCountDf_melt['threshold'] = hiddCountDf_melt.value >= 0\n",
    "\n",
    "    #just conditions we care about\n",
    "    hiddCountDf_melt2 = hiddCountDf_melt[~hiddCountDf_melt['variable'].isin(['cross-pair', 'not active'])]\n",
    "    \n",
    "    #for each run, is the condition met fully (i.e. threshold = 1)\n",
    "    percent_condition_met_by_run = hiddCountDf_melt2.groupby('run').mean()\n",
    "    \n",
    "    runs_condition_not_met = percent_condition_met_by_run[percent_condition_met_by_run['threshold']!=1]\n",
    "    runs_condition_met = percent_condition_met_by_run[percent_condition_met_by_run['threshold']==1]\n",
    "\n",
    "    num_runs_condition_not_met = len(runs_condition_not_met)\n",
    "    num_runs_condition_met = len(runs_condition_met)\n",
    "    #acrosss all runs, what percent of runs had some units assigned to each category?\n",
    "    percent_conditions = num_runs_condition_met / (num_runs_condition_met + num_runs_condition_not_met)\n",
    "    print('runs with units assigned to each category:\\n ' + str(percent_conditions * 100) + '%')\n",
    "    threshold_not_met = sum(hiddCountDf_melt2['threshold']==False) # number of times the minimum wasn't met. \n",
    "\n",
    "    if threshold_not_met >0 :\n",
    "        checkpoint_TF = False\n",
    "    else :\n",
    "        checkpoint_TF = True\n",
    "    temp = ['hidden unit count ', checkpoint_TF, percent_conditions * 100, 'Check that hidden layer has some units assigned to each category. Value is the percent of runs that have units for each category']\n",
    "    temp_series = pd.Series(temp, index = checkpoints_df.columns)\n",
    "    checkpoints_df = checkpoints_df.append(temp_series, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## set up hidden layer cycle data with the hidden category labels for analysis:\n",
    "\n",
    "def prepCycleDataHidden(data_trn_cyc_stacked, unit_dict_list, hidden_S, hidden_E) :\n",
    "    \n",
    "    hiddenLayerCycle = data_trn_cyc_stacked.loc[(slice(None),  slice(None), slice(None), slice(None), slice(hidden_S, hidden_E)),:]\n",
    "\n",
    "    hiddenLayerCycle.reset_index(inplace = True)\n",
    "\n",
    "    # Categorize the units in each run\n",
    "    def unitmapper(row):\n",
    "        \n",
    "        try:\n",
    "            return unit_dict_list[row[\"|Run\"]][row['key']]\n",
    "\n",
    "        except:\n",
    "            ;\n",
    "\n",
    "    \n",
    "    hiddenLayerCycle.loc[slice(None),\"Categorization\"] = hiddenLayerCycle.apply(unitmapper, axis = 1) # use the dictionary to set the category\n",
    "    # hiddenLayerCycle.head()\n",
    "    return hiddenLayerCycle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if train_cycle_done == 1 :\n",
    "    print('prepping activity for hidden layer')\n",
    "    hiddenLayerCycle_act = prepCycleDataHidden(data_trn_cyc_stacked, unit_dict_list_act, hidden_Start, hidden_End)\n",
    "\n",
    "    print('prepping AvgM for hidden layer')\n",
    "#     hiddenLayerCycle_ge = prepCycleDataHidden(data_trn_cyc_stacked, unit_dict_list_ge, hidden_ge_start, hidden_ge_end)\n",
    "    hiddenLayerCycle_AvgM = prepCycleDataHidden(data_trn_cyc_stacked, unit_dict_list_avgM, hidden_Start_AvgM, hidden_End_AvgM)\n",
    "    print('prepping AvgS for hidden layer')\n",
    "\n",
    "    hiddenLayerCycle_AvgS = prepCycleDataHidden(data_trn_cyc_stacked, unit_dict_list_avgS, hidden_Start_AvgS, hidden_End_AvgS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Plot the hidden layer pop up\n",
    "<a id='Plot_the_hidden_layer_pop_up'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "local_metadata": {
     "collapsed": false
    },
    "remote_metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "if train_cycle_done == 1 :\n",
    "    for epoch in range(10) :\n",
    "        analyses_df = plot_categorized_cycle(epoch, hiddenLayerCycle_act, 'Act', 'Hidden', analyses_df, selectedTrial = 'med1', selectedRun=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if train_cycle_done == 1 :\n",
    "    for epoch in range(10) :\n",
    "        analyses_df = plot_categorized_cycle(epoch, hiddenLayerCycle_act, 'Act', 'Hidden', analyses_df, selectedTrial = 'med1', selectedRun='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if train_cycle_done == 1 :\n",
    "    \n",
    "\n",
    "    analyses_df = plot_categorized_cycle(epoch_end_initial+1, hiddenLayerCycle_AvgM, 'AvgM', 'Hidden', analyses_df, selectedTrial = 'low1', selectedRun='all')\n",
    "    analyses_df = plot_categorized_cycle(epoch_end_initial+1, hiddenLayerCycle_AvgS, 'AvgS', 'Hidden', analyses_df, selectedTrial = 'low1', selectedRun='all')\n",
    "\n",
    "    analyses_df = plot_categorized_cycle(epoch_end_initial+1, hiddenLayerCycle_AvgM, 'AvgM', 'Hidden', analyses_df, selectedTrial = 'med1', selectedRun='all')\n",
    "    analyses_df = plot_categorized_cycle(epoch_end_initial+1, hiddenLayerCycle_AvgS, 'AvgS', 'Hidden', analyses_df, selectedTrial = 'med1', selectedRun='all')\n",
    "\n",
    "    analyses_df = plot_categorized_cycle(epoch_end_initial+1, hiddenLayerCycle_AvgM, 'AvgM', 'Hidden', analyses_df, selectedTrial = 'high1', selectedRun='all')\n",
    "    analyses_df = plot_categorized_cycle(epoch_end_initial+1, hiddenLayerCycle_AvgS, 'AvgS', 'Hidden', analyses_df, selectedTrial = 'high1', selectedRun='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Layer Pop Up over cycles PROPORTIONALLY -- \n",
    "#### i.e. each value on the y axis is that hidden layer unit types proportion of total activity during that cycle. This is useful to account for each type having different number of units. Also, we can see if the pop up is happening for all categories, or specifically the pairmate category of units. \n",
    "<a id='Hidden_Layer_Pop_Up_over_cycles_PROPORTIONALLY'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ### Analyze hidden pop up relatively-- so that fewer units are taken into account. \n",
    "# temp = hiddenLayerCycle\n",
    "# temp = temp.set_index(['|Run', '|Epoch', '|Cycle', 'key'])\n",
    "# temp = temp.drop(columns = ['$CurrentTask'])\n",
    "# temp.head()\n",
    "\n",
    "# #get the sum activity for each hidden category, at each cycle\n",
    "# sumEachCategory = temp.groupby(['|Run', '|Epoch', '|Cycle','hiddenCat']).sum();\n",
    "# sumEachCategory.head()\n",
    "\n",
    "# #get the sum activity for all units at each cycle\n",
    "# sumEachCycle = sumEachCategory.groupby(['|Run', '|Epoch', '|Cycle']).sum()\n",
    "\n",
    "# #divide to get each hidden category percentage of total activity. \n",
    "# percentHiddenAct = sumEachCategory.div(sumEachCycle)\n",
    "\n",
    "# percentHiddenAct = percentHiddenAct.reset_index()\n",
    "\n",
    "# percentHiddenAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# percentHiddenAct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## XCAL\n",
    "<a id='XCAL'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AvgSLrn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### some necessary set up for avgslrn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some necessary set up for avgslrn\n",
    "data_train['pair'] = data_train['$TrialName'].apply(lambda x: x[:-1])\n",
    "    \n",
    "#which trial in each pair comes first in train trials?\n",
    "first_each_epoch_train = data_train.loc[data_train.groupby(['|Run', '|Epoch','pair'])['|Trial'].idxmin()][['|Run','|Epoch', 'pair', '$TrialName']]\n",
    "first_each_epoch_train = first_each_epoch_train.sort_values(by=['|Run', '|Epoch'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### function definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_selected_output_activity(run, data, epoch, trial_type, first_unit_type, printvals = False) :\n",
    "\n",
    "#     run_activity_df = pd.DataFrame(columns = ['run', 'trial', 'unit_assignment', 'activity'])\n",
    "    \n",
    "#     activity_runs = np.empty(0);\n",
    "\n",
    "#     if run == 'all' :\n",
    "#         runs_to_do = range(data_train_stacked.index.get_level_values(0).max() + 1)\n",
    "#     else : \n",
    "#         runs_to_do = [run]\n",
    "\n",
    "#     for r in runs_to_do :\n",
    "#         #get units we care about:\n",
    "#         first_units = getKeysByValue(output_classification_dict_AvgSLrn, first_unit_type) # med 2 units\n",
    "        \n",
    "#         #get activations for these units during the first trial of trial_type during the recall task\n",
    "#         trial_first_units =data.loc[idx[r,epoch,:,first_units], [trial_type]]\n",
    "\n",
    "#         #reshape these to be nx1 and 1xn so we can do dot products\n",
    "#         trial_first_units_reshape = trial_first_units[[trial_type]].values\n",
    "\n",
    "#         if printvals == True :\n",
    "#             print('run = ' + str(r))\n",
    "#             print(first_unit_type + ' activations:\\n')\n",
    "#             print(trial_first_units_reshape)\n",
    "        \n",
    "#         temp_series = pd.Series([r, trial_type, first_unit_type, np.mean(trial_first_units_reshape)], index = run_activity_df.columns)\n",
    "#         run_activity_df = run_activity_df.append(temp_series, ignore_index = True)\n",
    "#         #activity_runs = np.append(activity_runs, trial_first_units)\n",
    "#     return (run_activity_df)\n",
    "\n",
    "# def get_selected_hidden_activity(run, data,  epoch,trial_type, first_unit_type, printvals = False) :\n",
    "\n",
    "#     run_activity_df = pd.DataFrame(columns = ['run', 'trial', 'unit_assignment', 'activity'])\n",
    "    \n",
    "#     activity_runs = np.empty(0);\n",
    "\n",
    "#     if run == 'all' :\n",
    "#         runs_to_do = range(data_train_stacked.index.get_level_values(0).max() + 1)\n",
    "#     else : \n",
    "#         runs_to_do = [run]\n",
    "\n",
    "#     for r in runs_to_do :\n",
    "#         #get units we care about:\n",
    "#         first_units = getKeysByValue(unit_dict_list_AvgSLrn[r], first_unit_type) # med 2 units\n",
    "\n",
    "#         #get activations for these units during the first trial of trial_type during the recall task\n",
    "#         trial_first_units =data.loc[idx[r,epoch,:,first_units], [trial_type]]\n",
    "\n",
    "#         #reshape these to be nx1 and 1xn so we can do dot products\n",
    "#         trial_first_units_reshape = trial_first_units[[trial_type]].values\n",
    "\n",
    "#         if printvals == True :\n",
    "#             print('run = ' + str(r))\n",
    "#             print(first_unit_type + ' activations:\\n')\n",
    "#             print(trial_first_units_reshape)\n",
    "        \n",
    "#         temp_series = pd.Series([r, trial_type, first_unit_type, np.mean(trial_first_units_reshape)], index = run_activity_df.columns)\n",
    "#         run_activity_df = run_activity_df.append(temp_series, ignore_index = True)\n",
    "#         #activity_runs = np.append(activity_runs, trial_first_units)\n",
    "#     return (run_activity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_selected_AvgSLrn(Layer, data, epoch, analyses_df) :\n",
    "    title = 'Competitor AvgSLrn in ' + Layer + ' layer, epoch #' + str(epoch)\n",
    "    try:\n",
    "        if Layer == 'Color' :\n",
    "            med, med_all = get_selected_output_activity_first_trial('all', data_train_stacked, epoch, 'med', 'Color', printvals = False)\n",
    "            low, low_all = get_selected_output_activity_first_trial('all', data_train_stacked,  epoch,'low', 'Color',printvals = False)\n",
    "            high, high_all = get_selected_output_activity_first_trial('all', data_train_stacked,  epoch,'high', 'Color', printvals = False)\n",
    "        elif Layer == 'Hidden' :\n",
    "            med, med_all = get_selected_output_activity_first_trial('all', data_train_stacked, epoch, 'med', 'Hidden', printvals = False)\n",
    "            low, low_all = get_selected_output_activity_first_trial('all', data_train_stacked,  epoch,'low', 'Hidden',printvals = False)\n",
    "            high, high_all = get_selected_output_activity_first_trial('all', data_train_stacked,  epoch,'high', 'Hidden', printvals = False)\n",
    "        elif Layer == 'Scene' :\n",
    "            med, med_all = get_selected_output_activity_first_trial('all', data_train_stacked, epoch, 'med', 'Scene', printvals = False)\n",
    "            low, low_all = get_selected_output_activity_first_trial('all', data_train_stacked,  epoch,'low', 'Scene',printvals = False)\n",
    "            high, high_all = get_selected_output_activity_first_trial('all', data_train_stacked,  epoch,'high', 'Scene', printvals = False)\n",
    "\n",
    "        all_competitors = pd.concat([low,med,high], axis = 0)\n",
    "        all_AvgSLrn_connections = pd.concat([low_all, med_all, high_all], axis = 0 )\n",
    "        if study_task_run == 1 :\n",
    "            sns.boxplot(x = 'pair', hue = 'targ', y = 'activity', data = all_competitors)\n",
    "        \n",
    "        elif study_task_run == 0 :\n",
    "        \n",
    "            sns.barplot(x = 'pair', hue = 'targ', y = 'activity', data = all_competitors)\n",
    "\n",
    "#         sns.swarmplot(x = 'pair', hue = 'targ', y = 'activity', data = all_competitors)\n",
    "        plt.title(title)\n",
    "        plt.ylim(0,1)\n",
    "        plt.ylabel('AvgSLrn')\n",
    "        plt.savefig(checkpoint_fig_dir + title + '.png', bbox_inches = \"tight\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, True) \n",
    "\n",
    "        return all_competitors, all_AvgSLrn_connections, analyses_df\n",
    "\n",
    "    except Exception as e:\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) \n",
    "        traceback.print_exc()\n",
    "\n",
    "        return \"error\", \"error\", analyses_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_selected_output_activity_first_trial(run, data,  epoch,pair, Layer, printvals = False) :\n",
    "    run_activity_df = pd.DataFrame(columns = ['run', 'epoch', 'pair', 'trial', 'unit', 'targ', 'activity'])\n",
    "\n",
    "    activity_runs = np.empty(0);\n",
    "\n",
    "    if run == 'all' :\n",
    "        runs_to_do = range(data_train_stacked.index.get_level_values(0).max() + 1)\n",
    "    else : \n",
    "        runs_to_do = [run]\n",
    "\n",
    "    all_connections_df = pd.DataFrame()\n",
    "    \n",
    "    for r in runs_to_do  :\n",
    "        is_run = first_each_epoch_train['|Run'] == r\n",
    "        is_epoch = first_each_epoch_train['|Epoch'] == epoch\n",
    "        is_pair = first_each_epoch_train['pair'] == pair\n",
    "        \n",
    "        \n",
    "        curr_first_trial = first_each_epoch_train[is_run & is_epoch & is_pair]['$TrialName'].to_string(index=False)\n",
    "        if curr_first_trial[0] == ' ': #weird bug where there's a space first...\n",
    "            curr_first_trial = curr_first_trial[1:]\n",
    "\n",
    "\n",
    "        if curr_first_trial[-1:] == '1' :\n",
    "            target = curr_first_trial\n",
    "            competitor = pair + '2' \n",
    "\n",
    "        elif curr_first_trial[-1:] == '2' :\n",
    "            target = curr_first_trial\n",
    "            competitor = pair + '1'\n",
    "\n",
    "        shared = pair +'1+2'\n",
    "        \n",
    "        if Layer == 'Color' :\n",
    "            u_dict = output_classification_dict_AvgSLrn\n",
    "        elif Layer == 'Hidden' :\n",
    "            u_dict = unit_dict_list_AvgSLrn[r]\n",
    "        elif Layer == 'Scene' :\n",
    "            u_dict = sceneKey_AvgSLrn\n",
    "            \n",
    "        #get units we care about:\n",
    "        competitor_units = getKeysByValue(u_dict, competitor) # med 2 units\n",
    "        target_units = getKeysByValue(u_dict, target) # med 2 units\n",
    "        \n",
    "        if Layer != 'Scene' :\n",
    "            shared_units = getKeysByValue(u_dict, shared) # med 2 units\n",
    "            \n",
    "        #get activations for these units during the first trial of trial_type during the recall task\n",
    "        trial_competitor_act =data.loc[idx[r,epoch,:,competitor_units], [curr_first_trial]]\n",
    "\n",
    "        trial_target_act =data.loc[idx[r,epoch,:,target_units], [curr_first_trial]]\n",
    "\n",
    "        if Layer != 'Scene' :\n",
    "            trial_shared_act =data.loc[idx[r,epoch,:,shared_units], [curr_first_trial]]\n",
    "\n",
    "        list_of_non_pair_units = []\n",
    "        for k, v in u_dict.items() :\n",
    "            if v == target or v == competitor or v == shared:\n",
    "                continue;\n",
    "            else:\n",
    "#                 if Layer == 'Hidden' :\n",
    "                list_of_non_pair_units.append(k)\n",
    "\n",
    "\n",
    "            \n",
    "        trial_non_pair_act =data.loc[idx[r,epoch,:,list_of_non_pair_units], [curr_first_trial]]\n",
    "        trial_non_pair_act = trial_non_pair_act[curr_first_trial].mean()\n",
    "\n",
    "        #reshape these to be nx1 and 1xn so we can do dot products\n",
    "        trial_competitor_act_reshape = trial_competitor_act[[curr_first_trial]].values\n",
    "\n",
    "        trial_target_act_reshape = trial_target_act[[curr_first_trial]].values\n",
    "        if Layer != 'Scene' :\n",
    "            trial_shared_act_reshape = trial_shared_act[[curr_first_trial]].values\n",
    "\n",
    "        if printvals == True :\n",
    "            print('run = ' + str(r))\n",
    "            print(competitor + ' activations:\\n')\n",
    "            print(trial_competitor_act_reshape)\n",
    "            print(target + ' activations:\\n')\n",
    "            print(trial_target_act_reshape)\n",
    "\n",
    "\n",
    "        temp_series = pd.Series([r, epoch, pair, curr_first_trial, competitor, 'competitor', np.mean(trial_competitor_act_reshape)], index = run_activity_df.columns)\n",
    "        run_activity_df = run_activity_df.append(temp_series, ignore_index = True)\n",
    "        temp_series = pd.Series([r, epoch, pair, curr_first_trial, target, 'target', np.mean(trial_target_act_reshape)], index = run_activity_df.columns)\n",
    "        run_activity_df = run_activity_df.append(temp_series, ignore_index = True)\n",
    "        \n",
    "        if Layer != 'Scene' :\n",
    "            temp_series = pd.Series([r, epoch, pair, curr_first_trial, shared, 'shared', np.mean(trial_shared_act_reshape)], index = run_activity_df.columns)\n",
    "            run_activity_df = run_activity_df.append(temp_series, ignore_index = True)\n",
    "        \n",
    "\n",
    "        temp_series = pd.Series([r, epoch, pair, curr_first_trial, 'non_pair', 'non_pair', trial_non_pair_act], index = run_activity_df.columns)\n",
    "        run_activity_df = run_activity_df.append(temp_series, ignore_index = True)\n",
    "\n",
    "\n",
    "        for type in ['competitor', 'target', 'shared'] :\n",
    "            if type == 'competitor' :\n",
    "                stim = competitor\n",
    "                specific_activity = trial_competitor_act_reshape.reshape(1, len(trial_competitor_act_reshape))[0]\n",
    "            elif type == 'target' :\n",
    "                stim = target\n",
    "                specific_activity = trial_target_act_reshape.reshape(1, len(trial_target_act_reshape))[0]\n",
    "            elif type == 'shared' :\n",
    "                if Layer != 'Scene' :\n",
    "                    stim = shared\n",
    "                    specific_activity = trial_shared_act_reshape.reshape(1, len(trial_shared_act_reshape))[0]\n",
    "\n",
    "            t_df = pd.DataFrame({'AvgSLrn': specific_activity})\n",
    "            t_df['run'] = r\n",
    "            t_df['epoch'] = epoch\n",
    "            t_df['pair'] = pair\n",
    "            t_df['curr_first_trial'] = curr_first_trial\n",
    "            t_df['competitor'] = stim\n",
    "            t_df['type'] = type\n",
    "            all_connections_df = all_connections_df.append(t_df)\n",
    "    \n",
    "    all_connections_df = all_connections_df.reset_index(drop=True)\n",
    "        #activity_runs = np.append(activity_runs, trial_first_units)\n",
    "    return run_activity_df, all_connections_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plot the AvgSLrn in each layer for target, competitor, and shared units in first epoch of Output Recall Task\n",
    "<a id='Plot_the_AvgSLrn_in_each_layer_for_target,_competitor,_and_shared_units_in_first_epoch_of_Color_Recall_Task'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if train_trial_done == 1:\n",
    "    plt.clf()\n",
    "    output_competitor_AvgSLrn, all_output_AvgSLrn_df, analyses_df = plot_selected_AvgSLrn('Color', data_train_stacked, epoch_end_initial+1, analyses_df)\n",
    "    plt.clf()\n",
    "    hidden_competitor_AvgSLrn, all_hidden_AvgSLrn_df, analyses_df = plot_selected_AvgSLrn('Hidden', data_train_stacked, epoch_end_initial+1,analyses_df)\n",
    "    plt.clf()\n",
    "    scene_competitor_AvgSLrn, all_scene_AvgSLrn_df, analyses_df = plot_selected_AvgSLrn('Scene', data_train_stacked, epoch_end_initial+1,analyses_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint for avgSLrn\n",
    "<a id='Checkpoint_for_avgSLrn'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def AvgSLrn_checkpoint(Layer, AvgSLrn_data, checkpoints_df):\n",
    "    \n",
    "    if AvgSLrn_data.sum != 'error' :\n",
    "        #output layer:\n",
    "        is_low = AvgSLrn_data['pair'] == 'low'\n",
    "        is_med = AvgSLrn_data['pair'] == 'med'\n",
    "        is_high = AvgSLrn_data['pair'] == 'high'\n",
    "\n",
    "        is_competitor = AvgSLrn_data['targ'] == 'competitor'\n",
    "        is_target = AvgSLrn_data['targ'] == 'target'\n",
    "\n",
    "        low = AvgSLrn_data[is_low & is_competitor]['activity'].mean()\n",
    "        med = AvgSLrn_data[is_med & is_competitor]['activity'].mean()\n",
    "        high = AvgSLrn_data[is_high & is_competitor]['activity'].mean()\n",
    "\n",
    "        if low< med < high:\n",
    "            checkpoint_TF = True\n",
    "        else :\n",
    "            checkpoint_TF = False\n",
    "        description = Layer + ' Layer: is AvgSLrn for competitor the first trial of the second task in correct low-med-high order'\n",
    "        temp = [Layer + ' AvgSLrn l-m-h', checkpoint_TF, 0, description]\n",
    "        temp_series = pd.Series(temp, index = checkpoints_df.columns)\n",
    "        checkpoints_df = checkpoints_df.append(temp_series, ignore_index = True)\n",
    "\n",
    "        mean_values = dict(low=low, med=med, high=high)\n",
    "\n",
    "        for type_overlap, mean_avgSLrn in mean_values.items() :\n",
    "\n",
    "            description = Layer + ' Layer: ' + type_overlap + ' competitor value of AvgSLrn (ignore true/false)'\n",
    "            temp = [Layer + ' ' + type_overlap +' ' + 'compet AvgSLrn VALUE', True, mean_avgSLrn, description]\n",
    "            temp_series = pd.Series(temp, index = checkpoints_df.columns)\n",
    "            checkpoints_df = checkpoints_df.append(temp_series, ignore_index = True)\n",
    "\n",
    "        temp = [Layer + ' AvgSLrn range', True, high - low, 'range of high competitor avgSlrn - low competitor avgslrn']\n",
    "        temp_series = pd.Series(temp, index = checkpoints_df.columns)\n",
    "        checkpoints_df = checkpoints_df.append(temp_series, ignore_index = True)\n",
    "\n",
    "\n",
    "        low_targ = AvgSLrn_data[is_low & is_target]['activity'].mean()\n",
    "        med_targ = AvgSLrn_data[is_med & is_target]['activity'].mean()\n",
    "        high_targ = AvgSLrn_data[is_high & is_target]['activity'].mean()\n",
    "\n",
    "        mean_values = dict(low=low_targ, med=med_targ, high=high_targ)\n",
    "\n",
    "        for type_overlap, mean_avgSLrn in mean_values.items() :\n",
    "\n",
    "            description = Layer + ' Layer: ' + type_overlap + ' target value of AvgSLrn (ignore true/false)'\n",
    "            temp = [Layer + ' ' + type_overlap +' ' + 'targ AvgSLrn VALUE', True, mean_avgSLrn, description]\n",
    "            temp_series = pd.Series(temp, index = checkpoints_df.columns)\n",
    "            checkpoints_df = checkpoints_df.append(temp_series, ignore_index = True)\n",
    "\n",
    "        is_non_pair = AvgSLrn_data['targ'] == 'non_pair'\n",
    "        low_non_pair = AvgSLrn_data[is_low & is_non_pair]['activity'].mean()\n",
    "        med_non_pair = AvgSLrn_data[is_med & is_non_pair]['activity'].mean()\n",
    "        high_non_pair = AvgSLrn_data[is_high & is_non_pair]['activity'].mean()\n",
    "\n",
    "        mean_values = dict(low=low_non_pair, med=med_non_pair, high=high_non_pair)\n",
    "\n",
    "        for type_overlap, mean_avgSLrn in mean_values.items() :\n",
    "            description = Layer + ' Layer: ' + type_overlap + ' non-pair value of AvgSLrn (ignore true/false)'\n",
    "            temp = [Layer + ' ' + type_overlap +' ' + 'nonPair AvgSLrn VALUE', True, mean_avgSLrn, description]\n",
    "            temp_series = pd.Series(temp, index = checkpoints_df.columns)\n",
    "            checkpoints_df = checkpoints_df.append(temp_series, ignore_index = True)\n",
    "\n",
    "        return(checkpoints_df)\n",
    "\n",
    "\n",
    "checkpoints_df = AvgSLrn_checkpoint('Color', output_competitor_AvgSLrn, checkpoints_df)\n",
    "checkpoints_df = AvgSLrn_checkpoint('Hidden', hidden_competitor_AvgSLrn, checkpoints_df)\n",
    "checkpoints_df = AvgSLrn_checkpoint('Scene', scene_competitor_AvgSLrn, checkpoints_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## FIGURE OUT NMPH LEARNING FUNCTION FOR EACH PROJECTION\n",
    "<a id='calc NMPH curve'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Learning Curve based on Trial 1 Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if calculate_learning_curve == 1 :\n",
    "\n",
    "    def calc_coproduct_layer(layer1_act, layer2_act, same_or_different):\n",
    "\n",
    "        if same_or_different == 'same' :\n",
    "            # if the two AvgSLRn sets of units are the same, only multiply pairs of units one time, and don't multiply same units. \n",
    "            coproducts = [layer1_act[a1] * layer2_act[b1] for a1 in range(len(layer1_act)) for b1 in range(len(layer2_act)) if a1 < b1]\n",
    "\n",
    "        elif same_or_different == 'different' :\n",
    "            coproducts =[layer1_act[a1] * layer2_act[b1] for a1 in range(len(layer1_act)) for b1 in range(len(layer2_act))]\n",
    "\n",
    "        return coproducts\n",
    "\n",
    "    def filter_runs_for_coproducts(first_layer_AvgSLrn, second_layer_AvgSLrn, first_layer, second_layer, percentile_give) :\n",
    "        #percentile_give gives the percentile flexibility. If 100, then it will be strict. if 95, then it takes the 95% percentile.\n",
    "\n",
    "\n",
    "        epoch = epoch_end_initial + 1\n",
    "        all_coact = pd.DataFrame()\n",
    "\n",
    "        if first_layer == second_layer :\n",
    "            within_layer = 1\n",
    "        else :\n",
    "            within_layer = 0\n",
    "\n",
    "        #strict filters:\n",
    "        filter_run_list = {'Max_compet_shared_MED_less_Min_target_shared_MED' :[]}\n",
    "        filter_run_list['Max_compet_shared_MED_less_Min_target_target_MED'] = []\n",
    "        filter_run_list['Max_compet_target_MED_less_Min_target_shared_MED'] = []\n",
    "        filter_run_list['Max_compet_target_MED_less_Min_target_target_MED'] = []\n",
    "\n",
    "    #     filter_run_list['Max_compet_shared_LOW_less_Min_compet_shared_MED'] = []\n",
    "    #     filter_run_list['Max_compet_shared_MED_less_Min_compet_shared_HIGH'] = []\n",
    "    #     filter_run_list['Max_compet_shared_MED_less_Min_target_shared_HIGH'] = []\n",
    "        filter_run_list['Max_compet_compet_MED_less_Min_compet_shared_MED'] = []\n",
    "\n",
    "\n",
    "\n",
    "        filter_run_list['all filters'] = []\n",
    "        for run in range(nruns + 1):\n",
    "            run_coact = pd.DataFrame()\n",
    "            currentRun_L1 = first_layer_AvgSLrn[first_layer_AvgSLrn['run'] == run]\n",
    "            currentRun_L2 = second_layer_AvgSLrn[second_layer_AvgSLrn['run'] == run]\n",
    "\n",
    "            for pair in ['low', 'med', 'high'] : \n",
    "                compet_act_1 = currentRun_L1[(currentRun_L1['type'] == 'competitor') & (currentRun_L1['pair'] == pair)]['AvgSLrn'].reset_index(drop = True)\n",
    "                targ_act_1 = currentRun_L1[(currentRun_L1['type'] == 'target') & (currentRun_L1['pair'] == pair)]['AvgSLrn'].reset_index(drop = True)\n",
    "                shared_act_1 = currentRun_L1[(currentRun_L1['type'] == 'shared') & (currentRun_L1['pair'] == pair)]['AvgSLrn'].reset_index(drop = True)\n",
    "\n",
    "                compet_act_2 = currentRun_L2[(currentRun_L2['type'] == 'competitor') & (currentRun_L2['pair'] == pair)]['AvgSLrn'].reset_index(drop = True)\n",
    "                targ_act_2 = currentRun_L2[(currentRun_L2['type'] == 'target') & (currentRun_L2['pair'] == pair)]['AvgSLrn'].reset_index(drop = True)\n",
    "                shared_act_2 = currentRun_L2[(currentRun_L2['type'] == 'shared') & (currentRun_L2['pair'] == pair)]['AvgSLrn'].reset_index(drop = True)\n",
    "\n",
    "\n",
    "                temp_DF = pd.DataFrame()\n",
    "\n",
    "\n",
    "                if within_layer == 1 :\n",
    "                    coprod_compet_compet = calc_coproduct_layer(compet_act_1, compet_act_2, 'same')\n",
    "                else :\n",
    "                    coprod_compet_compet = calc_coproduct_layer(compet_act_1, compet_act_2, 'different')\n",
    "                coprod_compet_targ = calc_coproduct_layer(compet_act_1, targ_act_2, 'different')\n",
    "\n",
    "                coprod_compet_shared = calc_coproduct_layer(compet_act_1, shared_act_2, 'different')\n",
    "\n",
    "                coprod_targ_compet = calc_coproduct_layer(targ_act_1, compet_act_2, 'different')\n",
    "                if within_layer == 1 :\n",
    "                    coprod_targ_targ = calc_coproduct_layer(targ_act_1, targ_act_2, 'same')\n",
    "                else :\n",
    "                    coprod_targ_targ = calc_coproduct_layer(targ_act_1, targ_act_2, 'different')\n",
    "                coprod_targ_shared = calc_coproduct_layer(targ_act_1, shared_act_2, 'different')\n",
    "\n",
    "                coprod_shared_compet = calc_coproduct_layer(shared_act_1, compet_act_2, 'different')\n",
    "                coprod_shared_targ = calc_coproduct_layer(shared_act_1, targ_act_2, 'different')\n",
    "                if within_layer == 1 :\n",
    "                    coprod_shared_shared = calc_coproduct_layer(shared_act_1, shared_act_2, 'same')\n",
    "                else:\n",
    "                    coprod_shared_shared = calc_coproduct_layer(shared_act_1, shared_act_2, 'different')\n",
    "\n",
    "                for coact_type in ['coprod_compet_compet', 'coprod_compet_targ', 'coprod_compet_shared', \n",
    "                                  'coprod_targ_compet', 'coprod_targ_targ', 'coprod_targ_shared',\n",
    "                                  'coprod_shared_compet', 'coprod_shared_targ', 'coprod_shared_shared'] :\n",
    "                    coact = eval(coact_type)\n",
    "                    temp_df= pd.DataFrame({'coproduct' : coact})\n",
    "                    temp_df['run'] = run\n",
    "                    temp_df['epoch'] = epoch\n",
    "                    temp_df['pair'] = pair\n",
    "                    temp_df['coact_type'] = coact_type\n",
    "                    run_coact = run_coact.append(temp_df)\n",
    "\n",
    "\n",
    "\n",
    "            all_coact = all_coact.append(run_coact)\n",
    "\n",
    "            #############################\n",
    "            #######FILTERS:\n",
    "\n",
    "            ###### Flag for if this run satisfies all the filters for this projection. \n",
    "            ###### If any filter fails, it gets set to 0. \n",
    "            all_filters_passed = 1;\n",
    "\n",
    "            low = run_coact['pair'] == 'low'\n",
    "            med = run_coact['pair'] == 'med'\n",
    "            high = run_coact['pair'] == 'high'\n",
    "\n",
    "            #---------------------\n",
    "            # FILTER #1\n",
    "            ## 'max of compet_shared LOW < min compet_shared MED')\n",
    "    #         try: \n",
    "\n",
    "    #             a = np.percentile(run_coact[low & (run_coact['coact_type'] == 'coprod_compet_shared')]['coproduct'], percentile_give) #max\n",
    "    #             b = np.percentile(run_coact[med & (run_coact['coact_type'] == 'coprod_compet_shared')]['coproduct'], 100 - percentile_give) #min   \n",
    "\n",
    "    #             if a < b : \n",
    "    #                 filter_run_list['Max_compet_shared_LOW_less_Min_compet_shared_MED'].append(run)\n",
    "    #             else : \n",
    "    #                 all_filters_passed = 0;\n",
    "    #         except:\n",
    "    #             all_filters_passed = 0;\n",
    "            #---------------------\n",
    "            # FILTER #2\n",
    "            ## 'max of compet_shared MED < min compet_shared HIGH')\n",
    "\n",
    "    #         try:\n",
    "\n",
    "    #             a = np.percentile(run_coact[med & (run_coact['coact_type'] == 'coprod_compet_shared')]['coproduct'], percentile_give) #max\n",
    "    #             b = np.percentile(run_coact[high & (run_coact['coact_type'] == 'coprod_compet_shared')]['coproduct'], 100 - percentile_give)#min\n",
    "\n",
    "    #             if a < b : \n",
    "    #                 filter_run_list['Max_compet_shared_MED_less_Min_compet_shared_HIGH'].append(run)\n",
    "    #             else : \n",
    "    #                 all_filters_passed = 0;\n",
    "    #         except: \n",
    "    #             all_filters_passed = 0;\n",
    "\n",
    "\n",
    "            #---------------------\n",
    "    #         # FILTER #3\n",
    "\n",
    "    #             a = np.percentile(run_coact[med & (run_coact['coact_type'] == 'coprod_compet_shared')]['coproduct'], percentile_give)\n",
    "    #             b = np.percentile(run_coact[high & (run_coact['coact_type'] == 'coprod_target_shared')]['coproduct'], 100 - percentile_give)\n",
    "\n",
    "    #             if a < b : \n",
    "    #                 filter_run_list['Max_compet_shared_MED_less_Min_target_shared_HIGH'].append(run)\n",
    "    #             else : \n",
    "    #                 all_filters_passed = 0;\n",
    "\n",
    "    #         except :\n",
    "    #             all_filters_passed = 0\n",
    "\n",
    "\n",
    "            #---------------------\n",
    "            # FILTER #4\n",
    "            try:\n",
    "\n",
    "                a = np.percentile(run_coact[med & (run_coact['coact_type'] == 'coprod_compet_compet')]['coproduct'], percentile_give) #max\n",
    "                b = np.percentile(run_coact[med & (run_coact['coact_type'] == 'coprod_compet_shared')]['coproduct'], 100 - percentile_give) #min\n",
    "\n",
    "                if a < b : \n",
    "                    filter_run_list['Max_compet_compet_MED_less_Min_compet_shared_MED'].append(run)\n",
    "                else : \n",
    "                    all_filters_passed = 0;\n",
    "            except:\n",
    "                all_filters_passed = 0;\n",
    "\n",
    "                    #---------------------\n",
    "            # FILTER #5\n",
    "            try:\n",
    "\n",
    "                # we want this one to be strict, so not using percentile:\n",
    "                a = run_coact[med & (run_coact['coact_type'] == 'coprod_compet_shared')]['coproduct'].max() #max\n",
    "                b = run_coact[med & (run_coact['coact_type'] == 'coprod_targ_shared')]['coproduct'].min() #min\n",
    "\n",
    "                if a < b : \n",
    "                    filter_run_list['Max_compet_shared_MED_less_Min_target_shared_MED'].append(run)\n",
    "                else : \n",
    "                    all_filters_passed = 0;\n",
    "            except:\n",
    "                all_filters_passed = 0;\n",
    "\n",
    "            ##---------------------\n",
    "            # FILTER #6\n",
    "            try:\n",
    "\n",
    "                # we want this one to be strict, so not using percentile:\n",
    "                a = run_coact[med & (run_coact['coact_type'] == 'coprod_compet_shared')]['coproduct'].max() #max\n",
    "                b = run_coact[med & (run_coact['coact_type'] == 'coprod_targ_targ')]['coproduct'].min() #min\n",
    "\n",
    "                if a < b : \n",
    "                    print(a)\n",
    "                    print(b)\n",
    "                    filter_run_list['Max_compet_shared_MED_less_Min_target_target_MED'].append(run)\n",
    "                else : \n",
    "                    all_filters_passed = 0;\n",
    "            except:\n",
    "                all_filters_passed = 0;\n",
    "\n",
    "                    #---------------------\n",
    "            # FILTER #7\n",
    "            try:\n",
    "\n",
    "                # we want this one to be strict, so not using percentile:\n",
    "                a = run_coact[med & (run_coact['coact_type'] == 'coprod_compet_targ')]['coproduct'].max() #max\n",
    "                b = run_coact[med & (run_coact['coact_type'] == 'coprod_targ_shared')]['coproduct'].min() #min\n",
    "\n",
    "                if a < b : \n",
    "                    filter_run_list['Max_compet_target_MED_less_Min_target_shared_MED'].append(run)\n",
    "                else : \n",
    "                    all_filters_passed = 0;\n",
    "            except:\n",
    "                all_filters_passed = 0;\n",
    "\n",
    "            ##---------------------\n",
    "            # FILTER #8\n",
    "            try:\n",
    "\n",
    "                # we want this one to be strict, so not using percentile:\n",
    "                a = run_coact[med & (run_coact['coact_type'] == 'coprod_compet_targ')]['coproduct'].max() #max\n",
    "                b = run_coact[med & (run_coact['coact_type'] == 'coprod_targ_targ')]['coproduct'].min() #min\n",
    "\n",
    "                if a < b : \n",
    "                    filter_run_list['Max_compet_target_MED_less_Min_target_target_MED'].append(run)\n",
    "                else : \n",
    "                    all_filters_passed = 0;\n",
    "            except:\n",
    "                all_filters_passed = 0;\n",
    "\n",
    "            #DONE!\n",
    "            if all_filters_passed == 1:\n",
    "                filter_run_list['all filters'].append(run)\n",
    "\n",
    "        return all_coact, filter_run_list\n",
    "\n",
    "\n",
    "\n",
    "    all_coact_hidd_hidd, filter_hidd_hidd = filter_runs_for_coproducts(all_hidden_AvgSLrn_df, all_hidden_AvgSLrn_df, 'Hidden', 'Hidden', 70)\n",
    "    all_coact_hidd_col, filter_hidd_col = filter_runs_for_coproducts(all_hidden_AvgSLrn_df, all_output_AvgSLrn_df, 'Hidden', 'Output',0)\n",
    "    all_coact_scene_hidd, filter_scene_hidd = filter_runs_for_coproducts(all_scene_AvgSLrn_df, all_hidden_AvgSLrn_df, 'Scene', 'Hidden',0)\n",
    "\n",
    "\n",
    "    # to get seed:\n",
    "    # run = ___\n",
    "    # seed = data_run[data_run['|Run'] == run]['$Seed']\n",
    "\n",
    "    print(' ')\n",
    "    print('filter_hidd_hidd')\n",
    "    pp.pprint(filter_hidd_hidd)\n",
    "    print(' ')\n",
    "    print('filter_hidd_col')\n",
    "    pp.pprint(filter_hidd_col)\n",
    "    print(' ')\n",
    "    print('filter_scene_hidd')\n",
    "    pp.pprint(filter_scene_hidd)\n",
    "    \n",
    "    def find_common_run(list1, list2) :\n",
    "        intersection_set = set.intersection(set(list1), set(list2))\n",
    "        intersection_list = list(intersection_set)\n",
    "        return intersection_list\n",
    "\n",
    "\n",
    "\n",
    "    allruns = np.arange(nruns+1)\n",
    "\n",
    "    # for curr_prjn in [filter_hidd_hidd, filter_scene_hidd, filter_hidd_col] :\n",
    "    for curr_prjn in [filter_hidd_hidd] :\n",
    "        all_common_runs = find_common_run(allruns, curr_prjn['all filters'])\n",
    "\n",
    "    print('\\n\\n***********\\n***********\\n')\n",
    "    print('THE ONLY RUNS THAT SATISFY ALL THE FILTERS FOR EACH PROJECTION' )\n",
    "\n",
    "    print(all_common_runs)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if calculate_learning_curve == 1 :\n",
    "\n",
    "    chosen_run = 0\n",
    "\n",
    "    if chosen_run not in all_common_runs :\n",
    "        raise ValueError('you need to manually set \"chosen run\" to be one of the runs that satisfy all the filters above')\n",
    "\n",
    "    else :\n",
    "        seed = data_run[data_run['|Run'] == chosen_run]['$Seed']\n",
    "        print(seed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ##TEMPORARY CODE TO JUST CHECK THAT THESE COACTIVITIES ARE THE SAME\n",
    "# # AS THE ONES WE PLOTTED IN TEH XCAL FUNCTION. \n",
    "\n",
    "# data_t = all_coact_hidd_col\n",
    "# low = data_t['pair'] == 'low'\n",
    "# med = data_t['pair'] == 'med'\n",
    "# high = data_t['pair'] == 'high'\n",
    "\n",
    "# run = data_t['run'] == 0\n",
    "# overlap = med\n",
    "# prjn_name = 'coprod_compet_shared'\n",
    "# prjn = data_t['coact_type'] == prjn_name\n",
    "\n",
    "\n",
    "# print(len(data_t[run & overlap & prjn]['coproduct']))\n",
    "# print(data_t[run & overlap & prjn]['coproduct'].min())\n",
    "# print(data_t[run & overlap & prjn]['coproduct'].max())\n",
    "# print(sorted(data_t[run & overlap & prjn]['coproduct']))\n",
    "\n",
    "# # for coact_type in ['coprod_compet_compet', 'coprod_compet_targ', 'coprod_compet_shared', \n",
    "# #                   'coprod_targ_compet', 'coprod_targ_targ', 'coprod_targ_shared',\n",
    "# #                   'coprod_shared_compet', 'coprod_shared_targ', 'coprod_shared_shared'] :\n",
    "    \n",
    "# #     prjn = data_t['coact_type'] == coact_type\n",
    "# #     sns.swarmplot(x = 'pair', hue = 'pair', y = 'coproduct', data = data_t[run & prjn])\n",
    "# #     plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "# #     plt.title(coact_type)\n",
    "# #     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## select correct boundaries:\n",
    "\n",
    "if calculate_learning_curve == 1 :\n",
    "    def select_NMPH_boundaries(projection, run) :\n",
    "        med = projection['pair'] == 'med'\n",
    "        run = projection['run'] == run\n",
    "\n",
    "        min_compet_shared_val = projection[run & med & (projection['coact_type'] == 'coprod_compet_shared')]['coproduct'].min()\n",
    "        max_compet_compet_val = projection[run & med & (projection['coact_type'] == 'coprod_compet_compet')]['coproduct'].max()\n",
    "        max_compet_shared_val = projection[run & med & (projection['coact_type'] == 'coprod_compet_shared')]['coproduct'].max()\n",
    "\n",
    "        min_targ_targ_val = projection[run &med & (projection['coact_type'] == 'coprod_targ_targ')]['coproduct'].min()\n",
    "        min_targ_shared_val = projection[run &med & (projection['coact_type'] == 'coprod_targ_shared')]['coproduct'].min()\n",
    "\n",
    "        #get D_Thr first\n",
    "\n",
    "        if max_compet_compet_val < min_compet_shared_val :#if it's easy, and there's a clean divide:\n",
    "\n",
    "            left_boundary_left = min(.0001, np.mean([min_compet_shared_val, max_compet_compet_val]))\n",
    "            boundary_Dthr = max_compet_compet_val + left_boundary_left\n",
    "        else :\n",
    "            left_boundary_right = .0001\n",
    "            boundary_Dthr = min_compet_shared_val - left_boundary_right\n",
    "\n",
    "        #get ThrP:\n",
    "\n",
    "        min_integration_values = min(min_targ_targ_val, min_targ_shared_val)\n",
    "\n",
    "        boundary_ThrP = np.mean([min_integration_values, max_compet_shared_val])    \n",
    "\n",
    "\n",
    "        boundary_DRev = np.median(projection[run & med & (projection['coact_type'] == 'coprod_compet_shared')]['coproduct'])\n",
    "\n",
    "        if boundary_DRev > boundary_ThrP :\n",
    "            boundary_DRev = np.mean([boundary_ThrP, boundary_Dthr])\n",
    "\n",
    "    #     print('DThr: ' + str(boundary_Dthr))\n",
    "    #     print('DRev: ' + str(boundary_DRev))\n",
    "    #     print('ThrP: ' + str(boundary_ThrP))\n",
    "\n",
    "        return boundary_Dthr, boundary_DRev, boundary_ThrP\n",
    "\n",
    "\n",
    "    print ('chosen run is ' + str(chosen_run))\n",
    "    h_h_boundary = {}\n",
    "    h_h_boundary['DThr'], h_h_boundary['DRev'], h_h_boundary['ThrP'] = select_NMPH_boundaries(all_coact_hidd_hidd, chosen_run)\n",
    "    h_h_boundary['ProjectionName'] = 'HiddenToHidden'\n",
    "\n",
    "    h_c_boundary = {}\n",
    "    h_c_boundary['DThr'], h_c_boundary['DRev'], h_c_boundary['ThrP'] = select_NMPH_boundaries(all_coact_hidd_col, chosen_run)\n",
    "    h_c_boundary['ProjectionName'] = 'HiddenToOutput'\n",
    "\n",
    "    f_h_boundary = {}\n",
    "    f_h_boundary['DThr'], f_h_boundary['DRev'], f_h_boundary['ThrP'] = select_NMPH_boundaries(all_coact_scene_hidd, chosen_run)\n",
    "    f_h_boundary['ProjectionName'] = 'SceneToHidden'\n",
    "\n",
    "    h_h_boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print out param sheet for each projection type to easily paste into output_diff.go\n",
    "<a id='Print_out_param_sheet_for_each_projection_type_to_easily_paste_into_output_diff.go'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if calculate_learning_curve == 1 :\n",
    "    for projection in [h_h_boundary, h_c_boundary, f_h_boundary] :\n",
    "\n",
    "        this_projection = projection['ProjectionName']\n",
    "        Layers = this_projection.split('To')\n",
    "        reverse_projection = Layers[1] + 'To' + Layers[0]\n",
    "\n",
    "        if this_projection == reverse_projection :\n",
    "            projection_list = [this_projection]\n",
    "\n",
    "        else :\n",
    "            projection_list = [this_projection, reverse_projection]\n",
    "\n",
    "        for prjn_direction_name in projection_list :\n",
    "\n",
    "            print('{Sel: \"#' + prjn_direction_name + '\", \"default connection (will change for non-shape learning task).\", \\\n",
    "            \\n\\tParams: params.Params{\\n \\\n",
    "            \\t\\t\"Prjn.Learn.XCal.DThr_NMPH\" : \"' + str(projection['DThr']) +'\",\\n\\\n",
    "            \\t\\t\"Prjn.Learn.XCal.DRev_NMPH\" : \"' + str(projection['DRev']) +'\",\\n\\\n",
    "            \\t\\t\"Prjn.Learn.XCal.DRevMag_NMPH\" : \"-0.3\",\\n\\\n",
    "            \\t\\t\"Prjn.Learn.XCal.DMaxMag_NMPH\" : \"0.3\",\\n\\\n",
    "            \\t\\t\"Prjn.Learn.XCal.ThrP_NMPH\" : \"' + str(projection['ThrP']) +'\",\\n\\\n",
    "            }},')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot scatter plot of DWt vs. AvgSLrn coproducts\n",
    "<a id='plot_scatter_plot_DWt_vs_AvgSLrn_coproducts'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_competitor_AvgSLrn[hidden_competitor_AvgSLrn['pair']=='med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_unit_key_from_id(idx, layer):\n",
    "    \n",
    "    if layer == 'Scene':\n",
    "        x, y = [idx // 3, idx % 3]\n",
    "        if (x == 0) & (y == 0):\n",
    "            extra = '<4:2,1,1,3>'\n",
    "        else:\n",
    "            extra = ''\n",
    "\n",
    "        return f'#SceneAvgSLrn[4:{x},0,0,{y}]{extra}'\n",
    "    elif layer == 'Output':\n",
    "        x, y = [idx // 50, idx % 50]\n",
    "        \n",
    "        if (x == 0) & (y == 0):\n",
    "            extra = '<2:1,50>'\n",
    "        else:\n",
    "            extra = ''\n",
    "\n",
    "        return f'#OutAvgSLrn[2:{x},{y}]{extra}'\n",
    "    elif layer == 'Hidden':\n",
    "        if hidden_dimensions == 1 :\n",
    "            x, y = [idx // 50, idx % 50]\n",
    "#             print(idx, x, y)\n",
    "            if (x == 0) & (y == 0):\n",
    "                extra ='<2:1,50>' \n",
    "            else:\n",
    "                extra = ''\n",
    "\n",
    "            return f'#HiddenAvgSLrn[2:{x},{y}]{extra}'\n",
    "        \n",
    "        elif hidden_dimensions == 2 :\n",
    "            x, y = [idx // 10, idx % 10]\n",
    "            if (x == 0) & (y == 0):\n",
    "                extra ='<2:10,10>' \n",
    "            else:\n",
    "                extra = ''\n",
    "\n",
    "            return f'#HiddenAvgSLrn[2:{x},{y}]{extra}'\n",
    "\n",
    "def get_unit_type_dict_for_layer(layer, run = 0):\n",
    "    # Get dictionary classifying unit type by layer\n",
    "    if layer == 'Hidden':\n",
    "        return unit_dict_list_AvgSLrn[run]\n",
    "    elif layer == 'Output':\n",
    "        return output_classification_dict_AvgSLrn\n",
    "    elif layer == 'Scene':\n",
    "        return sceneKey_AvgSLrn\n",
    "\n",
    "def analyze_DWt_AvgSLrn_by_trial_type(data, run, epoch, trial_type, \n",
    "                                      first_layer, second_layer, plot_all_combinations, pdf):\n",
    "    \"\"\"\n",
    "    data: data_train_stacked \n",
    "    trial_type: one of ['low', 'med', 'high']\n",
    "    \"\"\"  \n",
    "    \n",
    "    # Define target, competitor, and shared unit types\n",
    "    target_first_trial_type = list(hidden_competitor_AvgSLrn[(hidden_competitor_AvgSLrn['run'] == run) & (hidden_competitor_AvgSLrn['pair'] == trial_type)]['trial'])\n",
    "    target_first_trial_type = target_first_trial_type[0]\n",
    "    competitor_unit_first_trial_type = competitor_trial(target_first_trial_type)\n",
    "    shared_unit_first_trial_type = trial_type + '1+2'\n",
    "    analyzed_units = [target_first_trial_type, competitor_unit_first_trial_type, shared_unit_first_trial_type]\n",
    "    num_units_sender_layer = parameter_values['Num_units_per_layer'][first_layer]\n",
    "    num_units_receiver_layer = parameter_values['Num_units_per_layer'][second_layer]\n",
    "#     print(num_units_sender_layer, num_units_sender_layer)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # get AvgSLrn values into trial_first_units \n",
    "    def get_layer_start_and_end_indices_AvgSLrn(layer):\n",
    "        if layer == \"Hidden\":\n",
    "            start_index = hidden_Start_AvgSLrn\n",
    "            end_index = hidden_End_AvgSLrn\n",
    "        elif layer == \"Scene\":\n",
    "            start_index = scene_Start_AvgSLrn\n",
    "            end_index = scene_End_AvgSLrn\n",
    "        elif layer == \"Output\":\n",
    "            start_index = output_Start_AvgSLrn\n",
    "            end_index = output_End_AvgSLrn\n",
    "        return start_index, end_index\n",
    "    \n",
    "    start_index, end_index = get_layer_start_and_end_indices_AvgSLrn(first_layer)\n",
    "    trial_first_units = data.loc[idx[run,epoch,slice(None),slice(start_index, end_index)], [target_first_trial_type]]\n",
    "    trial_first_units = trial_first_units.values\n",
    "    \n",
    "    start_index, end_index = get_layer_start_and_end_indices_AvgSLrn(second_layer)\n",
    "    trial_second_units = data.loc[idx[run,epoch,slice(None),slice(start_index, end_index)], [target_first_trial_type]]\n",
    "    trial_second_units = trial_second_units.values\n",
    "    \n",
    "    # get saved DWt\n",
    "    if first_layer == \"Hidden\" and second_layer == \"Hidden\":\n",
    "        start_index = hidden_to_hidden_DWt_Start\n",
    "        end_index = hidden_to_hidden_DWt_End\n",
    "    elif first_layer == \"Hidden\" and second_layer == \"Scene\":\n",
    "        start_index = hidden_to_scene_DWt_Start\n",
    "        end_index = hidden_to_scene_DWt_End\n",
    "    elif first_layer == \"Scene\" and second_layer == \"Hidden\":\n",
    "        start_index = scene_to_hidden_DWt_Start\n",
    "        end_index = scene_to_hidden_DWt_End\n",
    "    elif first_layer == \"Hidden\" and second_layer == \"Output\":\n",
    "        start_index = hidden_to_output_DWt_Start\n",
    "        end_index = hidden_to_output_DWt_End\n",
    "    elif first_layer == \"Output\" and second_layer == \"Hidden\":\n",
    "        start_index = output_to_hidden_DWt_Start\n",
    "        end_index = output_to_hidden_DWt_End\n",
    "    run_dwt = np.array(data.loc[(run, epoch, slice(None), slice(start_index, end_index)), \n",
    "                                target_first_trial_type]) \n",
    "    \n",
    "    \n",
    "    # connection_type holds the type of connection (one of compet-compet, compet-shared, target-shared)\n",
    "    connection_type = []\n",
    "    \n",
    "    # coprods holds the coproducts of AvgSLrn values for different connection types\n",
    "    coprods = []\n",
    "    \n",
    "    # dwts holds the dwt values for different connection types\n",
    "    dwts = []\n",
    "    \n",
    "    \n",
    "        \n",
    "    def infer_receiving_unit_type(sender_unit_type):\n",
    "        if plot_all_combinations:\n",
    "            return [shared_unit_first_trial_type, competitor_unit_first_trial_type, target_first_trial_type]\n",
    "        else:\n",
    "            if sender_unit_type == competitor_unit_first_trial_type:\n",
    "                return [shared_unit_first_trial_type, competitor_unit_first_trial_type]\n",
    "            elif sender_unit_type == target_first_trial_type:\n",
    "                return [shared_unit_first_trial_type]\n",
    "        \n",
    "    classify_sending_layer_units_dict = get_unit_type_dict_for_layer(first_layer, run)\n",
    "    classify_receiving_layer_units_dict = get_unit_type_dict_for_layer(second_layer, run)\n",
    "#     print(classify_receiving_layer_units_dict)\n",
    "    for i in range(num_units_sender_layer):\n",
    "        sender_unit = get_unit_key_from_id(i, first_layer)\n",
    "        sender_unit_type =  classify_sending_layer_units_dict[sender_unit]\n",
    "        if sender_unit_type in [competitor_unit_first_trial_type, target_first_trial_type]:\n",
    "            for j in range(num_units_receiver_layer):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                receiver_unit = get_unit_key_from_id(j, second_layer)\n",
    "                receiver_unit_type = classify_receiving_layer_units_dict[receiver_unit]\n",
    "                if receiver_unit_type in infer_receiving_unit_type(sender_unit_type):\n",
    "                    coprods.append(trial_first_units[i] * trial_second_units[j])\n",
    "                    connection_type.append(f\"{sender_unit_type}-{receiver_unit_type}\")\n",
    "                    # Hidden units don't connect to themselves: this affects how we access DWt\n",
    "                    if first_layer == \"Hidden\" and second_layer == \"Hidden\":\n",
    "                        weight_id = i * (num_units_receiver_layer - 1) + j - int(j > i) \n",
    "                    else:\n",
    "                        weight_id = i * (num_units_receiver_layer) + j \n",
    "                    \n",
    "                    dwts.append(run_dwt[weight_id])\n",
    "                    \n",
    "#     print(len(coprods), len(connection_type), len(dwts))\n",
    "    print((coprods))\n",
    "    print(connection_type)\n",
    "    print(dwts)\n",
    "    print(competitor_unit_first_trial_type, shared_unit_first_trial_type, target_first_trial_type)\n",
    "#     print(connection_type)\n",
    "#     print(dwts)\n",
    "\n",
    "    output_dictionary = {f\"{competitor_unit_first_trial_type}-{competitor_unit_first_trial_type}\": \"red\",\n",
    "                        f\"{competitor_unit_first_trial_type}-{shared_unit_first_trial_type}\": \"black\",\n",
    "                        f\"{competitor_unit_first_trial_type}-{target_first_trial_type}\": \"orange\",\n",
    "                        f\"{target_first_trial_type}-{shared_unit_first_trial_type}\": \"blue\",\n",
    "                        f\"{target_first_trial_type}-{competitor_unit_first_trial_type}\": \"green\",\n",
    "                        f\"{target_first_trial_type}-{target_first_trial_type}\": \"purple\",\n",
    "                       }\n",
    "    connection_color =[output_dictionary[conn] for conn in connection_type]\n",
    "\n",
    "\n",
    "    title = f\"{first_layer}_to_{second_layer}: First trial ({target_first_trial_type}) DWt vs. AvgSLrn from {first_layer} to {second_layer}\"   \n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "    ax.scatter(coprods, dwts, c = connection_output, alpha = .3)\n",
    "\n",
    "    ax.set_xlabel('Coproducts', fontsize=25)\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_ylabel(f'DWt', fontsize=25)\n",
    "    ax.set_ylim(-1.1,0.4)\n",
    "\n",
    "    ax.set_title(f\"{title} Run {run} Epoch {epoch}\")\n",
    "    ax.axhline()\n",
    "    legend_elements = [\n",
    "                   Line2D([0], [0], marker='o', color='w', markerscenecolor=('red'), label=f\"{competitor_unit_first_trial_type}-{competitor_unit_first_trial_type}\", markersize=8),\n",
    "                   Line2D([0], [0], marker='o', color='w', markerscenecolor='black', label=f\"{competitor_unit_first_trial_type}-{shared_unit_first_trial_type}\", markersize=8),\n",
    "                   Line2D([0], [0], marker='o', color='w', markerscenecolor='orange', label=f\"{competitor_unit_first_trial_type}-{target_first_trial_type}\", markersize=8),\n",
    "                   Line2D([0], [0], marker='o', color='w', markerscenecolor='green', label=f\"{target_first_trial_type}-{competitor_unit_first_trial_type}\", markersize=8),\n",
    "                   Line2D([0], [0], marker='o', color='w', markerscenecolor='blue', label=f\"{target_first_trial_type}-{shared_unit_first_trial_type}\", markersize=8),\n",
    "                   Line2D([0], [0], marker='o', color='w', markerscenecolor='purple', label=f\"{target_first_trial_type}-{target_first_trial_type}\", markersize=8)\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "    pdf.savefig(fig, bbox_inches = \"tight\")\n",
    "\n",
    "def plot_scatter_plot_DWt_vs_AvgSLrn_coproducts(data, first_layer, second_layer, plot_all_combinations, analyses_df):\n",
    "    # trial_types = ['low', 'med', 'high']\n",
    "    trial_types = ['med']\n",
    "    \n",
    "    try:\n",
    "        pdf = PdfPages(checkpoint_fig_dir + f\"{first_layer}_to_{second_layer}:AvgSLrn_vs_DWt_scatter_plots.pdf\")\n",
    "#         runs_to_do = range(nruns + 1)\n",
    "        runs_to_do = range(1)\n",
    "        epochs_to_do = [epoch_end_initial + 1] #range(max_final_epoch)\n",
    "        print(\"epoch_end_initial\", epoch_end_initial)\n",
    "        for run in runs_to_do :\n",
    "            for epoch in epochs_to_do:\n",
    "                for trial_type in trial_types:\n",
    "                    coprods = analyze_DWt_AvgSLrn_by_trial_type(data, run, epoch, trial_type, \n",
    "                                                                first_layer, second_layer, \n",
    "                                                                plot_all_combinations=plot_all_combinations, pdf=pdf)\n",
    "\n",
    "        pdf.close()\n",
    "        #analyses_df = add_analysis_to_analyses_df(analyses_df, title, True) \n",
    "    except:\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) \n",
    "        traceback.print_exc()\n",
    "    return analyses_df\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analyses_df = plot_scatter_plot_DWt_vs_AvgSLrn_coproducts(data_train_stacked, \"Hidden\", \"Hidden\", plot_all_combinations=True, analyses_df=analyses_df)\n",
    "plt.show()\n",
    "analyses_df = plot_scatter_plot_DWt_vs_AvgSLrn_coproducts(data_train_stacked, \"Scene\", \"Hidden\", plot_all_combinations=True, analyses_df=analyses_df)\n",
    "plt.show()\n",
    "analyses_df = plot_scatter_plot_DWt_vs_AvgSLrn_coproducts(data_train_stacked, \"Hidden\", \"Scene\", plot_all_combinations=True, analyses_df=analyses_df)\n",
    "plt.show()\n",
    "analyses_df = plot_scatter_plot_DWt_vs_AvgSLrn_coproducts(data_train_stacked, \"Hidden\", \"Output\", plot_all_combinations=True, analyses_df=analyses_df)\n",
    "plt.show()\n",
    "analyses_df = plot_scatter_plot_DWt_vs_AvgSLrn_coproducts(data_train_stacked, \"Output\", \"Hidden\", plot_all_combinations=True, analyses_df=analyses_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "def get_unit_key_from_id(id):\n",
    "    x, y = [id // 10, id % 10]\n",
    "    if (x == 0) & (y == 0):\n",
    "        extra = '<2:10,10>'\n",
    "    else:\n",
    "        extra = ''\n",
    "\n",
    "    return f'#HiddenAvgSLrn[2:{x},{y}]{extra}'\n",
    "\n",
    "def analyze_DWt_AvgSLrn_by_trial_type(data, run, epoch, trial_type, pdf, \n",
    "                                      first_layer = \"Hidden\", second_layer = \"Hidden\"):\n",
    "    \"\"\"\n",
    "    data: data_train_stacked \n",
    "    trial_type: one of ['low', 'med', 'high']\n",
    "    \"\"\"  \n",
    "    \n",
    "    # Define target, competitor, and shared unit types\n",
    "    target_first_trial_type = list(hidden_competitor_AvgSLrn[(hidden_competitor_AvgSLrn['run'] == run) & (hidden_competitor_AvgSLrn['pair'] == trial_type)]['trial'])\n",
    "    target_first_trial_type = target_first_trial_type[0]\n",
    "    competitor_unit_first_trial_type = competitor_trial(target_first_trial_type)\n",
    "    shared_unit_first_trial_type = trial_type + '1+2'\n",
    "    analyzed_units = [target_first_trial_type, competitor_unit_first_trial_type, shared_unit_first_trial_type]\n",
    "    \n",
    "    # trial_first_units hold the AvgSLrn values  \n",
    "    trial_first_units = data.loc[idx[run,epoch,slice(None),slice(hidden_Start_AvgSLrn, hidden_End_AvgSLrn)], [target_first_trial_type]]\n",
    "    trial_first_units = trial_first_units.values\n",
    "    \n",
    "    # get saved DWt\n",
    "    start_index, end_index = [hidden_to_hidden_DWt_Start, hidden_to_hidden_DWt_End]\n",
    "    run_dwt = np.array(data.loc[(run, epoch, slice(None), slice(start_index, end_index)), \n",
    "                                target_first_trial_type]) \n",
    "    \n",
    "    \n",
    "    # connection_type holds the type of connection (one of compet-compet, compet-shared, target-shared)\n",
    "    connection_type = []\n",
    "    \n",
    "    # coprods holds the coproducts of AvgSLrn values for different connection types\n",
    "    coprods = []\n",
    "    \n",
    "    # dwts holds the dwt values for different connection types\n",
    "    dwts = []\n",
    "    \n",
    "    def infer_receiving_unit_type(sender_unit_type):\n",
    "        if sender_unit_type == competitor_unit_first_trial_type:\n",
    "            return [shared_unit_first_trial_type, competitor_unit_first_trial_type]\n",
    "        elif sender_unit_type == target_first_trial_type:\n",
    "            return [shared_unit_first_trial_type]\n",
    "        \n",
    "    for i in range(100):\n",
    "        sender_unit = get_unit_key_from_id(i)\n",
    "        sender_unit_type = unit_dict_list_AvgSLrn[run][sender_unit]\n",
    "        if sender_unit_type in [competitor_unit_first_trial_type, target_first_trial_type]:\n",
    "            for j in range(100):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                receiver_unit = get_unit_key_from_id(j)\n",
    "                receiver_unit_type = unit_dict_list_AvgSLrn[run][receiver_unit]\n",
    "                if receiver_unit_type in infer_receiving_unit_type(sender_unit_type):\n",
    "                    coprods.append(trial_first_units[i] * trial_first_units[j])\n",
    "                    connection_type.append(f\"{sender_unit_type}-{receiver_unit_type}\")\n",
    "                    weight_id = i * 99 + j - int(j > i) \n",
    "                    dwts.append(run_dwt[weight_id])\n",
    "                    \n",
    "#     print(len(coprods), len(connection_type), len(dwts))\n",
    "#     print(connection_type)\n",
    "#     print(dwts)\n",
    "\n",
    "    output_dictionary = {f\"{competitor_unit_first_trial_type}-{competitor_unit_first_trial_type}\": \"red\",\n",
    "                        f\"{competitor_unit_first_trial_type}-{shared_unit_first_trial_type}\": \"black\",\n",
    "                        f\"{target_first_trial_type}-{shared_unit_first_trial_type}\": \"blue\"\n",
    "                       }\n",
    "    connection_color =[output_dictionary[conn] for conn in connection_type]\n",
    "\n",
    "\n",
    "    title = f\"First trial ({target_first_trial_type}) DWt vs. AvgSLrn from {first_layer} to {second_layer}\"   \n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "    ax.scatter(coprods, dwts, c = connection_output, alpha = .3)\n",
    "\n",
    "    ax.set_xlabel('Coproducts', fontsize=25)\n",
    "    ax.set_xlim(0,1)\n",
    "    ax.set_ylabel(f'DWt', fontsize=25)\n",
    "    ax.set_ylim(-0.1,0.1)\n",
    "\n",
    "    ax.set_title(f\"{title} Run {run} Epoch {epoch}\")\n",
    "    ax.axhline()\n",
    "    legend_elements = [\n",
    "                   Line2D([0], [0], marker='o', color='w', markerscenecolor='red', label=f\"{competitor_unit_first_trial_type}-{competitor_unit_first_trial_type}\", markersize=8),\n",
    "                   Line2D([0], [0], marker='o', color='w', markerscenecolor='black', label=f\"{competitor_unit_first_trial_type}-{shared_unit_first_trial_type}\", markersize=8),\n",
    "                   Line2D([0], [0], marker='o', color='w', markerscenecolor='blue', label=f\"{target_first_trial_type}-{shared_unit_first_trial_type}\", markersize=8)\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='lower right')\n",
    "\n",
    "    pdf.savefig(fig, bbox_inches = \"tight\")\n",
    "\n",
    "def plot_scatter_plot_DWt_vs_AvgSLrn_coproducts(data, first_layer, second_layer, \n",
    "                                                first_unit_type, second_unit_type, \n",
    "                                                weight_or_dwt, analyses_df):\n",
    "    \n",
    "    try:\n",
    "        pdf = PdfPages(checkpoint_fig_dir + f\"AvgSLrn_vs_DWt_scatter_plots.pdf\")\n",
    "        runs_to_do = range(nruns + 1)\n",
    "        epochs_to_do = [8] #range(max_final_epoch)\n",
    "        for run in runs_to_do :\n",
    "            for epoch in epochs_to_do:\n",
    "                for trial_type in ['low', 'med', 'high']:\n",
    "                    analyze_DWt_AvgSLrn_by_trial_type(data, run, epoch, trial_type, pdf)\n",
    "\n",
    "        pdf.close()\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, True) \n",
    "    except:\n",
    "        analyses_df = add_analysis_to_analyses_df(analyses_df, title, False) \n",
    "        traceback.print_exc()\n",
    "    return analyses_df\n",
    "    \n",
    "analyses_df = plot_scatter_plot_DWt_vs_AvgSLrn_coproducts(data_train_stacked, \"Hidden\", \"Hidden\", \"med1+2\", \n",
    "                                                          \"med2\", \"dwt\", analyses_df)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## ######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add necessary checkpoint info\n",
    "<a id='Add_necessary_checkpoint_info'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if results_df['TF'].sum() == len(results_df['TF']) :\n",
    "    all_results_true = True\n",
    "    temp = ['ALL RESULTS MET', all_results_true, 1, 'Only add if all resulting predictions are met']\n",
    "    temp_series = pd.Series(temp, index = results_df.columns)\n",
    "    results_df = results_df.append(temp_series, ignore_index = True)\n",
    "\n",
    "else :\n",
    "    all_results_true = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpoints_df['OscAmnt_Scene'] = parameter_values['OscAmnt']['Scene']\n",
    "checkpoints_df['Gi_Scene'] = parameter_values['Gi']['Scene']\n",
    "checkpoints_df['OscAmnt_Hidd'] = parameter_values['OscAmnt']['Hidden']\n",
    "checkpoints_df['Gi_Hidd'] = parameter_values['Gi']['Hidden']\n",
    "checkpoints_df['OscAmnt_Out'] = parameter_values['OscAmnt']['Output']\n",
    "checkpoints_df['Gi_Out'] = parameter_values['Gi']['Output']\n",
    "checkpoints_df['dir_name'] = data_file\n",
    "\n",
    "checkpoints_df.to_csv(checkpoint_fig_dir + 'checkpoints.csv')\n",
    "\n",
    "results_df['OscAmnt_Scene'] = parameter_values['OscAmnt']['Scene']\n",
    "results_df['Gi_Scene'] = parameter_values['Gi']['Scene']\n",
    "results_df['OscAmnt_Hidd'] = parameter_values['OscAmnt']['Hidden']\n",
    "results_df['Gi_Hidd'] = parameter_values['Gi']['Hidden']\n",
    "results_df['OscAmnt_Out'] = parameter_values['OscAmnt']['Output']\n",
    "results_df['Gi_Out'] = parameter_values['Gi']['Output']\n",
    "results_df['same_diff_condition'] = parameter_values['overlap']['same_diff_condition']\n",
    "results_df['dir_name'] = data_file\n",
    "results_df.to_csv(results_fig_dir + 'results.csv')\n",
    "\n",
    "\n",
    "analyses_df['dir_name'] = data_file\n",
    "analyses_df.to_csv(figDir + 'analyses.csv')\n",
    "\n",
    "center_of_mass_df['same_diff_condition'] = parameter_values['overlap']['same_diff_condition']\n",
    "center_of_mass_df.to_csv(results_fig_dir + 'center_of_mass.csv')\n",
    "\n",
    "if scene_test == True:\n",
    "    scene_data_df.to_csv(results_fig_dir + 'scene_data.csv')\n",
    "\n",
    "\n",
    "## correlation df:\n",
    "hidden_corr_long['layer'] = 'hidden'\n",
    "output_corr_long['layer'] = 'output'\n",
    "corr_df = hidden_corr_long.append(output_corr_long)\n",
    "corr_df['same_diff_condition'] = parameter_values['overlap']['same_diff_condition']\n",
    "corr_df.to_csv(results_fig_dir + 'correlation.csv')\n",
    "\n",
    "num_shared_units_df.to_csv(results_fig_dir + 'num_units.csv')\n",
    "df_pre_post_corr.to_csv(results_fig_dir + 'pre_post_corr.csv')\n",
    "with open(f\"{dataDir}/codeprofiler.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    s = io.StringIO()\n",
    "    ps = pstats.Stats(codeprofiler, stream=s).sort_stats(\"cumtime\")\n",
    "    ps.print_stats()\n",
    "    f.write(s.getvalue())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "center_of_mass_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save\n",
    "<a id='Save'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if from_cmdLine != 'cmd' :\n",
    "    os.system('ipython nbconvert --to HTML Post_analyses.ipynb')\n",
    "    os.system('mv Post_analyses.html ' + dataDir + data_file + '_analysis.html')\n",
    "    print(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('done with analysis!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (leabra)",
   "language": "python",
   "name": "leabra"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
